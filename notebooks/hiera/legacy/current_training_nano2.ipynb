{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326fe080-349c-4351-8cb5-8d15dae4ab23",
   "metadata": {},
   "source": [
    "# TinyHiera with multiloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df70a83-863a-41ab-8361-8fcce3634d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293c138d-55ff-4de0-904a-4449479c48e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import scaled_dot_product_attention\n",
    "from torch.nn.attention import SDPBackend, sdpa_kernel\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "from torch.optim import AdamW, Adam\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "from experanto.datasets import ChunkDataset, SimpleChunkedDataset\n",
    "from experanto.utils import LongCycler, MultiEpochsDataLoader\n",
    "from experanto.dataloaders import get_multisession_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178fae80-70f0-4f84-a43f-b9f1e7d820f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['dynamic29513-3-5-Video-full',\n",
    "         'dynamic29514-2-9-Video-full',\n",
    "         'dynamic29755-2-8-Video-full',\n",
    "         'dynamic29647-19-8-Video-full',\n",
    "         'dynamic29156-11-10-Video-full',\n",
    "         'dynamic29623-4-9-Video-full',\n",
    "         'dynamic29515-10-12-Video-full',\n",
    "         'dynamic29234-6-9-Video-full',\n",
    "         'dynamic29712-5-9-Video-full',\n",
    "         'dynamic29228-2-10-Video-full'\n",
    "        ]\n",
    "full_paths = [path.join(\"/data/mouse_polly/\", f) for f in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e08de-a283-4b70-800a-0c6c57809c44",
   "metadata": {},
   "source": [
    "## Load Config Object from .yaml file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbf2809-83e0-4d29-8681-35a1a8143a3a",
   "metadata": {},
   "source": [
    "### Modify the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a4a9b8-fe4d-46d8-84ab-292cc1531bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from experanto.configs import DEFAULT_CONFIG as cfg\n",
    "cfg.dataset.global_chunk_size = 16\n",
    "cfg.dataset.global_sampling_rate = 8\n",
    "cfg.dataset.modality_config.screen.include_blanks=True\n",
    "cfg.dataset.modality_config.screen.valid_condition = {\"tier\": \"train\"}\n",
    "cfg.dataset.modality_config.screen.transforms.Resize.size = [72, 128]\n",
    "\n",
    "cfg.dataloader.num_workers=4\n",
    "cfg.dataloader.prefetch_factor=1\n",
    "cfg.dataloader.batch_size=32\n",
    "cfg.dataloader.pin_memory=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15408235-5208-4c24-9961-09c9cf90cf93",
   "metadata": {},
   "source": [
    "### Instantiate MultiDataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac12c18-b7da-45f0-83e0-f56d6f932c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the multiple dataloader is an iterator that returns a tuple of (key, batch)\n",
    "train_dl = get_multisession_dataloader(full_paths, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c38564-cdfd-420d-af9f-c031e9b118c9",
   "metadata": {},
   "source": [
    "# Hiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2ed553-eb2b-49d6-81a2-3fe54aee9fa3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from hiera import Hiera\n",
    "tiny_hiera = Hiera(input_size=(16,72, 128),\n",
    "                     num_heads=1,\n",
    "                     embed_dim=256,\n",
    "                     stages=(4, 8), \n",
    "                     q_pool=1, \n",
    "                     in_chans=1,\n",
    "                     q_stride=(1, 2, 2),\n",
    "                     mask_unit_size=(1, 8, 8),\n",
    "                     patch_kernel=(3, 8, 8),\n",
    "                     patch_stride=(2, 4, 4),\n",
    "                     patch_padding=(1, 3, 3),\n",
    "                     sep_pos_embed=True,)\n",
    "#tiny_hiera = torch.compile(tiny_hiera).cuda().to(torch.bfloat16);\n",
    "tiny_hiera = tiny_hiera.cuda().to(torch.bfloat16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f6f53-9958-4c60-a368-7646884b4993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcd413cf-5874-42f2-9fdd-c221b24e6298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 9, 16, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_in = torch.ones(8,1,16,72, 128).to(\"cuda\", torch.bfloat16)\n",
    "out = tiny_hiera(example_in, return_intermediates=True);\n",
    "features = out[-1][-1]\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3a7d3-6aac-4fe9-9ac9-c1af5d018f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b4a908-60d2-4060-8122-33cceb904a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:01<00:00, 77.76it/s]\n"
     ]
    }
   ],
   "source": [
    "example_in = torch.ones(8,1,16,72, 128).to(\"cuda\", torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        out = tiny_hiera(example_in, return_intermediates=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a8c2f-48af-4622-8387-7645e97dbd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2a39383-d3eb-4014-a0bd-6a72d3af4a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:13, 14.63it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (k, b) in tqdm(enumerate(train_dl)):\n",
    "        videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        out = tiny_hiera(videos, return_intermediates=True);\n",
    "        if i > 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d72ebb3-5278-4f25-82a4-89c1d7351b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7680"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*15*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7692e9-4a29-45a8-8c12-3cfe24839116",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c4694af-e27c-4d71-94ba-f6db53cbef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexedLinearReadout(nn.Module):\n",
    "    \"\"\"\n",
    "    Readout module for MTM models with selectable weights based on \n",
    "    input IDs. Based on :class:`torch.nn.Linear`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        unique_ids: int,\n",
    "        in_features: int = 384,\n",
    "        out_features: int = 1,\n",
    "        bias: bool = True,\n",
    "        device=\"cuda\",\n",
    "        dtype=torch.float32,\n",
    "        init_std: float = 0.02,\n",
    "    ):\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.unique_ids = unique_ids\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.init_std = init_std\n",
    "\n",
    "        self.query = nn.Parameter(\n",
    "            torch.empty(1, 4, unique_ids, 32, **factory_kwargs)\n",
    "        )\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.empty(unique_ids, in_features, out_features, **factory_kwargs)\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(\n",
    "                torch.empty(1, unique_ids, out_features, **factory_kwargs)\n",
    "            )\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self, cutoff_factor: int = 3):\n",
    "        \"\"\"See `TorchTitan <https://github.com/pytorch/torchtitan/blob/40a10263c5b3468ffa53b3ac98d80c9267d68155/torchtitan/models/llama/model.py#L403>`__.\"\"\"\n",
    "        readout_std = self.in_features**-0.5\n",
    "        nn.init.trunc_normal_(\n",
    "            self.weight,\n",
    "            mean=0.0,\n",
    "            std=readout_std,\n",
    "            a=-cutoff_factor * readout_std,\n",
    "            b=cutoff_factor * readout_std,\n",
    "        )\n",
    "        readout_std = self.in_features**-0.5\n",
    "        nn.init.trunc_normal_(\n",
    "            self.query,\n",
    "            mean=0.0,\n",
    "            std=readout_std,\n",
    "            a=-cutoff_factor * readout_std,\n",
    "            b=cutoff_factor * readout_std,\n",
    "        )\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92941df8-cf61-4020-a2a1-db87ad2c3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELU1(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from `NeuralPredictors <https://github.com/sinzlab/neuralpredictors/blob/main/neuralpredictors/layers/activations.py>`__.\n",
    "    \n",
    "    Elu activation function shifted by 1 to ensure that the\n",
    "    output stays positive. That is:\n",
    "    Elu1(x) = Elu(x) + 1\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x, inplace=False, eps=0.0):\n",
    "        return F.elu(x, inplace=inplace) + 1.0 + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e66573a-c54e-42ea-bb06-1ae0f966efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MouseHieraSmall(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 dls,\n",
    "                 t=16,\n",
    "                 dim=512,\n",
    "                 dim_head=32,\n",
    "                 num_heads=4):\n",
    "        super().__init__()\n",
    "        self.backbone=backbone\n",
    "        self.num_heads=num_heads\n",
    "        self.dim_head=dim_head\n",
    "        self.wk = nn.Linear(dim, dim_head * num_heads, bias=False)\n",
    "        self.wv = nn.Linear(dim, dim_head * num_heads, bias=False)\n",
    "        self.neuron_proj = nn.Linear(dim_head * num_heads, t, bias=False)\n",
    "        self.readout = nn.ModuleDict()\n",
    "        self.activation = ELU1()\n",
    "        for k, v in dls.loaders.items():\n",
    "            n_neurons = next(iter(v))[\"responses\"].shape[-1]\n",
    "            self.readout[k] = IndexedLinearReadout(n_neurons, in_features=dim_head*num_heads, out_features=1)\n",
    "    \n",
    "    def forward(self, x, key):\n",
    "        x = self.backbone(x, return_intermediates=True)[1][-1]\n",
    "        b, t, h, w, d = x.shape\n",
    "        seq_len = t*h*w\n",
    "        x = x.view(b, -1, d)\n",
    "        k, v = self.wk(x), self.wv(x)\n",
    "        q = self.readout[key].query\n",
    "        n = q.shape[2]\n",
    "        q = q.tile(b, 1, 1, 1)\n",
    "        k = k.view(b, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
    "        v = v.view(b, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
    "        with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n",
    "            o = F.scaled_dot_product_attention(q, k, v)\n",
    "        o = o.transpose(1,2).contiguous().view(b, -1, self.num_heads * self.dim_head)\n",
    "        o = self.neuron_proj(o) # (B, N, D) -> (B, N, t)\n",
    "        o = o + r.readout[key].bias\n",
    "        o = F.elu(o, inplace=True) + 1.0\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "978b704d-4235-49a8-873a-f649abd63307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[-1][-1].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63645b3c-a1dd-4f11-96e0-123c75278889",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_dim = features[-1][-1].shape[-1]\n",
    "r = MouseHieraSmall(tiny_hiera, train_dl, 16, backbone_dim, dim_head=32,num_heads=4)\n",
    "#opt_r = torch.compile(r, )\n",
    "opt_r = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "601898c6-8526-4341-b2b3-6ab56c228475",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "opt_r.backbone.to(torch.bfloat16).cuda();\n",
    "opt_r = torch.compile(opt_r, mode=\"max-autotune\").cuda().to(torch.bfloat16).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "168ad656-3bb1-45ff-a623-66ea4f135ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1016 15:30:48.688000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/fb/cfbey7guqahp2dwzldohl2tgf6coebtbchdowr6uwoeeau2xml5h.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:30:48.690000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/6w/c6wpvtj4slovobmjyin6zjrfwj7t7detj6niciamr7lzdq3tnkxe.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:30:48.692000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/rx/crxxhezmdfz7ia7s3s5gsquxzpyz6jwu6wpmiaqf63ghlh26g63z.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:30:49.973000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:30:50.341000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:30:50.950000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE addmm(147456x1024, 147456x256, 256x1024)\n",
      "  triton_mm_56 0.5790 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_62 0.5843 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_55 0.5960 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  bias_addmm 0.5984 ms 96.8% \n",
      "  triton_mm_61 0.6006 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_54 0.6037 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_59 0.6052 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_58 0.6130 ms 94.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_60 0.6244 ms 92.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_51 0.6380 ms 90.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2624 seconds and 0.0072 seconds precompiling\n",
      "E1016 15:30:52.313000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ix/cixksy7ehlrxxwuq7xnlrzbi5znvp2ya4btbpqhbu3r4y2724ovx.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:30:52.314000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/co/ccopqsarrdpuciyrpu5emnavwdzpuo27lrukx37sbpif4x57pxiq.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:30:52.316000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ln/cln5k5ol2p5455pl2gnyx6yahhnk6u5o3h2rr2q3fwnvizccscwk.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:30:53.572000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:30:53.937000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:30:54.539000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE addmm(36864x2048, 36864x512, 512x2048)\n",
      "  triton_mm_415 0.4185 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_414 0.4205 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  bias_addmm 0.4732 ms 88.4% \n",
      "  triton_mm_409 0.4781 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_413 0.4841 ms 86.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_411 0.4890 ms 85.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_407 0.4938 ms 84.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_412 0.5180 ms 80.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_408 0.5198 ms 80.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_404 0.5660 ms 73.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2276 seconds and 0.0063 seconds precompiling\n",
      "E1016 15:30:56.777000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/o3/co3h5sprdce7hx2lrpsammoqrvvv6pmqlnbcu3clwjbit22fihn2.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:30:56.779000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ab/cabqn6dc4qga5npd6oyq4q2lo7n6l2tcfhzzb4wjm7axballeqzr.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:30:56.780000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/q6/cq6ihm4clo5suy4shksc3ia37etwxu4v263ce2s6lux5ngxaruho.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:30:57.901000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:30:58.267000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:30:58.867000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x2048, 2048x512)\n",
      "  triton_mm_1127 0.4070 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1126 0.4193 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.4268 ms 95.4% \n",
      "  triton_mm_1121 0.4645 ms 87.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1123 0.4759 ms 85.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1119 0.4846 ms 84.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1124 0.4949 ms 82.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1120 0.5030 ms 80.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1125 0.5186 ms 78.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_1117 0.5418 ms 75.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0915 seconds and 0.0059 seconds precompiling\n",
      "AUTOTUNE mm(245472x128, 128x16)\n",
      "  triton_mm_1177 0.1239 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_1171 0.1244 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_1168 0.1247 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  mm 0.1265 ms 97.9% \n",
      "  triton_mm_1182 0.1285 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_1181 0.1297 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1174 0.1298 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1170 0.1468 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_1169 0.1477 ms 83.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_1180 0.1510 ms 82.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8022 seconds and 0.0019 seconds precompiling\n",
      "AUTOTUNE convolution(32x1x16x72x128, 256x1x3x8x8)\n",
      "  triton_convolution3d_1 1.0164 ms 100.0% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_D=3, KERNEL_H=8, KERNEL_W=8, PADDING_D=1, PADDING_H=3, PADDING_W=3, STRIDE_D=2, STRIDE_H=4, STRIDE_W=4, UNROLL=False, num_stages=2, num_warps=4\n",
      "  triton_convolution3d_6 1.0600 ms 95.9% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_D=3, KERNEL_H=8, KERNEL_W=8, PADDING_D=1, PADDING_H=3, PADDING_W=3, STRIDE_D=2, STRIDE_H=4, STRIDE_W=4, UNROLL=False, num_stages=2, num_warps=8\n",
      "  triton_convolution3d_4 1.4462 ms 70.3% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_D=3, KERNEL_H=8, KERNEL_W=8, PADDING_D=1, PADDING_H=3, PADDING_W=3, STRIDE_D=2, STRIDE_H=4, STRIDE_W=4, UNROLL=False, num_stages=2, num_warps=4\n",
      "  triton_convolution3d_3 1.5208 ms 66.8% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_D=3, KERNEL_H=8, KERNEL_W=8, PADDING_D=1, PADDING_H=3, PADDING_W=3, STRIDE_D=2, STRIDE_H=4, STRIDE_W=4, UNROLL=False, num_stages=2, num_warps=8\n",
      "  triton_convolution3d_2 1.5679 ms 64.8% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=1024, BLOCK_N=16, GROUPS=1, KERNEL_D=3, KERNEL_H=8, KERNEL_W=8, PADDING_D=1, PADDING_H=3, PADDING_W=3, STRIDE_D=2, STRIDE_H=4, STRIDE_W=4, UNROLL=False, num_stages=1, num_warps=8\n",
      "  triton_convolution3d_5 1.8060 ms 56.3% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_D=3, KERNEL_H=8, KERNEL_W=8, PADDING_D=1, PADDING_H=3, PADDING_W=3, STRIDE_D=2, STRIDE_H=4, STRIDE_W=4, UNROLL=False, num_stages=2, num_warps=8\n",
      "  triton_convolution3d_0 2.0131 ms 50.5% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_D=3, KERNEL_H=8, KERNEL_W=8, PADDING_D=1, PADDING_H=3, PADDING_W=3, STRIDE_D=2, STRIDE_H=4, STRIDE_W=4, UNROLL=False, num_stages=2, num_warps=4\n",
      "  convolution 2.4589 ms 41.3% \n",
      "SingleProcess AUTOTUNE benchmarking takes 1.0511 seconds and 0.0014 seconds precompiling\n",
      "E1016 15:31:04.172000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/cl/cclcngcs6exdk4dtcv4w2ssyv5mon2gnhcmyfyb626gs7faxpllm.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:31:04.174000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ax/cax27bp44as3xmg3brwtlqii27zldks7q3yyg4xcvoxdopoqfg5t.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:31:04.175000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/xu/cxukfnhnjul324o3jkcxcprdx2ptk5dqik3j6fldap6sxuva6i5x.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "W1016 15:31:05.422000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:05.784000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:06.382000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE addmm(147456x768, 147456x256, 256x768)\n",
      "  triton_mm_18 0.4601 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_24 0.4648 ms 99.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_17 0.4733 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_21 0.4823 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_23 0.4837 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_16 0.4852 ms 94.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_20 0.4917 ms 93.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  bias_addmm 0.4935 ms 93.2% \n",
      "  triton_mm_13 0.5005 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_14 0.5192 ms 88.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2107 seconds and 0.0060 seconds precompiling\n",
      "E1016 15:31:06.389000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/3a/c3airaav7sapw5xobyvgwbbzcqu63i4ogalpensoi5ngjngpbm64.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:31:06.390000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/gk/cgkv2z4spz6xnqzdbnvcs52juoqz6o2sak434zmj5ikql6bl2wi3.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:31:06.392000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/tj/ctjh4pywouncrxa72uhgd25dvzz33mcpduivcwdkeb2afnl2wnk4.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:31:07.432000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:07.779000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:08.353000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(147456x256, 256x256)\n",
      "  triton_mm_37 0.2381 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_33 0.2391 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_43 0.2395 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_32 0.2452 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_41 0.2461 ms 96.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_36 0.2532 ms 94.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.2542 ms 93.7% \n",
      "  triton_mm_40 0.2560 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_28 0.2598 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_42 0.2634 ms 90.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9662 seconds and 0.0053 seconds precompiling\n",
      "E1016 15:31:08.361000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/3e/c3en6jxvz3dtedlhcri4ty6cc6lr36ypoxyfn2q4os7tql26z7om.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:31:08.362000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/nv/cnvmnemc6qgez3fyxzjp6w4jdv5xqb62vdpyjbgzh5xk6rzurvft.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:31:08.363000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/db/cdbu5g64777drao7lifkzd4tu3bwxl3y2mggnbeirchla3uinbpl.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:31:09.493000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:09.859000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:10.467000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(147456x1024, 1024x256)\n",
      "  triton_mm_71 0.6592 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_75 0.6671 ms 98.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_81 0.6741 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_70 0.6798 ms 97.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_79 0.6845 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_73 0.6891 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_77 0.6895 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_80 0.6930 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.6968 ms 94.6% \n",
      "  triton_mm_74 0.7439 ms 88.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1057 seconds and 0.0075 seconds precompiling\n",
      "E1016 15:31:10.484000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/5i/c5icbn5pdvjyol5zq53pkapfqst4qgbiv5x3bklfhtpoikhshpau.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:31:10.485000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/sk/cskx7o25eardp27rdiyzp2fqjizhob3q7fnhup6andax2ra4jrrw.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:31:10.486000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ln/clnynl72fscmoiuood3dvfuix74vjmzltjkfgfx2odacajfhcy7e.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:31:11.698000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:12.052000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:12.639000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE addmm(147456x512, 147456x256, 256x512)\n",
      "  triton_mm_322 0.3484 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_318 0.3495 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_328 0.3517 ms 99.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_317 0.3612 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_321 0.3628 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_326 0.3631 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_325 0.3667 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_327 0.3751 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_320 0.3755 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_324 0.3791 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1559 seconds and 0.0063 seconds precompiling\n",
      "E1016 15:31:12.647000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/aa/caaabujc4mfpx3scws7ln75ubvjlzie2lcfnp5nhirn5qxg64d6x.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:31:12.648000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/wi/cwi6k5rhcldwqqkichitz2mf5syklznhnf3u5m4ych7zaqj3tgjc.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:31:12.649000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/gq/cgqq2hogtbstuweh4cj5ex4wfpjyl55jxrmueqxxawalirboeg3t.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:31:13.977000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:14.349000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:14.967000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE addmm(147456x1536, 147456x256, 256x1536)\n",
      "  triton_mm_347 0.8124 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_346 0.8390 ms 96.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  bias_addmm 0.8428 ms 96.4% \n",
      "  triton_mm_341 0.8454 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_339 0.8551 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_343 0.8674 ms 93.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_344 0.9388 ms 86.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_345 0.9423 ms 86.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_340 0.9724 ms 83.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_336 1.0907 ms 74.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.3220 seconds and 0.0064 seconds precompiling\n",
      "E1016 15:31:14.976000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 122880, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ul/culrzecgta5iohipl2kbrsprz52xhkgrpyyr7izr2pyf2xp3ixzw.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:31:14.977000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 163840, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/wt/cwtd6flueg2t3whkpft32gm2kmjdodvqoipfhzesbc2gkngjy5zs.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "W1016 15:31:16.071000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 163840, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:16.316000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 122880, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE bmm(4608x16x256, 4608x256x64)\n",
      "  bmm 0.6433 ms 100.0% \n",
      "  triton_bmm_361 0.6436 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_356 0.6450 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_351 0.6515 ms 98.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_358 0.6560 ms 98.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_359 0.6592 ms 97.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_355 0.6612 ms 97.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_bmm_353 0.6634 ms 97.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_bmm_350 0.6764 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_bmm_354 0.6831 ms 94.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.4647 seconds and 0.0040 seconds precompiling\n",
      "AUTOTUNE bmm(4608x16x64, 4608x64x256)\n",
      "  triton_bmm_373 0.6321 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_374 0.6323 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  bmm 0.6354 ms 99.5% \n",
      "  triton_bmm_372 0.6358 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_364 0.6393 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_378 0.6421 ms 98.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_bmm_370 0.6443 ms 98.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_369 0.6449 ms 98.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_376 0.6477 ms 97.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_371 0.6525 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1775 seconds and 0.0024 seconds precompiling\n",
      "E1016 15:31:18.626000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ha/chaqfah5tofn5ujoyd4em7wljtnn6k4v66cc26irbkvj2wemodt7.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:31:18.627000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/bd/cbdoq53x22yeatl2tzjhqqi6sgyn2j62pcyw24eeke6klra5c467.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:31:18.628000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/rd/crdq7pq5444h7dtn2p72zlulda3xt6wozjcz2yp4cq5lcwthgamk.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:31:19.653000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:19.986000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:20.537000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x512, 512x512)\n",
      "  triton_mm_390 0.1296 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_396 0.1296 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_389 0.1432 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_393 0.1451 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.1480 ms 87.6% \n",
      "  triton_mm_388 0.1509 ms 85.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_386 0.1514 ms 85.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_395 0.1514 ms 85.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_392 0.1556 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_385 0.1616 ms 80.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9121 seconds and 0.0082 seconds precompiling\n",
      "E1016 15:31:20.548000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ya/cyaltdzo33v5n2abq3calbe35swypjf3vm4iznlbine554cioglo.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:31:20.549000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/tf/ctf7tcxt64fs6lmw3dqrfalvlxvnm5mlxnpg2pqf2j4fucs6o5lk.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:31:20.550000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/hj/chjnjlnikf3ldb7ldggbl3qhdqga5hl7pxrnienpeb46lxypoelu.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:31:21.659000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:22.016000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:22.604000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x512, 512x1536)\n",
      "  triton_mm_453 0.3072 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_452 0.3204 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.3432 ms 89.5% \n",
      "  triton_mm_447 0.3597 ms 85.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_445 0.3692 ms 83.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_449 0.3715 ms 82.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_451 0.3729 ms 82.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_446 0.3863 ms 79.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_450 0.3893 ms 78.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_442 0.4294 ms 71.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0562 seconds and 0.0083 seconds precompiling\n",
      "AUTOTUNE bmm(4608x16x256, 4608x256x16)\n",
      "  triton_bmm_458 0.2859 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=1\n",
      "  triton_bmm_464 0.2860 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=1\n",
      "  triton_bmm_461 0.2873 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=1\n",
      "  triton_bmm_465 0.2875 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=1\n",
      "  triton_bmm_456 0.2876 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=1\n",
      "  triton_bmm_457 0.2918 ms 98.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=1\n",
      "  triton_bmm_463 0.2949 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=1\n",
      "  triton_bmm_462 0.2980 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=1\n",
      "  triton_bmm_460 0.2996 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=1\n",
      "  bmm 0.3184 ms 89.8% \n",
      "SingleProcess AUTOTUNE benchmarking takes 1.3827 seconds and 0.0019 seconds precompiling\n",
      "AUTOTUNE bmm(4608x16x16, 4608x16x256)\n",
      "  triton_bmm_474 0.2425 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_477 0.2425 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_bmm_476 0.2427 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_bmm_475 0.2427 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_472 0.2428 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_468 0.2428 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_471 0.2433 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_470 0.2435 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_bmm_473 0.2436 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_467 0.2518 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.4914 seconds and 0.0031 seconds precompiling\n",
      "E1016 15:31:25.527000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/44/c44uwg5lngnrfc6penpzwd2ohb4yllywf22shn7tq76lx3xnex3j.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:31:25.529000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ac/caczrq77zip3xy3j7kbulhhp2sqsljrvz5glvff4ncx5y3vmilzc.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:31:25.530000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/x4/cx432j7ufgkcko5ewidk7iyijlarfkq6uaavr6qg36mplk7rgm5u.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:31:26.498000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:26.810000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:31:27.332000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x512, 512x128)\n",
      "  triton_mm_1136 0.0880 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1135 0.0899 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_1140 0.0915 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1133 0.0926 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_1146 0.0926 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1130 0.0946 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  mm 0.0973 ms 90.4% \n",
      "  triton_mm_1144 0.1022 ms 86.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_1142 0.1033 ms 85.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1131 0.1040 ms 84.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8071 seconds and 0.0065 seconds precompiling\n"
     ]
    }
   ],
   "source": [
    "k, b = next(iter(train_dl))\n",
    "videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "out = opt_r(videos, k);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac41068c-cad4-4049-9db4-9af771c96ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k, b = next(iter(train_dl))\n",
    "videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).transpose(1,2)\n",
    "responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "out = opt_r(videos, k);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8909f571-fb98-4b6b-8609-2cfb46832edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.PoissonNLLLoss(log_input=False, reduction='mean')\n",
    "opt = Adam(opt_r.parameters(), lr=1e-3, fused=True)\n",
    "import pytorch_warmup as warmup\n",
    "from torch.amp import autocast\n",
    "warmup_scheduler = warmup.UntunedLinearWarmup(opt, )\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, 1e6, eta_min=1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "727f5eb4-9e06-4213-b73c-d39a66b17cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.002501250625313e-07"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb023e-344f-4a4b-bd87-753466da6e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_inductor/cudagraph_trees.py:2345: UserWarning: Unable to hit fast path of CUDAGraphs because of pending, uninvoked backwards. Consider running with torch.no_grad() or using torch.compiler.cudagraph_mark_step_begin() before each model invocation\n",
      "  warnings.warn(\n",
      "E1016 15:34:44.910000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ew/cewkcwvenh43pcad3binwzel7bm3rkylz6fyfeclsdwlbzc5lvoq.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:34:44.912000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/uk/cuktk3kb6i2wcp4reifs4xbrzq437hstdsebztumohlfjzrlsxbx.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:34:44.914000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/uw/cuwjtusfkvtgbptn3er6fbufqce3b5vtoue77h5452d7grzgmpgy.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "W1016 15:34:46.051000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:34:46.420000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:34:47.030000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(147456x256, 256x1024)\n",
      "  triton_mm_2939 0.5793 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2945 0.5810 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2938 0.5907 ms 98.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2944 0.5946 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2937 0.5947 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2942 0.5951 ms 97.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.5956 ms 97.3% \n",
      "  triton_mm_2941 0.6039 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2934 0.6061 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_2943 0.6075 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1218 seconds and 0.0077 seconds precompiling\n",
      "E1016 15:34:48.693000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/4q/c4qpg7cb6k3mef46ijxmjwopzxp2kh4tmetm5iw7ufhjd6dfnw4j.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:34:48.697000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/qk/cqkfyvtkjud7sioszsytlqqyndctkuwbi2j4lhmpqdjobk5sbol7.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:34:48.698000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ek/ceka6x64cp4pebokiq7wq6o67xe6g7pjxwkn6qhqtfvtqsce7p5f.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:34:49.820000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:34:50.183000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:34:50.779000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x512, 512x2048)\n",
      "  triton_mm_1308 0.3991 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1309 0.4043 ms 98.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.4499 ms 88.7% \n",
      "  triton_mm_1307 0.4565 ms 87.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_1303 0.4662 ms 85.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1301 0.4670 ms 85.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1305 0.4765 ms 83.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1306 0.4890 ms 81.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1302 0.4966 ms 80.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1298 0.5454 ms 73.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0862 seconds and 0.0099 seconds precompiling\n",
      "AUTOTUNE bmm(4608x16x64, 4608x64x256)\n",
      "  triton_bmm_2846 0.6311 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_2847 0.6313 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_2851 0.6341 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_bmm_2842 0.6344 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_2843 0.6350 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_2839 0.6428 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_bmm_2836 0.6431 ms 98.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_bmm_2845 0.6436 ms 98.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_2837 0.6450 ms 97.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_2838 0.6455 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1927 seconds and 0.0029 seconds precompiling\n",
      "E1016 15:34:56.238000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ah/cahqyj4oghpru3bb7d2jvxz6ohoynuqnbglo6ncnlu7m6vc6llmz.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:34:58.280000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x128, 128x512)\n",
      "  triton_mm_1285 0.0744 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_1284 0.0762 ms 97.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1290 0.0766 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1280 0.0778 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1281 0.0779 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_1279 0.0785 ms 94.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  mm 0.0785 ms 94.7% \n",
      "  triton_mm_1283 0.0786 ms 94.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1288 0.0795 ms 93.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_1287 0.0815 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0462 seconds and 0.0041 seconds precompiling\n",
      "E1016 15:34:59.440000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/fm/cfmcsawjqlqiyxbrszwh4f5rzq4xob3g2lv4fryhzeicrqsuqofy.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:35:01.069000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(16x245472, 245472x128)\n",
      "  mm 0.1460 ms 100.0% \n",
      "  triton_mm_1187 0.3669 ms 39.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_1191 0.4931 ms 29.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_1186 0.8152 ms 17.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_1185 0.8504 ms 17.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_1199 0.8827 ms 16.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_1190 0.9609 ms 15.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1197 1.0834 ms 13.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_1184 1.1642 ms 12.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_1194 1.1862 ms 12.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1404 seconds and 0.0047 seconds precompiling\n",
      "AUTOTUNE mm(245472x16, 16x128)\n",
      "  triton_mm_1214 0.1064 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1208 0.1067 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1210 0.1067 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_1209 0.1068 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.1075 ms 99.0% \n",
      "  triton_mm_1207 0.1088 ms 97.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_1211 0.1088 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1206 0.1088 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1205 0.1089 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_1212 0.1090 ms 97.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8164 seconds and 0.0034 seconds precompiling\n",
      "E1016 15:35:03.408000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/l7/cl7wlvzovl4ijavjafezh5mtwo55g5gt26ybrmizx737buqft4r3.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:03.411000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/3v/c3vpu4kkezxbtxzzscwevllpxdpfh7iurynq7lq6dnqachjjbjae.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:03.412000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/7d/c7d52k6bd6ogexvmlzy2jce4n4nehcbxq7egqlngtm7dvzbavfd2.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:35:04.433000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:04.784000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:05.381000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(128x36864, 36864x512)\n",
      "  mm 0.1019 ms 100.0% \n",
      "  triton_mm_1220 0.1173 ms 86.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_1218 0.1907 ms 53.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_1219 0.1910 ms 53.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_1223 0.2211 ms 46.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1217 0.2255 ms 45.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_1230 0.2685 ms 37.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1226 0.2755 ms 37.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1227 0.2999 ms 34.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1225 0.3461 ms 29.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9726 seconds and 0.0085 seconds precompiling\n",
      "E1016 15:35:05.394000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/kf/ckfoarlmlq2samyllav73fol33khcbz5bpzo3vrkpxhr5eobptqr.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:05.395000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ps/cps2hbkiqmiayrvmiq3lu42rwmu5pmavnzri325uzzqxyvclava6.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:05.397000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/4s/c4ssc27bvgroj3yrsnpgh6znj6eap4b6vke5ljok32vgjm3z6usq.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:35:06.526000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:06.889000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:07.493000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(512x36864, 36864x2048)\n",
      "  mm 0.3713 ms 100.0% \n",
      "  triton_mm_1322 0.4673 ms 79.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1321 0.4790 ms 77.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1325 0.4832 ms 76.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1320 0.4961 ms 74.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1324 0.5023 ms 73.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1328 0.5215 ms 71.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1318 0.5417 ms 68.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1327 0.5473 ms 67.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1317 0.6629 ms 56.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0977 seconds and 0.0089 seconds precompiling\n",
      "E1016 15:35:07.502000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/6p/c6pfgdckbidjr2o7vp4inqxv4rmtoabffhy5aagnwaccdkog7j6w.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:07.503000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/of/cofvzsgpvwjfk46vcy3zp4bi4fbbmdiqcx7o5cnnblzeqmfhm56z.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:07.504000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/6v/c6v4n6tfly3525jb2hrdgheyfkifiuvezqoqnwru52vu6dt57kzv.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:35:08.633000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:08.997000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:09.597000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x2048, 2048x512)\n",
      "  triton_mm_1346 0.4174 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1347 0.4210 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.4238 ms 98.5% \n",
      "  triton_mm_1341 0.4641 ms 89.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1339 0.4660 ms 89.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1343 0.4762 ms 87.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1340 0.4881 ms 85.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1344 0.4965 ms 84.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1345 0.5254 ms 79.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_1337 0.5457 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0957 seconds and 0.0081 seconds precompiling\n",
      "E1016 15:35:09.606000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ex/cexni3ips6j4mx4u7rsom73vw3i5nb4r5oj7jerag6fx435kyhrr.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:09.607000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/sw/cswgytwlqcdagcetwx2qbvcs2hqaojcm4j3p5fqhrz5ecye6pznr.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:09.608000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ou/couxg5u2pq6vj73f37665cis4dmnnegahmdr7ruaffykqragpjzf.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:35:10.740000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:11.099000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:11.703000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(2048x36864, 36864x512)\n",
      "  mm 0.3779 ms 100.0% \n",
      "  triton_mm_1359 0.4783 ms 79.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1363 0.4794 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1360 0.4844 ms 78.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1362 0.4952 ms 76.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1358 0.5135 ms 73.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1366 0.5327 ms 70.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1356 0.5535 ms 68.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1365 0.5566 ms 67.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1355 0.6551 ms 57.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0972 seconds and 0.0078 seconds precompiling\n",
      "E1016 15:35:11.712000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/hk/chkskabecpzbooy5u6vnqbivx4fbskcgomfr2l6l24zalinm7dzq.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:11.713000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/wl/cwlhpxxdlobe7p5n3vnimiv3wbdyoin3tj7kjakzvixo537vkpg3.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:11.714000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/hz/chzfokc5imy6hapkcmxx22zk33skjoqpc5auv3rtqlxdqdbfsmho.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:35:12.738000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:13.072000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:13.627000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x512, 512x512)\n",
      "  triton_mm_1379 0.1289 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1385 0.1297 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1378 0.1379 ms 93.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1382 0.1428 ms 90.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1384 0.1472 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.1483 ms 86.9% \n",
      "  triton_mm_1377 0.1493 ms 86.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1375 0.1518 ms 84.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1381 0.1552 ms 83.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1374 0.1632 ms 78.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9164 seconds and 0.0071 seconds precompiling\n",
      "E1016 15:35:13.636000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/n3/cn35mnvmxduybq4ybljanwj4b7xlai5vots4xxk7okpo43xf3ij7.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:13.637000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/l2/cl2xz35mrnpr3vayuawwurge6sjzdeswkherr6ka6yxvtz3otrtc.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:13.637000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/4e/c4e3smxj2cpveh6bziz3adpnl2tqs5j44424khsgq67fug3ch2op.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "W1016 15:35:14.671000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:15.022000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:15.620000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(512x36864, 36864x512)\n",
      "  triton_mm_1391 0.1882 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  mm 0.2094 ms 89.9% \n",
      "  triton_mm_1389 0.2462 ms 76.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_1390 0.2463 ms 76.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_1394 0.2636 ms 71.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1388 0.2748 ms 68.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_1401 0.3011 ms 62.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1397 0.3025 ms 62.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1398 0.3289 ms 57.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1396 0.3768 ms 49.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9874 seconds and 0.0073 seconds precompiling\n",
      "AUTOTUNE bmm(4608x16x16, 4608x16x256)\n",
      "  triton_bmm_1412 0.2399 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_1414 0.2400 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_1413 0.2416 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_1416 0.2417 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_bmm_1417 0.2420 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_bmm_1411 0.2424 ms 99.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_1415 0.2425 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_1410 0.2426 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_bmm_1408 0.2432 ms 98.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  bmm 0.2468 ms 97.2% \n",
      "SingleProcess AUTOTUNE benchmarking takes 1.5153 seconds and 0.0039 seconds precompiling\n",
      "AUTOTUNE bmm(4608x16x256, 4608x256x16)\n",
      "  triton_bmm_1421 0.2874 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=1\n",
      "  triton_bmm_1427 0.2891 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=1\n",
      "  triton_bmm_1428 0.2907 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=1\n",
      "  triton_bmm_1424 0.2919 ms 98.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=1\n",
      "  triton_bmm_1419 0.2927 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=1\n",
      "  triton_bmm_1420 0.3042 ms 94.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=1\n",
      "  triton_bmm_1426 0.3096 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=1\n",
      "  triton_bmm_1425 0.3162 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=1\n",
      "  triton_bmm_1423 0.3181 ms 90.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=1\n",
      "  triton_bmm_1422 0.3242 ms 88.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=1\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.3872 seconds and 0.0026 seconds precompiling\n",
      "AUTOTUNE bmm(4608x256x16, 4608x16x16)\n",
      "  triton_bmm_1436 0.2399 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_1437 0.2418 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_1439 0.2419 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_bmm_1438 0.2420 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_bmm_1435 0.2437 ms 98.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_1433 0.2439 ms 98.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_bmm_1434 0.2441 ms 98.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_1432 0.2443 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  bmm 0.2458 ms 97.6% \n",
      "  triton_bmm_1430 0.2515 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.3850 seconds and 0.0026 seconds precompiling\n",
      "AUTOTUNE bmm(4608x16x16, 4608x16x256)\n",
      "  triton_bmm_1446 0.2403 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_1448 0.2403 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_1451 0.2415 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_bmm_1450 0.2418 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_bmm_1447 0.2418 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_1449 0.2438 ms 98.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_1442 0.2439 ms 98.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_1444 0.2439 ms 98.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_bmm_1445 0.2440 ms 98.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_1443 0.2450 ms 98.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.5061 seconds and 0.0029 seconds precompiling\n",
      "E1016 15:35:21.439000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/hh/chhtcxzemlwxbkq72jij6gei5gdezdyd3hgisuvqukrypornwxbj.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:21.441000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/kb/ckbmnte5libpxtpf6nkld4nd4e2d5qyqlxq2s2v7z4mgiaxl2gbv.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:21.442000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ui/cuivviu6mgxo6dwzqnkiepjj5asoj7gy3ktaryxtywiai7bauntb.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "W1016 15:35:22.548000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:22.907000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:23.499000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(36864x1536, 1536x512)\n",
      "  triton_mm_1468 0.3223 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1469 0.3237 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.3306 ms 97.5% \n",
      "  triton_mm_1461 0.3541 ms 91.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1463 0.3548 ms 90.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1465 0.3639 ms 88.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1462 0.3750 ms 85.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1466 0.3865 ms 83.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1467 0.4104 ms 78.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_1459 0.4213 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0606 seconds and 0.0083 seconds precompiling\n",
      "E1016 15:35:23.508000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ar/car4erqagxef7o2umbszehkeek2225o775kwvubnnddns2x75vgb.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:23.509000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/fy/cfyb7qaww3srd3j3rvqjp67fpbanpz722ysn2u73sodnuw4mq7la.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:23.510000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/je/cje76l5uturjtxfgbfdp52y3kdg4ya4du6vcwqgcfsqclvozzgpg.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "W1016 15:35:24.624000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:24.980000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:25.586000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(1536x36864, 36864x512)\n",
      "  mm 0.3172 ms 100.0% \n",
      "  triton_mm_1485 0.4016 ms 79.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1481 0.4073 ms 77.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_1482 0.4075 ms 77.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1478 0.4365 ms 72.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_1484 0.4448 ms 71.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1480 0.4557 ms 69.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1488 0.5137 ms 61.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1487 0.5388 ms 58.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_1475 0.6040 ms 52.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0799 seconds and 0.0076 seconds precompiling\n",
      "AUTOTUNE bmm(4608x64x16, 4608x16x256)\n",
      "  triton_bmm_2804 0.5988 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_2798 0.5990 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_bmm_2794 0.6025 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_bmm_2802 0.6030 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_2803 0.6031 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_2797 0.6034 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_bmm_2800 0.6034 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_2801 0.6034 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_2799 0.6036 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_2806 0.6038 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9567 seconds and 0.0024 seconds precompiling\n",
      "E1016 15:35:27.657000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 163840, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/nj/cnjamafvnmetgspkxccqnkdndkf2cloxuz6o4xrirboc6siptath.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:27.658000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 122880, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/6v/c6vc6rbska22ro2q6xtmwurs42brtwrdnp7olfih4jvausanr44e.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:35:28.759000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 163840, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:29.008000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 122880, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE bmm(4608x16x256, 4608x256x64)\n",
      "  triton_bmm_2811 0.6462 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_bmm_2819 0.6533 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_2814 0.6562 ms 98.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_2808 0.6608 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  bmm 0.6635 ms 97.4% \n",
      "  triton_bmm_2810 0.6980 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_bmm_2809 0.7026 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_bmm_2817 0.7182 ms 90.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_2816 0.7194 ms 89.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_2813 0.7218 ms 89.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.4774 seconds and 0.0048 seconds precompiling\n",
      "AUTOTUNE bmm(4608x256x16, 4608x16x64)\n",
      "  bmm 0.5972 ms 100.0% \n",
      "  triton_bmm_2826 0.5985 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_bmm_2829 0.5988 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_2831 0.6003 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_bmm_2833 0.6016 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_bmm_2834 0.6019 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_bmm_2832 0.6021 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_bmm_2825 0.6037 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_bmm_2830 0.6038 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_bmm_2827 0.6040 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9592 seconds and 0.0029 seconds precompiling\n",
      "E1016 15:35:31.105000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/t2/ct232a44fgeprga7w7nok4jdxeqlwgb3nfirrk5trwqgiya3dwa2.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:31.107000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/kp/ckprgppsr225w27wgdgel6wu62x3uorskzrpnlyihus4rlucmkgz.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:31.108000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ag/cagncqgudf3iedgaia2xzxmqfdmtwa6qvnfabhbu4p4ntrlcdfoo.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:35:32.279000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:32.658000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:33.284000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(147456x1536, 1536x256)\n",
      "  triton_mm_2863 0.9008 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2869 0.9190 ms 98.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2859 0.9200 ms 97.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_2861 0.9273 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2865 0.9292 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2858 0.9327 ms 96.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_2868 0.9364 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2867 0.9465 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  mm 0.9503 ms 94.8% \n",
      "  triton_mm_2862 1.0352 ms 87.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1808 seconds and 0.0077 seconds precompiling\n",
      "E1016 15:35:33.294000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/k7/ck7wyjy2glnchoilz52usjwjndp22xw334fjsvqh3rdyhow3xjqz.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:33.295000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/za/czayk2vqk75ldw3pat554e3vmdfls3ryfcjpfaomon3tfhrxv7id.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:33.296000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/xu/cxuopt446z4arkwy55nrwzt3fpmnsvuibxy3vkjgh3n7ergzmqp3.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:35:34.496000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:34.882000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:35.553000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(1536x147456, 147456x256)\n",
      "  mm 0.8501 ms 100.0% \n",
      "  triton_mm_2878 1.0300 ms 82.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_2885 1.1373 ms 74.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2881 1.1571 ms 73.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2882 1.2663 ms 67.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2884 1.4450 ms 58.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2874 1.4473 ms 58.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_2880 1.4618 ms 58.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2872 1.4824 ms 57.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_2873 1.5021 ms 56.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2626 seconds and 0.0067 seconds precompiling\n",
      "E1016 15:35:35.564000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ck/cckon5juygc6potfoffjkbzghjxm4xh4vdbew6vy7zfujigh6c4b.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:35.566000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/nq/cnqlunlb3ql2km3shur35dpkovmmemid5fhikusrjqbmqs3r4q4f.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:35.566000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/vc/cvc7mvv5qdlly2rqekvt3weui2ruhi6gx6qbffe5ylgfgae2zznn.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:35:36.656000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:37.013000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:37.604000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(147456x512, 512x256)\n",
      "  triton_mm_2901 0.4051 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2907 0.4067 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2897 0.4097 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_2905 0.4166 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  mm 0.4235 ms 95.6% \n",
      "  triton_mm_2896 0.4281 ms 94.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_2900 0.4449 ms 91.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2892 0.4515 ms 89.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_2904 0.4553 ms 89.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2899 0.4607 ms 87.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0420 seconds and 0.0072 seconds precompiling\n",
      "E1016 15:35:37.614000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ab/cabvao6qs75ndbvb44xgqrxwlytfkxfh6ztkhqtdbcrxcbaxcluw.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:37.615000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/zm/czmzllcw47e3dxvpiydajzug47du3jqigwivq2rgugwerjpifrcb.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:37.616000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ie/cieqezavhvgqozr4hd3hooxutixcrgialkhasmselau4g7imnbai.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:35:38.779000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:39.166000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:39.834000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(512x147456, 147456x256)\n",
      "  mm 0.4330 ms 100.0% \n",
      "  triton_mm_2913 0.4604 ms 94.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_2911 0.7025 ms 61.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_2912 0.7066 ms 61.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_2916 0.8438 ms 51.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_2910 0.8603 ms 50.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_2923 1.0556 ms 41.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2919 1.0574 ms 40.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2920 1.1653 ms 37.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2922 1.3160 ms 32.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2234 seconds and 0.0074 seconds precompiling\n",
      "E1016 15:35:39.847000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/g5/cg5kjij3dmkur333pi7pxokwzvqnemhz5vuzlgedn22ucqvwjbdg.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:39.848000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/3d/c3ds2xycrws7zwskfnq5e33oio6iwshb5aftekbtupfkf633c4az.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:39.849000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/di/cdigkqp6qe24rejhvbivs7xjtjeo47qhxuuxdy6pjc6im7sg4pbt.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:35:41.022000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:41.411000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:42.081000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(256x147456, 147456x1024)\n",
      "  mm 0.6420 ms 100.0% \n",
      "  triton_mm_2951 0.7560 ms 84.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_2950 0.8771 ms 73.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_2949 0.8823 ms 72.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_2954 0.8999 ms 71.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_2948 1.0124 ms 63.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_2961 1.0906 ms 58.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2957 1.0977 ms 58.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2958 1.1903 ms 53.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2956 1.3595 ms 47.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2365 seconds and 0.0073 seconds precompiling\n",
      "E1016 15:35:42.092000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/xr/cxrhy7sfs6rhaxceamazjaay4s6fw4jjj2z7eb25j5loirgnzxrd.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:42.093000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/rc/crchsdibfdrhqv7zmakakmavlhqrimu4gc5debrldjricdprinvf.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:42.095000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/zi/czidceybx4ha4jhiek7lcnk6qf57c4bpdiaquoenu5cblbhodm5u.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:35:43.224000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:43.591000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:44.201000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(147456x1024, 1024x256)\n",
      "  triton_mm_2973 0.6596 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_2977 0.6667 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2983 0.6775 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2981 0.6776 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_2972 0.6815 ms 96.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_2982 0.6921 ms 95.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2975 0.6931 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2979 0.6933 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.7029 ms 93.8% \n",
      "  triton_mm_2976 0.7320 ms 90.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1125 seconds and 0.0070 seconds precompiling\n",
      "E1016 15:35:44.212000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/fn/cfna5himnzolh7lvzcrstlvdmm3c42borxzxxciapuclxszdw5zq.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:44.213000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/xu/cxuhvfbwmgzm37umrwajznlpjkojxizlir25vy5xokb77wf4dtnp.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:44.214000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/yw/cywnjyzrs7bzpvxgcc3cdr3f6wnygecqdv3fvq3lrvzzlgvsgh4y.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:35:45.385000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:45.773000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:46.442000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(1024x147456, 147456x256)\n",
      "  mm 0.6415 ms 100.0% \n",
      "  triton_mm_2989 0.7689 ms 83.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_2988 0.8732 ms 73.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_2987 0.8810 ms 72.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_2992 0.9257 ms 69.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_2986 1.0177 ms 63.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_2999 1.0937 ms 58.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2995 1.1004 ms 58.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_2996 1.2092 ms 53.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_2998 1.3732 ms 46.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2333 seconds and 0.0066 seconds precompiling\n",
      "E1016 15:35:46.453000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ya/cyavwpwifog3xfglkmde53rfppsohbabx7sornhooy2ii4m6byjq.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:46.454000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/5q/c5qwluohylhfksxcns5fpp4ih3vece2emzvbrwqcokbftiaeobzs.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:46.455000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/ox/coxckqp2fer5j2lktozcmw3u6bf4jx3ny5sryjmdbu4s4o6cw4zm.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "W1016 15:35:47.504000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:47.853000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:48.431000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(147456x256, 256x256)\n",
      "  triton_mm_3011 0.2392 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_3015 0.2392 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_3021 0.2404 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_3019 0.2455 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_3010 0.2461 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_3014 0.2495 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_3006 0.2510 ms 95.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_3018 0.2529 ms 94.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.2545 ms 94.0% \n",
      "  triton_mm_3013 0.2616 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9826 seconds and 0.0064 seconds precompiling\n",
      "E1016 15:35:48.443000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/4u/c4un4zzojgtiaannuywc544iahi76cilxiu3sqxiesrlzjhodxo7.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:48.444000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/zq/czqcn47v77q6zxxvlddkq2xmtfo2cfcozdh3opowkfvsw2p7ste5.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:48.444000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/so/csoejhqgqmlmplzdyzj3fibvst6e4skfx6omcz7yhsepvsp6vzgp.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "W1016 15:35:49.592000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:49.979000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:50.650000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(256x147456, 147456x256)\n",
      "  mm 0.2941 ms 100.0% \n",
      "  triton_mm_3027 0.4108 ms 71.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_3026 0.6736 ms 43.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_3025 0.6763 ms 43.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_3030 0.8141 ms 36.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_3024 0.8336 ms 35.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_3037 1.0409 ms 28.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_3033 1.0485 ms 28.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_3034 1.1786 ms 25.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_3036 1.3011 ms 22.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2125 seconds and 0.0057 seconds precompiling\n",
      "E1016 15:35:50.663000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/2h/c2hwvvnjhhmv54h62wdv5cqq3r45wmirhgo2rfq6ul7ywcil6uay.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:50.665000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/7w/c7wjym25b474j6tx5j6gxhcp4v2oqs6kco24a5bovkpiddpzbeuv.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "E1016 15:35:50.666000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/eq/ceqajz6hh2zjnzgwhjvd2i25ondcycphuugoezzjwsqrqoq4x2ha.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "W1016 15:35:51.775000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:52.138000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:52.739000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(147456x768, 768x256)\n",
      "  triton_mm_3049 0.5388 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_3053 0.5473 ms 98.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_3059 0.5509 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_3057 0.5561 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_3048 0.5578 ms 96.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  mm 0.5733 ms 94.0% \n",
      "  triton_mm_3058 0.5735 ms 94.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_3052 0.5982 ms 90.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_3056 0.6052 ms 89.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_3051 0.6369 ms 84.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0790 seconds and 0.0064 seconds precompiling\n",
      "E1016 15:35:52.749000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/qh/cqh2i5cdpxkoxip7erbxwquaaz3qlod66zjqwzx2epmrql4sf4sp.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8)\n",
      "E1016 15:35:52.750000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/lx/clxc2eviaxce6xykm4nbssd7w3bmktbzkge3xwqguwdtluu5ffpb.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4)\n",
      "E1016 15:35:52.750000 89844 torch/_inductor/select_algorithm.py:1305] [0/0] Exception out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/z7/cz7lwgaqpmqwh7he3er7xtpzdl5wywq5eooua64wr3ln2it4g3rm.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:35:53.905000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:54.293000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1016 15:35:54.958000 89844 torch/_inductor/select_algorithm.py:1522] [0/0] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(768x147456, 147456x256)\n",
      "  mm 0.5402 ms 100.0% \n",
      "  triton_mm_3065 0.5985 ms 90.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_3063 0.7685 ms 70.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_3064 0.7700 ms 70.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_3068 0.8879 ms 60.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_3062 0.8883 ms 60.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_3075 1.0727 ms 50.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_3071 1.0773 ms 50.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_3072 1.1855 ms 45.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_3074 1.3379 ms 40.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.2146 seconds and 0.0045 seconds precompiling\n",
      "1it [04:13, 253.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.000142230012033236\n",
      "1.000500250122594e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUTOTUNE mm(239840x128, 128x16)\n",
      "  triton_mm_4707 0.1211 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_4713 0.1214 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_4704 0.1227 ms 98.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  mm 0.1237 ms 97.9% \n",
      "  triton_mm_4718 0.1261 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_4717 0.1271 ms 95.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_4710 0.1273 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_4706 0.1439 ms 84.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_4705 0.1441 ms 84.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_4716 0.1465 ms 82.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8089 seconds and 0.0014 seconds precompiling\n",
      "E1016 15:36:51.005000 89844 torch/_inductor/select_algorithm.py:1305] [0/1] Exception out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/5p/c5pgfoqcpibbanfoelw6blvn37a7bplak6t42t6hpzgkajt6hhvn.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:36:52.619000 89844 torch/_inductor/select_algorithm.py:1522] [0/1] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(16x239840, 239840x128)\n",
      "  mm 0.1421 ms 100.0% \n",
      "  triton_mm_4723 0.3588 ms 39.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_4727 0.4819 ms 29.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_4722 0.7990 ms 17.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_4721 0.8262 ms 17.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_4735 0.8633 ms 16.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_4726 0.9395 ms 15.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_4733 1.0484 ms 13.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_4720 1.1409 ms 12.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_4730 1.1567 ms 12.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1200 seconds and 0.0037 seconds precompiling\n",
      "AUTOTUNE mm(239840x16, 16x128)\n",
      "  triton_mm_4744 0.1028 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_4746 0.1028 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_4750 0.1033 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_4745 0.1046 ms 98.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_4748 0.1053 ms 97.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.1061 ms 96.9% \n",
      "  triton_mm_4747 0.1061 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_4742 0.1064 ms 96.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_4743 0.1066 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_4738 0.1067 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8175 seconds and 0.0017 seconds precompiling\n",
      "2it [05:02, 133.04s/it]AUTOTUNE mm(259904x128, 128x16)\n",
      "  triton_mm_8249 0.1308 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_8243 0.1313 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_8240 0.1316 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  mm 0.1329 ms 98.4% \n",
      "  triton_mm_8254 0.1359 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_8246 0.1372 ms 95.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_8253 0.1377 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_8242 0.1565 ms 83.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_8241 0.1573 ms 83.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_8248 0.1608 ms 81.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8137 seconds and 0.0015 seconds precompiling\n",
      "E1016 15:37:38.500000 89844 torch/_inductor/select_algorithm.py:1305] [0/2] Exception out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/xy/cxyuxrdtoai3ljbetpdhadteexes3cztgkjrl7t7moxho3msf4lc.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:37:40.135000 89844 torch/_inductor/select_algorithm.py:1522] [0/2] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(16x259904, 259904x128)\n",
      "  mm 0.1532 ms 100.0% \n",
      "  triton_mm_8259 0.3884 ms 39.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_8263 0.5213 ms 29.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_8258 0.8657 ms 17.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_8257 0.8944 ms 17.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_8271 0.9339 ms 16.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_8262 1.0087 ms 15.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_8269 1.1357 ms 13.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_8256 1.2361 ms 12.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_8266 1.2560 ms 12.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1407 seconds and 0.0053 seconds precompiling\n",
      "AUTOTUNE mm(259904x16, 16x128)\n",
      "  triton_mm_8286 0.1117 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_8282 0.1131 ms 98.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_8280 0.1132 ms 98.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_8281 0.1141 ms 97.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_8283 0.1149 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_8284 0.1153 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.1153 ms 96.9% \n",
      "  triton_mm_8278 0.1156 ms 96.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_8287 0.1157 ms 96.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_8285 0.1158 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8169 seconds and 0.0018 seconds precompiling\n",
      "3it [05:49, 93.96s/it] AUTOTUNE mm(262464x128, 128x16)\n",
      "  triton_mm_11779 0.1321 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_11776 0.1325 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_11785 0.1327 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  mm 0.1354 ms 97.6% \n",
      "  triton_mm_11790 0.1372 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_11782 0.1380 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_11789 0.1385 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_11778 0.1577 ms 83.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_11777 0.1586 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_11788 0.1619 ms 81.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8166 seconds and 0.0013 seconds precompiling\n",
      "E1016 15:38:28.316000 89844 torch/_inductor/select_algorithm.py:1305] [0/3] Exception out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/at/catqekv4i3qsznksegdb7qaluwdmbbyqd5sc6iqqxw6jvwuo334k.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:38:29.947000 89844 torch/_inductor/select_algorithm.py:1522] [0/3] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(16x262464, 262464x128)\n",
      "  mm 0.1546 ms 100.0% \n",
      "  triton_mm_11795 0.3928 ms 39.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_11799 0.5264 ms 29.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_11794 0.8755 ms 17.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_11793 0.9064 ms 17.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_11807 0.9435 ms 16.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_11798 1.0206 ms 15.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_11805 1.1508 ms 13.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_11792 1.2494 ms 12.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_11802 1.2679 ms 12.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1465 seconds and 0.0037 seconds precompiling\n",
      "AUTOTUNE mm(262464x16, 16x128)\n",
      "  triton_mm_11822 0.1127 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_11818 0.1136 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_11816 0.1137 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_11817 0.1148 ms 98.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.1157 ms 97.4% \n",
      "  triton_mm_11820 0.1166 ms 96.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_11821 0.1170 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_11819 0.1172 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_11815 0.1172 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_11813 0.1173 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8201 seconds and 0.0020 seconds precompiling\n",
      "4it [06:39, 76.56s/it]AUTOTUNE mm(238080x128, 128x16)\n",
      "  triton_mm_15315 0.1209 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_15321 0.1213 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_15312 0.1221 ms 99.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  mm 0.1234 ms 98.0% \n",
      "  triton_mm_15326 0.1245 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_15318 0.1265 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_15325 0.1268 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_15314 0.1426 ms 84.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_15313 0.1427 ms 84.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_15324 0.1456 ms 83.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8078 seconds and 0.0015 seconds precompiling\n",
      "E1016 15:39:16.462000 89844 torch/_inductor/select_algorithm.py:1305] [0/4] Exception out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/63/c63pionfmpjcyptql7xydtmp3ryyape5xapyoa3mtz3njp5cmijf.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:39:18.076000 89844 torch/_inductor/select_algorithm.py:1522] [0/4] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(16x238080, 238080x128)\n",
      "  mm 0.1425 ms 100.0% \n",
      "  triton_mm_15331 0.3442 ms 41.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_15335 0.4783 ms 29.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_15330 0.7935 ms 18.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_15329 0.8191 ms 17.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_15343 0.8559 ms 16.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_15334 0.9261 ms 15.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_15341 1.0404 ms 13.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_15328 1.0798 ms 13.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_15338 1.1499 ms 12.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1215 seconds and 0.0036 seconds precompiling\n",
      "AUTOTUNE mm(238080x16, 16x128)\n",
      "  triton_mm_15358 0.1039 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_15352 0.1039 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_15353 0.1039 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_15354 0.1039 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  mm 0.1048 ms 99.1% \n",
      "  triton_mm_15355 0.1052 ms 98.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_15349 0.1061 ms 97.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_15351 0.1061 ms 97.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_15356 0.1063 ms 97.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_15357 0.1066 ms 97.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8224 seconds and 0.0021 seconds precompiling\n",
      "5it [07:36, 69.40s/it]AUTOTUNE mm(253056x128, 128x16)\n",
      "  triton_mm_18857 0.1280 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_18848 0.1284 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_18851 0.1284 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  mm 0.1310 ms 97.7% \n",
      "  triton_mm_18862 0.1332 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_18854 0.1340 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_18861 0.1342 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_18850 0.1516 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_18849 0.1535 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_18860 0.1561 ms 82.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8176 seconds and 0.0013 seconds precompiling\n",
      "E1016 15:40:12.937000 89844 torch/_inductor/select_algorithm.py:1305] [0/5] Exception out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/nj/cnj7pn6ewsus373rarifhv4lyn7chylheao24yabcju7fupljrzk.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:40:14.558000 89844 torch/_inductor/select_algorithm.py:1522] [0/5] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(16x253056, 253056x128)\n",
      "  mm 0.1497 ms 100.0% \n",
      "  triton_mm_18867 0.3657 ms 40.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_18871 0.5082 ms 29.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_18866 0.8412 ms 17.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_18865 0.8704 ms 17.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_18879 0.9094 ms 16.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_18870 0.9825 ms 15.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_18877 1.1044 ms 13.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_18864 1.1439 ms 13.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_18874 1.2215 ms 12.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1324 seconds and 0.0034 seconds precompiling\n",
      "AUTOTUNE mm(253056x16, 16x128)\n",
      "  triton_mm_18888 0.1094 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_18890 0.1095 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_18894 0.1100 ms 99.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_18889 0.1104 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_18891 0.1119 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  mm 0.1120 ms 97.7% \n",
      "  triton_mm_18892 0.1121 ms 97.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_18895 0.1124 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_18893 0.1126 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "  triton_mm_18886 0.1126 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8199 seconds and 0.0019 seconds precompiling\n",
      "6it [08:23, 62.00s/it]AUTOTUNE mm(251616x128, 128x16)\n",
      "  triton_mm_22387 0.1269 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_22393 0.1275 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_22384 0.1280 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  mm 0.1292 ms 98.2% \n",
      "  triton_mm_22398 0.1320 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_22390 0.1326 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_22397 0.1335 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_22386 0.1513 ms 83.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_22385 0.1524 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_22396 0.1554 ms 81.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8127 seconds and 0.0013 seconds precompiling\n",
      "E1016 15:41:01.040000 89844 torch/_inductor/select_algorithm.py:1305] [0/6] Exception out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/r7/cr76ackejrt66diofnr254vqnsvpq4565tsn4zg5whhtowrgzf45.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:41:02.671000 89844 torch/_inductor/select_algorithm.py:1522] [0/6] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(16x251616, 251616x128)\n",
      "  mm 0.1480 ms 100.0% \n",
      "  triton_mm_22403 0.3763 ms 39.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_22407 0.5048 ms 29.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_22402 0.8350 ms 17.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_22401 0.8686 ms 17.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_22415 0.9053 ms 16.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_22406 0.9833 ms 15.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_22413 1.1075 ms 13.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_22400 1.1928 ms 12.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_22410 1.2136 ms 12.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1421 seconds and 0.0037 seconds precompiling\n",
      "AUTOTUNE mm(251616x16, 16x128)\n",
      "  triton_mm_22424 0.1086 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_22426 0.1087 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_22430 0.1094 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_22425 0.1095 ms 99.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.1103 ms 98.5% \n",
      "  triton_mm_22427 0.1112 ms 97.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_22428 0.1113 ms 97.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_22431 0.1118 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_22422 0.1118 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8\n",
      "  triton_mm_22429 0.1118 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8197 seconds and 0.0018 seconds precompiling\n",
      "7it [09:12, 57.51s/it]AUTOTUNE mm(265120x128, 128x16)\n",
      "  triton_mm_25923 0.1343 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_25929 0.1345 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_25920 0.1348 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  mm 0.1371 ms 97.9% \n",
      "  triton_mm_25934 0.1384 ms 97.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_25926 0.1396 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_25933 0.1409 ms 95.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_25922 0.1604 ms 83.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_25921 0.1620 ms 82.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_25932 0.1639 ms 82.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=16, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8143 seconds and 0.0014 seconds precompiling\n",
      "E1016 15:41:50.235000 89844 torch/_inductor/select_algorithm.py:1305] [0/7] Exception out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help. for benchmark choice TritonTemplateCaller(/tmp/torchinductor_root/qd/cqd7yrz5cy744afxsr4ltn45xm6bzimln2eeoczyh3x3vupyiqbw.py, ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4)\n",
      "W1016 15:41:51.873000 89844 torch/_inductor/select_algorithm.py:1522] [0/7] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(16x265120, 265120x128)\n",
      "  mm 0.1554 ms 100.0% \n",
      "  triton_mm_25939 0.3963 ms 39.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_25943 0.5322 ms 29.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_25938 0.8854 ms 17.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2\n",
      "  triton_mm_25937 0.9149 ms 17.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "  triton_mm_25951 0.9536 ms 16.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_25942 1.0381 ms 15.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_25949 1.1621 ms 13.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_25936 1.2596 ms 12.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2\n",
      "  triton_mm_25946 1.2825 ms 12.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1496 seconds and 0.0036 seconds precompiling\n",
      "AUTOTUNE mm(265120x16, 16x128)\n",
      "  triton_mm_25960 0.1147 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_25962 0.1148 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4\n",
      "  triton_mm_25966 0.1155 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_25961 0.1157 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  mm 0.1173 ms 97.7% \n",
      "  triton_mm_25964 0.1177 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8\n",
      "  triton_mm_25967 0.1181 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8\n",
      "  triton_mm_25963 0.1182 ms 97.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4\n",
      "  triton_mm_25957 0.1185 ms 96.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4\n",
      "  triton_mm_25959 0.1186 ms 96.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.8213 seconds and 0.0017 seconds precompiling\n",
      "8it [10:01, 54.90s/it]W1016 15:41:57.779000 89844 torch/_dynamo/convert_frame.py:844] [0/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W1016 15:41:57.779000 89844 torch/_dynamo/convert_frame.py:844] [0/8]    function: 'forward' (/tmp/ipykernel_89844/1382549279.py:22)\n",
      "W1016 15:41:57.779000 89844 torch/_dynamo/convert_frame.py:844] [0/8]    last reason: 0/0: L['key'] == '29513-3-5'                                     \n",
      "W1016 15:41:57.779000 89844 torch/_dynamo/convert_frame.py:844] [0/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1016 15:41:57.779000 89844 torch/_dynamo/convert_frame.py:844] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "101it [10:22,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016847406682926454\n",
      "5.10255114721966e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [10:46,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001779294921229002\n",
      "0.00010105051519036971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [11:09,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014711306429552366\n",
      "0.00015107550399947792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [11:32,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0095818413066003\n",
      "0.0002011004704943595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [11:55,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03876006884801138\n",
      "0.00025112540726985645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [12:18,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06249440504170203\n",
      "0.00030115030692081556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [12:41,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09157838959855505\n",
      "0.0003511751620420897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [13:04,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1045501330691029\n",
      "0.0004011999652285392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [13:28,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11500490657001446\n",
      "0.00045122470907503313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [13:51,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12232573986925868\n",
      "0.0005012493861764506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [14:14,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12133709216182219\n",
      "0.0005512739891276802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [14:37,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12066570996860267\n",
      "0.0006012985105236241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [15:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12549717300954238\n",
      "0.0006513229429591978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [15:24,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12977761354420014\n",
      "0.0007013472790293314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [15:47,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12443380073554015\n",
      "0.0007513715113289696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1601it [16:10,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12406692158672758\n",
      "0.0008013956324530766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1701it [16:33,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12793507335819904\n",
      "0.0008514196349966324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1801it [16:56,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13146862411866989\n",
      "0.0009014435115546369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1901it [17:20,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12131787985642559\n",
      "0.0009514672547221117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [17:43,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12952810951022004\n",
      "0.0009999901215440093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020it [17:47,  1.89it/s]\n",
      "1it [00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13704194854693932\n",
      "0.0009999899230874326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:23,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1338087015777781\n",
      "0.0009999889011993108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:46,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12669183486019264\n",
      "0.000999987829969197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:10,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13165695502259542\n",
      "0.0009999867093971977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [01:33,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.136189672308245\n",
      "0.0009999855394834238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:56,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13451220184800722\n",
      "0.0009999843202279902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [02:20,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14117773987252596\n",
      "0.0009999830516310168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [02:43,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14115624124257975\n",
      "0.00099998173369263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [03:06,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12717500569312404\n",
      "0.000999980366412959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [03:29,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13754842885914945\n",
      "0.0009999789497921387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [03:53,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1387734936533281\n",
      "0.0009999774838303091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [04:16,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13408078675037588\n",
      "0.0009999759685276157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [04:39,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13831119453589966\n",
      "0.0009999744038842063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [05:02,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1282064306457263\n",
      "0.000999972789900238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [05:26,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1303761581677448\n",
      "0.0009999711265758669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [05:49,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1374867112189813\n",
      "0.0009999694139112584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1601it [06:12,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12882489571671105\n",
      "0.0009999676519065832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1701it [06:35,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14216245565756871\n",
      "0.0009999658405620132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1801it [06:58,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13422120187362557\n",
      "0.0009999639798777273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1901it [07:22,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1336501031184375\n",
      "0.0009999620698539098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [07:45,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13738908603029704\n",
      "0.0009999601104907503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020it [07:49,  4.30it/s]\n",
      "1it [00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13249775896836535\n",
      "0.0009999597126974142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13696087765575027\n",
      "0.0009999576941272974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:46,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13270663065597035\n",
      "0.0009999556262182696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:09,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14652206758321165\n",
      "0.0009999535089705322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [01:33,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14245509307617676\n",
      "0.0009999513423842987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:56,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13648106877451616\n",
      "0.0009999491264597816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [02:19,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13543852239192677\n",
      "0.0009999468611971982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [02:42,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13974803161572633\n",
      "0.0009999445465967722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [03:05,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13257488262992517\n",
      "0.0009999421826587323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [03:28,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13836855347698246\n",
      "0.0009999397693833119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [03:52,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14307183040158514\n",
      "0.000999937306770749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [04:15,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12673362392124743\n",
      "0.0009999347948212874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [04:38,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1377994309843797\n",
      "0.0009999322335351754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [05:01,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13273844469395327\n",
      "0.0009999296229126636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [05:24,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1406294462753105\n",
      "0.0009999269629540112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [05:47,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1266084415562815\n",
      "0.00099992425365948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1601it [06:10,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14429013517519323\n",
      "0.000999921495029339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1657it [06:23,  4.38it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "1297it [05:00,  4.38it/s]"
     ]
    }
   ],
   "source": [
    "losses, corrs, lrs = [], [], []\n",
    "for train_loop in range(250):\n",
    "    for i, (k, b) in tqdm(enumerate(train_dl)):\n",
    "        videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        #with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        #    out = opt_r(videos, k);\n",
    "        #    loss = criteria(out.transpose(1,2), responses)\n",
    "        out = opt_r(videos, k);\n",
    "        loss = criteria(out.transpose(1,2), responses)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(opt_r.parameters(), max_norm=1.0, norm_type=2)\n",
    "        opt.step()\n",
    "\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        with warmup_scheduler.dampening():\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "        if i % 10 ==0:\n",
    "            r2 = responses.to(torch.float32).cpu().numpy().flatten()\n",
    "            r1 = out.transpose(1,2).detach().cpu().to(torch.float32).numpy().flatten()\n",
    "            corrs.append(np.corrcoef(r1,r2)[0,1].item())\n",
    "            lrs.append(opt.param_groups[0]['lr'])\n",
    "        if i % 100 ==0:\n",
    "            print(np.corrcoef(r1,r2)[0,1].item())\n",
    "            print(opt.param_groups[0]['lr'])\n",
    "    for k, v in train_dl.loaders.items():\n",
    "        v.dataset.shuffle_valid_screen_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d4c72-f344-4611-93a9-e987ab8be8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb769f-33d9-45cf-adac-f0d5ed721754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183db5c9-cb4c-421c-8c92-6bd7391ae371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115d1d1-098b-4a8c-bf7e-e07613b164d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea3c7e-c6e7-4759-859b-6a96efd2fdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1228fd3-d718-4443-befd-ffcd2714b9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbcd8c05870>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPQUlEQVR4nO3de1hU1foH8O8MMCByBwFBFG95RwwU8Zo5R1BPZVGpWZrHtDpqKV2ULqh5ClIzj2landTOSdP8nbKOGqUomomiKN4x7+BlQCUYBIFhZv3+MLZuucjgXGD4fp5nnmf22u/seWel7re119pbIYQQICIiImrglNZOgIiIiMgUWNQQERGRTWBRQ0RERDaBRQ0RERHZBBY1REREZBNY1BAREZFNYFFDRERENoFFDREREdkEe2snYCkGgwGXL1+Gq6srFAqFtdMhIiKiWhBCoLCwEAEBAVAqax6LaTRFzeXLlxEUFGTtNIiIiKgOsrOz0aJFixpjGk1R4+rqCuBWp7i5uVk5GyIiIqoNrVaLoKAg6Txek0ZT1FRccnJzc2NRQ0RE1MDUZuoIJwoTERGRTWBRQ0RERDaBRQ0RERHZBBY1REREZBNY1BAREZFNqFNRs3TpUgQHB8PJyQkRERFIS0urNvaLL75A//794enpCU9PT6jV6krxzz//PBQKhewVHR0ti8nLy8OYMWPg5uYGDw8PTJgwATdu3KhL+kRERGSDjC5q1q1bh9jYWMyaNQsHDhxA9+7dERUVhdzc3CrjU1JSMHr0aGzfvh2pqakICgrCkCFDcOnSJVlcdHQ0rly5Ir2++eYb2f4xY8bg2LFj2LJlCzZu3IidO3di0qRJxqZPRERENkohhBDGfCAiIgI9e/bEkiVLANx6/EBQUBCmTp2KmTNn3vPzer0enp6eWLJkCcaOHQvg1khNfn4+NmzYUOVnTpw4gc6dO2Pfvn0IDw8HACQlJWHYsGG4ePEiAgIC7vm9Wq0W7u7uKCgo4H1qiIiIGghjzt9GjdSUlZUhPT0darX69gGUSqjVaqSmptbqGMXFxdDpdPDy8pK1p6SkwNfXFx06dMDLL7+M69evS/tSU1Ph4eEhFTQAoFaroVQqsXfv3iq/p7S0FFqtVvYiIiIi22VUUXPt2jXo9Xr4+fnJ2v38/KDRaGp1jBkzZiAgIEBWGEVHR+Pf//43kpOT8eGHH2LHjh0YOnQo9Ho9AECj0cDX11d2HHt7e3h5eVX7vQkJCXB3d5defO4TERGRbbPoYxISExOxdu1apKSkwMnJSWofNWqU9L5bt24ICQlB27ZtkZKSgsGDB9fpu+Li4hAbGyttVzw7goiIiGyTUSM1Pj4+sLOzQ05Ojqw9JycH/v7+NX52wYIFSExMxC+//IKQkJAaY9u0aQMfHx+cPn0aAODv719pInJ5eTny8vKq/V5HR0fpOU983hMREZHtM6qoUalUCAsLQ3JystRmMBiQnJyMyMjIaj83b948zJ07F0lJSbJ5MdW5ePEirl+/jubNmwMAIiMjkZ+fj/T0dClm27ZtMBgMiIiIMOYnEBER0X26WliKqd8cxC/Hajf1xFKMXv20bt06jBs3Dp999hl69eqFRYsW4dtvv0VmZib8/PwwduxYBAYGIiEhAQDw4YcfIj4+HmvWrEHfvn2l47i4uMDFxQU3btzAnDlzEBMTA39/f5w5cwZvvvkmCgsLceTIETg6OgIAhg4dipycHCxfvhw6nQ7jx49HeHg41qxZU6u8ufqJiIjINIJnbpLeKxXAmQ+G1eop2nVhzPnb6Dk1I0eOxNWrVxEfHw+NRoPQ0FAkJSVJk4ezsrKgVN4eAFq2bBnKysrw5JNPyo4za9YszJ49G3Z2djh8+DC++uor5OfnIyAgAEOGDMHcuXOlggYAVq9ejSlTpmDw4MFQKpWIiYnB4sWLjU2fiIiI7sM/t56SbRsEcCDrD4S18qrmE5Zj9EhNQ8WRGiIiovt35yhNhbeHdcLEAW3M8n1mu08NERERNQ7f7svGz3fNmTmY9Yf0ft6TIZjYvzUA4MOkTATP3IT/7LkAa46VsKghIiIiiRACwTM34c3/HsaL/0lHYYlO2vd7TqH0/unwILRp5gIAKDfcKmTe3XDUbHNraoNFDREREUlC5vwi2+42+xdMWXMABTd1mPHfIwCAlwa2BQBEd5HfVuWFfq0tk2Q1WNQQERERAOCXYxoUlpRXat94+Aq631HshLfyBAB4NlVh49R+UvuMoR3Nn2QNLHpHYSIiIqo/bpSW4/MdZ/BoaCAc7ZWY9J/b94N7oV9r/GvXuSo/p+58+3FJXQPdcT5xuNlzrQ0WNURERI3Qoq2/Y9Gfy7MXbztdaf87f+2McX2CkXRUg/c3n5Daj86JsliOxuLlJyIiIhtWrjfgX7+exak7JvnqDUIqaKpy+v2hAIAgL2dMHNAGx9+LwrO9W2LdpN5wcay/4yG8Tw0REZENG/rPX3HiihYAsPL5nhjU0bfKe81U+O/LfRD255yZ+oD3qSEiIiKkX8iTChoAGL9qX6WCZk/cYOl9zIMt6lVBY6z6O4ZEREREdXYp/yZilqXWGJMR/xd4OKvqzUTf+8WRGiIiIhtTWq5H38Rtsra+7bwrxXk4qyyVkkVwpIaIiKiBmv3jMazafR4vDWyLGdEdoFAokKstQa8PkmVx5xJuPUV70+ErWLc/G+MiW2FQB18rZW0+LGqIiIgaoJOaQqzafR4AsHzHGQghMOXhdpUKmq8nREiPLhge0hzDQ5pbOlWL4eonIiKiBubajVKE/2PrPeM+ey4MUXc9yqCh4eonIiIiG1VWbqhVQQOgwRc0xmJRQ0REVE/pDQI3SsuRfuEPlOj0AICB87fLYs4lDMOQOx5bAAB73xpsMyuajME5NURERPWQEAJt39pcY0zFBODPx4ZbKKv6jSM1RERE9VBGdn6N+xOf6CZNAKZbOFJDRERkJXqDQP8Pt+FyQQkA4IkegVg4MhTArbv/VqdHSw+M7BlkiRQbFBY1REREVqAt0SFk9i+ytu8OXsJLD7VFG5+myC/WAQDee6wLxkYGAwAOZv0BhUKB0CAPC2fbMLCoISIisoL0C39U2f7Ep7txo7Rc2n4yrIX0vkfLhvtcJkvgnBoiIiIrmLz6gPS+R0sP6f2dBQ0AOKs4/lBb7CkiIiIzK9cb8OWuc+gS4I5Vu8/D0UGJ4jK9tH/tpN5Iv/AHnvlir+xzKa8/ZOFMGzYWNURERGbW7u2fqt23e+bDcLS3Q5+2PrL2H6f0RbBPU3OnZlN4+YmIiMhMsq4XI3jmphpjAjyaSO+PvxeFQR2a4dsXIxHSwsPM2dkejtQQERGZyYC77v57tw2T+8q2nVX2WDm+lzlTsmksaoiIiEyktFwPB6USCgWwbMcZ2b73H++Kt78/CgDYGjsA7XxdrZGiTWNRQ0REdB/OXL0B9cIdEKL6mMOzh8DNyQHeTR2hvalD22YulkuwEWFRQ0REVEf7z+fhyeWp94xzc3IAAER3bVxPzbY0ThQmIiKqg2s3Su9Z0IS0cEfm3GgLZUR1KmqWLl2K4OBgODk5ISIiAmlpadXGfvHFF+jfvz88PT3h6ekJtVoti9fpdJgxYwa6deuGpk2bIiAgAGPHjsXly5dlxwkODoZCoZC9EhMT65I+ERHRfckrKkP4P7ZWal/xfDg+fy4Mf3+oLc4lDMOPU/rBycHOChk2TkZfflq3bh1iY2OxfPlyREREYNGiRYiKisLJkyfh6+tbKT4lJQWjR49Gnz594OTkhA8//BBDhgzBsWPHEBgYiOLiYhw4cADvvvsuunfvjj/++AOvvvoqHn30Uezfv192rPfeew8TJ06Utl1dOcmKiIgs4/ecQmRk5UNbosM/Np2Q7Tv1/lA42N0eJxjShZeZrEEhRE1TmyqLiIhAz549sWTJEgCAwWBAUFAQpk6dipkzZ97z83q9Hp6enliyZAnGjh1bZcy+ffvQq1cvXLhwAS1btgRwa6Rm2rRpmDZtmjHpSrRaLdzd3VFQUAA3N7c6HYOIiBqnif/ejy3Hc6rc9/s/hkJlz9kc5mLM+duo/wplZWVIT0+HWq2+fQClEmq1Gqmp954oBQDFxcXQ6XTw8vKqNqagoAAKhQIeHh6y9sTERHh7e6NHjx6YP38+ysvLqz4AERGRiRy7XFBtQXN49hAWNPWIUZefrl27Br1eDz8/P1m7n58fMjMza3WMGTNmICAgQFYY3amkpAQzZszA6NGjZRXZK6+8ggcffBBeXl7YvXs34uLicOXKFSxcuLDK45SWlqK0tFTa1mq1tcqPiIiowg8Zl/Dq2oxK7e19XbAldqDlE6IaWXRJd2JiItauXYuUlBQ4OTlV2q/T6fD0009DCIFly5bJ9sXGxkrvQ0JCoFKp8OKLLyIhIQGOjo6VjpWQkIA5c+aY/kcQEVGjcXdBkzStP/ady8NzkcFWyYdqZtSYmY+PD+zs7JCTIx+Gy8nJgb9/zZOiFixYgMTERPzyyy8ICQmptL+ioLlw4QK2bNlyz+tmERERKC8vx/nz56vcHxcXh4KCAumVnZ1d848jIiK6Q6ZGPsL/06v90dHfjQVNPWbUSI1KpUJYWBiSk5MxYsQIALcmCicnJ2PKlCnVfm7evHl4//338fPPPyM8PLzS/oqC5tSpU9i+fTu8vb3vmUtGRgaUSmWVK64AwNHRscoRHCIioqqsTcuCyl4JT2cVxq/aJ9t3LmEYFAqFlTKj2jL68lNsbCzGjRuH8PBw9OrVC4sWLUJRURHGjx8PABg7diwCAwORkJAAAPjwww8RHx+PNWvWIDg4GBqNBgDg4uICFxcX6HQ6PPnkkzhw4AA2btwIvV4vxXh5eUGlUiE1NRV79+7FoEGD4OrqitTUVEyfPh3PPvssPD09TdUXRETUSO05ex0zvztS5b7EJ7qxoGkgjC5qRo4ciatXryI+Ph4ajQahoaFISkqSJg9nZWVBqbx9VWvZsmUoKyvDk08+KTvOrFmzMHv2bFy6dAk//vgjACA0NFQWs337djz00ENwdHTE2rVrMXv2bJSWlqJ169aYPn26bJ4NERFRXXx34CJivz1U7f6RPYMsmA3dD6PvU9NQ8T41RER0J22JDtszc6tc3QQAcUM74tnerdDUkY9JtCZjzt/8L0VERI3Cpfyb6Ju4rcaYZ3u3RKfmbng6PEh2h2BqGFjUEBGRzTtz9QYeX/pbjTF/f6gt3ozuaKGMyBxY1BARkU07e/UGBn+0o8aYzLnRfPCkDWBRQ0RENmv7yVyMXylfnj02shXGRgbj2o1S/GfPBXwyqgeUSq5usgUsaoiIyCZkXS/Gm/89hD1n8wAATVV2KCrTy2L6tvPGe491BQC083VB7zb3vi8aNRwsaoiIqMErLddjwPztsra7C5ofp/RFlwB3S6ZFFsaihoiIGryhi36tcT/vCNw4sKghIqIG53RuIdQLd1a5r397Hxy+WICCmzosfzYMgzv5sqBpJFjUEBFRg7L79DU886+9Ve5Lef0hBPs0tXBGVF/wzkJERNRgCCGqLWgAsKBp5FjUEBFRg/HRL79L7/3dnPDKw+2k7flPhlgjJapHePmJiIjqtUyNFtFVTATe89ZgAMCTYUHwcVXBWcVTWmPHPwFERFQv3SzTo1N8UpX7+rXzkd639Ha2VEpUz7GoISKieqOotByf7zwLbxcV4n84Vm3c0mcetGBW1FCwqCEionohr6gMD87dUqtYd2cHM2dDDRGLGiIisjohBD7ZdqrKfatfiEDvNt44d60I6oU7sGp8TwtnRw0FixoiIrKIq4WlOJVTiD53zIcpKzcg+p87cfZqUaX4oV398emYB6Ub57XzdcH5xOEWy5caHhY1RERkdkII9Hx/KwDA1dEeR+ZEQQiBB975qVLsopGhGNEj0NIpkg1gUUNERGa3bl+29L6wtBzBMzdVGTc8pDkLGqozFjVERGR2M787UuP+w7OHwM2Jk3/p/vCOwkREZDZCiGpHZSosGhnKgoZMgiM1RERkNiknr8q2f542AFGLdqJPW2+sfiECAPgEbTIZFjVERGQW564VYfyqfdL2P0eFooO/K1cwkdmwqCEiIpPSGwTavrVZ1jb3sS54LJQTgMm8OKeGiIhMRqc3VCpoAOBRFjRkARypISIio+n0Buw+cx1Z14vw7g/H8FzvVogJa4ERS3+rFJsa9zDcm3AiMJmfQgghrJ2EJWi1Wri7u6OgoABubm7WToeIqMHS6Q1o/3blm+bd7fT7Q2FvxwsCdH+MOX/zTxsRERll/s8n7xlz8h/RLGjI4vgnjoiIau3HQ5fx+c6zsrbwVp6y7bBWnnC0t7NkWkQAOKeGiIhqkFdUhv4fbkOARxOcyr0h2/fO8E54oX8bAIC2RIemKnsoACiVvO8MWQeLGiIiqla/D7ehuExfqaBxVtlhQr/W0jbvCEz1QZ0uPy1duhTBwcFwcnJCREQE0tLSqo394osv0L9/f3h6esLT0xNqtbpSvBAC8fHxaN68OZo0aQK1Wo1Tp07JYvLy8jBmzBi4ubnBw8MDEyZMwI0b8r9kRERkOukX/kBxmb5Su4OdAsffi+adgKneMbqoWbduHWJjYzFr1iwcOHAA3bt3R1RUFHJzc6uMT0lJwejRo7F9+3akpqYiKCgIQ4YMwaVLl6SYefPmYfHixVi+fDn27t2Lpk2bIioqCiUlJVLMmDFjcOzYMWzZsgUbN27Ezp07MWnSpDr8ZCIiupcPkzIRs2x3pfY1EyNw6v1hVsiI6N6MXtIdERGBnj17YsmSJQAAg8GAoKAgTJ06FTNnzrzn5/V6PTw9PbFkyRKMHTsWQggEBATgtddew+uvvw4AKCgogJ+fH1atWoVRo0bhxIkT6Ny5M/bt24fw8HAAQFJSEoYNG4aLFy8iICDgnt/LJd1ERLUjhEDruNs30It5sAU+erq7FTOixsxsS7rLysqQnp4OtVp9+wBKJdRqNVJTU2t1jOLiYuh0Onh5eQEAzp07B41GIzumu7s7IiIipGOmpqbCw8NDKmgAQK1WQ6lUYu/evcb8BCIiqoHeIBD77SFZ26uD21spGyLjGDVR+Nq1a9Dr9fDz85O1+/n5ITMzs1bHmDFjBgICAqQiRqPRSMe4+5gV+zQaDXx9feWJ29vDy8tLirlbaWkpSktLpW2tVlur/IiIGqtJ/96PX47nyNrS3hoMXzcnK2VEZByL3qcmMTERa9euxffffw8nJ/P+JUlISIC7u7v0CgoKMuv3ERE1FONXpiF45iaczr2BEp0eRy8VIHjmpkoFzcap/VjQUINi1EiNj48P7OzskJMj/4Ofk5MDf3//Gj+7YMECJCYmYuvWrQgJCZHaKz6Xk5OD5s2by44ZGhoqxdw9Ebm8vBx5eXnVfm9cXBxiY2Olba1Wy8KGiBo9IQS2n7wKAFAv3FFt3OheQega6G6ptIhMwqiRGpVKhbCwMCQnJ0ttBoMBycnJiIyMrPZz8+bNw9y5c5GUlCSbFwMArVu3hr+/v+yYWq0We/fulY4ZGRmJ/Px8pKenSzHbtm2DwWBAREREld/p6OgINzc32YuIqDG7ewJwVV4f8gDOJw5HwhMhNcYR1UdG33wvNjYW48aNQ3h4OHr16oVFixahqKgI48ePBwCMHTsWgYGBSEhIAAB8+OGHiI+Px5o1axAcHCzNgXFxcYGLiwsUCgWmTZuGf/zjH2jfvj1at26Nd999FwEBARgxYgQAoFOnToiOjsbEiROxfPly6HQ6TJkyBaNGjarVyiciIgJ+z6n53l4rn++JQR19a4whqs+MLmpGjhyJq1evIj4+HhqNBqGhoUhKSpIm+mZlZUGpvD0AtGzZMpSVleHJJ5+UHWfWrFmYPXs2AODNN99EUVERJk2ahPz8fPTr1w9JSUmyeTerV6/GlClTMHjwYCiVSsTExGDx4sV1+c1ERI2OEAJLt5+WtnfNGIQWns4wGAQfa0A2w+j71DRUvE8NETUWOr0Bn24/g8v5N7Fufza2v/4QRiz9DQU3dQCAiNZeWPdi9VMGiOoTY87ffPYTEZENyc4rRv9522VtgxakyLZnP9rFghkRWY5Fl3QTEZF53V3Q3K1PW290as7RarJNLGqIiGzEvWYTjIloiTUTe1soGyLL4+UnIiIbcedy7Q9juuHp8CDc1OlxUlOIPWfzMKZ3SytmR2R+LGqIiGzAyM/kz98b2fNWAeOsskePlp7o0dLTGmkRWRQvPxERNXCHsvOx91yetL0nbrAVsyGyHhY1REQN2NFLBXhs6W/S9tvDOsHfnc9rosaJl5+IiBqopdtPY/7PJ2VtL/RvbaVsiKyPRQ0RUQOy8fBlTFlzsMp9p98fCoWCdwemxotFDRFRPVWuN+DLXefwUAdfPPLJLpTpDVXGtW3WFEnTBsDejjMKqHFjUUNEVE+1e/snAEDCT5k1xiW/9pAFsiGq/1jUEBHVM0IIfL03q9r9Ux9uh77tfHCl4CYeeoBP1SaqwKKGiMjKfj6mgaagBEO7+qOoTF/pWU0VpqnbY5r6AcsmR9SAsKghIrKiUzmFePE/6QCAWT8eq7S/bbOm+GZSb5zKuYG+7XwsnR5Rg8JZZUREFvLdgYsInrkJ2XnFyNWW4GaZHn/5eGe18Y90D8DW2IHwdXViQUNUCxypISKygA82n8DnO88CuPeTtAHgo6e6IyashbnTIrIpLGqIiMwseOame8acSxgGhUKB07k3oDcIdPB3tUBmRLaFRQ0RkQloCkrQxMEO7s4OsvbaFDQvDmwj3TSvna+LWfIjagxY1BAR3aekoxq89PWtyb6dmrvhh8l9obJXYuVv52Rx/325D8JaeeI/qefx7g/H8P3f+8AggAdbelghayLboxBCCGsnYQlarRbu7u4oKCiAm5ubtdMhIhtQVFqOLrN+rlXsr28OQpCXs5kzIrI9xpy/ufqJiKiOhi/+tVZx/dr5sKAhsgAWNURERtqemYsTV7Q4f71Y1r54dI8q478YG26JtIgaPc6pISKqhdQz19HB3xVPLt+Ns1eLKu2fO6IrHu0egEe7B2DKmgPYePgK1kyMQJ+2vL8MkaVwTg0R0T3cawXT+cThFsqEqPHhnBoiojoQQqBEp5e1jVuRVuNnznwwzJwpEZERePmJiAhAud6Adm//JG1P7N8aX/x6rsrY7i3c8d+X+8Dejv9fSFSfsKghIgIwd+Nx2fbdBc07wzvBIAQyNYVY+HSoBTMjotpiUUNEBOCr1AvV7kt4ohtG92ppwWyIqC44dkpENu+PojKczi3Ea98egrZEJ9unNwjZROBRPYOk9+/+tTMOzRrCgoaogeBIDRHZtGs3ShH+j63S9n8PXMRfOvtJ9475++p0WfzsR7sgMSbEojkSkWlwpIaIbFZ+cZmsoKmw5XgOZv1wFMVl5fj5WI7U/sv0AXBysLNkikRkQnUqapYuXYrg4GA4OTkhIiICaWnVL3k8duwYYmJiEBwcDIVCgUWLFlWKqdh392vy5MlSzEMPPVRp/0svvVSX9ImoESgqLUfoe1uq3f9V6gV0jr/93KZ1k3rjAT9XS6RGRGZidFGzbt06xMbGYtasWThw4AC6d++OqKgo5ObmVhlfXFyMNm3aIDExEf7+/lXG7Nu3D1euXJFeW7bc+ofoqaeeksVNnDhRFjdv3jxj0yeiRuC309cqPWhyzqNd8Oubg/DB492q/ExEG29LpEZEZmR0UbNw4UJMnDgR48ePR+fOnbF8+XI4OztjxYoVVcb37NkT8+fPx6hRo+Do6FhlTLNmzeDv7y+9Nm7ciLZt22LgwIGyOGdnZ1kc7wxM1LgIIVBQrEO53lBtzP+lX8SYf+2VtWXOjca4PsEI8nLG8JDm8HOT/1uUGvewWfIlIssyaqJwWVkZ0tPTERcXJ7UplUqo1WqkpqaaJKGysjJ8/fXXiI2NhUKhkO1bvXo1vv76a/j7++ORRx7Bu+++C2dnPvmWqDH49dRVPPel/FL3uYRhsn8nnvliD3afuS6LOTYnSjZPxr2JA/a+pQYAHMj6A8HeTeHVVGXGzInIUowqaq5duwa9Xg8/Pz9Zu5+fHzIzM02S0IYNG5Cfn4/nn39e1v7MM8+gVatWCAgIwOHDhzFjxgycPHkS3333XZXHKS0tRWlpqbSt1WpNkh8RmZ7BIKBUKrDvfB7W78/GG1Ed0cxVPpry+c6zlT731vdHkPBECL7YeRbvbz5Raf+hWUPQ1LH6f+YebOl5/8kTUb1R75Z0f/nllxg6dCgCAgJk7ZMmTZLed+vWDc2bN8fgwYNx5swZtG3bttJxEhISMGfOHLPnS0T35/hlLYYt/lXW9u3+iwCAPXGD4dVUhT+Ky/DrqWuVPvtNWjbcm6iwfMcZWXsTBzt89bdecG/iYL7EiajeMaqo8fHxgZ2dHXJycmTtOTk51U4CNsaFCxewdevWakdf7hQREQEAOH36dJVFTVxcHGJjY6VtrVaLoKCgSnFEZF13FzR36p2QXKnth8l94epkj4c/2gEAlQqaH6f0RUgLD5PmSEQNg1FFjUqlQlhYGJKTkzFixAgAgMFgQHJyMqZMmXLfyaxcuRK+vr4YPnz4PWMzMjIAAM2bN69yv6OjY7UTk4nIfEp0ehSVlsPbRf737+ilAvz1k10AgDeiOmD+zyfrdPzuQR4AgL/1bY0Vv8mfz3T3HBsialyMvvwUGxuLcePGITw8HL169cKiRYtQVFSE8ePHAwDGjh2LwMBAJCQkALg18ff48ePS+0uXLiEjIwMuLi5o166ddFyDwYCVK1di3LhxsLeXp3XmzBmsWbMGw4YNg7e3Nw4fPozp06djwIABCAnhnT+J6oOycgPOXruB6EW3R17+76VIhAd7AQDe/eGo1F5VQXPmg2GwUyqw8JeTWLztdJXf0b+9j/Q+/pHOcHJQ4tOUWyM1P08bwIKGqJFTCCGEsR9asmQJ5s+fD41Gg9DQUCxevFi6HPTQQw8hODgYq1atAgCcP38erVu3rnSMgQMHIiUlRdr+5ZdfEBUVhZMnT+KBBx6QxWZnZ+PZZ5/F0aNHUVRUhKCgIDz++ON45513ar2sW6vVwt3dHQUFBVwKTmRiL3y1H1tP5Nw7sBq7ZgxCC89bKxnL9QYcu6yFvZ0CwxffGtkZGR4EH1cV3ojqWOmz6Rf+gI+LCq28m9b5+4mo/jLm/F2noqYhYlFDZHqvfHMQPx66bNRnfF0dkVtYCnUnX2w9kYuv/tYLAx9oVmXsrlPX4OvmyDv9EjVixpy/693qJyKq//KLyzBoQQr+KNZVuf+Vh9tVewlp71uDa32ZqN8dl5uIiO6FRQ1RI3Wl4CZe+eYgXhncHv3b3x4p0RsE2r61uVL8vrfVUNkpcfVGCdQLd1ba37+9D/4zIULaHhbSXJpfMy6yFWKHdOASayIyK15+ImqEnl+ZhpSTV6Xtj0d2x+M9WgAAgmduMupY7wzvhF6tvdAt0J0TdYnI5Hj5iYiqpC3RIWT2L5Xap687hEe7B2JJNZeMqvPNxN6IbMsHQRJR/cCihqgROHetCJ8kn8J3By9VG3P3Jad/jgrFq2szqo0/MnsIXJ14OYmI6g8WNUQ2plxvQGFJOTybqnDtRim+3HUOy1LOVIqLG9oRLw5sizZxm2C46yJ05+ZueCw0EI+FBkrHLDcI2YMhiYjqGxY1RDYiO68Y/edtr1Xsxqn90DXQHQBwdE4UOsf/LO3r09Ybayb2lsXb2ylhz3qGiOo5pbUTIKL7d7NMX6uCZt2k3jifOFwqaADAWWWPPXGDpe0vxoabJUciInPjSA1RA/NNWhbivjuCtLcHw9fVCUWl5egy6+d7fi417mE0d29S5T5/dyecT7z3M9eIiOozFjVEDUjW9WLEfXcEANDr/cpPsAYgFTtnr97ArtPX8EhIADybqiyZJhGRVbCoIWogfsi4VONqJAD4cUpf+Lo6AQDaNHNBm2YuFsiMiKh+4JwaIisRQuCkphA6vaHSvqOXCpB+4Q9ZW20KmpAWHibMkIioYeFIDZGVrEnLwtvfHwUAxP+1M97beBz+bk7QluhQXKaXxX7weDfZ9qH4IXBSKbE9Mxc+Lo4I9GxS7XwZIqLGgo9JILKwx5bswqGLBXX+fObcaN4vhogaDWPO37z8RGQBv52+huCZm7Bk26n7Kmi6BrqxoCEiqgaLGiIzulpYij4JyRjzr70AgAW//F6rz43uFYSU1x+q1P7D5H6mTI+IyKZwTg2RCZ24osVjS3+DEAKvPNweH22puoiJG9oRoyNawu0ez046nzgcO36/9TTtgQ80M3m+RES2hEUNkYkEz9wk2767oBndKwjfpGWjT1tvvDiwba2Py2KGiKh2WNQQ3adfT13Fc1+m1Riz4KnueDKsBRKeCLFQVkREjQ+LGiIjnM69gU2Hr6C0XI83ozvizNUblQoar6Yq5BWVAQCCvZ2x/fWHoFAorJEuEVGjwqKGqJbOXyuCeuEOafvTlDOVYta/FImewV6WTIuIiP7E1U9EtVBYosNDC1JqjPlrSHMWNEREVsSRGqJa6Db7lxr3n35/KOzt+P8IRETWxKKGqAqaghK88X+HEOzdFNPU7WX7ziUMg0KhQI62BCt/O4/XhjzAgoaIqB7gYxKI7nL30uw7/f6PoVDZs4AhIrIUPiaBqJburuk/TMqsMZ4FDRFR/cXLT9Ro6A0Cp3ILcTArH3HfHYGzyk56GvZrf3kAW0/kyJ7L1LuNFwwCSDuXBwBIfm2gVfImIqLaYVFDjUJGdj5GLP1N1lZR0ACV7/77yegeeKR7AIBbozm8zwwRUf3HsXSyGbmFJYhZthspJ3Nl7YM/SqlU0NTE381JKmgAsKAhImogOFJDDZ7eIND2rc3S9vMr9+HXNwchyMsZRy8V4MzVokqfGRkehHX7swEAGyb3RcLmE2jt0xSRbb3xWGigxXInIiLT4eonarBytSWYu+kE/nfocqV9Lb2c4e2iwsGsfFn7+cThFsqOiIhMweyrn5YuXYrg4GA4OTkhIiICaWnVP8zv2LFjiImJQXBwMBQKBRYtWlQpZvbs2VAoFLJXx44dZTElJSWYPHkyvL294eLigpiYGOTk5NQlfWrg1qZlYdHW39Hrg+QqCxoAyMorlhU0E/q1ZkFDRGTjjC5q1q1bh9jYWMyaNQsHDhxA9+7dERUVhdzc3Crji4uL0aZNGyQmJsLf37/a43bp0gVXrlyRXrt27ZLtnz59Ov73v/9h/fr12LFjBy5fvownnnjC2PSpnsrOK0bwzE0InrkJekP1g4f/2XMBM787gkVbT1Xat3Fqv2oLl9eGPGCyXImIqH4y+vJTREQEevbsiSVLlgAADAYDgoKCMHXqVMycObPGzwYHB2PatGmYNm2arH327NnYsGEDMjIyqvxcQUEBmjVrhjVr1uDJJ58EAGRmZqJTp05ITU1F796975k3Lz/VX3fPiQGA5c+GIbrr7SI4O68Y/edtr/LzP0zui+5BHre3My7h1bUZ0vasRzpjfN/WJs2ZiIgsw5jzt1EThcvKypCeno64uDipTalUQq1WIzU1tW7Z/unUqVMICAiAk5MTIiMjkZCQgJYtWwIA0tPTodPpoFarpfiOHTuiZcuWtS5qyLquFpbib6v24cil2/eBmfpwO7w2pAOST1S+jPjS1+nS4wgAVFvQZM6NhpODnaztsdBARHXxh0EIOKs4F56IqLEw6l/8a9euQa/Xw8/PT9bu5+eHzMya78Rak4iICKxatQodOnTAlStXMGfOHPTv3x9Hjx6Fq6srNBoNVCoVPDw8Kn2vRqOp8pilpaUoLS2VtrVabZ3zo7r7dn823vy/w1Xu+2TbaXy24yzK9AapTakAKq4+tY7bjLeGdcR3By5V+uy95sfcXegQEZHtqxf3qRk6dCieeuophISEICoqCps3b0Z+fj6+/fbbOh8zISEB7u7u0isoKMiEGVNtVVfQVLizoPl4ZHecTZAXKx9szkSmplDabu7uhGNzokybJBER2QSjihofHx/Y2dlVWnWUk5NT4yRgY3l4eOCBBx7A6dOnAQD+/v4oKytDfn5+rb83Li4OBQUF0is7O9tk+VHtLNr6e6W2uY91wf531JgyqF2lfSP+vD/MofghVR7vvce6IDVuMJo68pISERFVZlRRo1KpEBYWhuTkZKnNYDAgOTkZkZGRJkvqxo0bOHPmDJo3bw4ACAsLg4ODg+x7T548iaysrGq/19HREW5ubrIXmdb4lWnSiqUSnV62L/3CH7IVSucShuF84nA8FxkMHxdHvB7VASfei8brQx7AsG7+OPPB7fkz7s4OOPFeNFp6OUuf/3FKX4yNDLbI7yIioobJ6P/ljY2Nxbhx4xAeHo5evXph0aJFKCoqwvjx4wEAY8eORWBgIBISEgDcmlx8/Phx6f2lS5eQkZEBFxcXtGt36//WX3/9dTzyyCNo1aoVLl++jFmzZsHOzg6jR48GALi7u2PChAmIjY2Fl5cX3NzcMHXqVERGRnKSsBV8vvMMPtgsn0PV8d0keDVVIf0dNRQKBWKW7Zb2bZzar8pHDTRR2WHKw+2r/I4mKjvsfHOQaRMnIiKbZnRRM3LkSFy9ehXx8fHQaDQIDQ1FUlKSNHk4KysLSuXtAaDLly+jR48e0vaCBQuwYMECDBw4ECkpKQCAixcvYvTo0bh+/TqaNWuGfv36Yc+ePWjWrJn0uY8//hhKpRIxMTEoLS1FVFQUPv3007r+bqqDqpZe3ymvqAwpv1/Foex8qW1GdEd0DXS3QHZERNTY8TEJVC2d3oAVu87hAX9XbM/Mxb9TL1SK2RM3GL0Tkqv49C28iy8REd0Ps92nhmxfud6Adm//hPa+LjiVe6PauHWTeiOijTeAW4XLx1t+xz+T5Xf5nfdkiFlzJSIiuhOLGgIA/H11OjYfuX3Pn5oKmoz4v8DDWSVrm/6XB2RFzRtRHfB0OJfRExGR5bCoIWgKSmQFTXXWvxSJts1cKhU0Fc4nDocQospJwURERObGoqaRuVmmx6rd5/FMREu4N3EAADzzrz1VxrZt1hQ/vToApeV6uDo51Or4LGiIiMhaWNQ0IkIIdIpPAgB8mJSJsx8MAwCcvVoEAOjXzgdfvxBR6XMq+3px42kiIqIasahpRKasOSjbbnPX8mxO7CUiooaMRU0jUKLTo+O7SfeMC/BoYoFsiIiIzIPXFRqBDzafkG3PfaxLpZgT70VbKh0iIiKz4EiNjSkrNyDsH1tQWFKOz54Lw4v/SZftnxcTgqd7BuGZiFY4kPUHwlp6Qqnk5F4iImr4eEdhG7Lwl5NYvO10tfu3TB+A9n6uFsyIiIjo/vCOwjbIYBDYdOQKdv5+FRMHtMGlP25iUEdfaX/7tzdDp6+5Pm3n62LuNImIiKyGRY2FfJOWheQTOVB38sPInkFG38/lzpVK69Mv1vpz0V38cSq3EB+PDOU9ZIiIyKaxqLGAq4WliPvuCABg64lcZGTnIzHm9vLpfefz8NTyVPi4OOKDx7uivZ8rWvs0BXDrWUzT1mXU+rv+76VIhAd7Abj1VG07zpchIqJGgqufLGDzkSuy7bX7sqE33LpUpDcIPLU8FQBw7UYpJv0nHYMWpCCvqAxf7DyLdm//hI2Hb3/+8R6B1X7PwXf/IhU0AFjQEBFRo8KRGguY9eMxAICbkz20JeUAgOU7zuDp8CDkaEuq/MyDc7dUausW6I6PR4bi45GhePv7I1i9Nwt74gbD393JfMkTERE1EFz9ZGancgrxl493AgD2vjUYER8kVxsb1cUPPx/LqXLfmhciENnWm/NiiIioUTHm/M3LT2a26c9LT10C3ODn5oTdMx+uMu6d4Z3w2XPhOPDuX2Ttnz0XhnMJw9CnnQ8LGiIiohrw8pOZbcvMBQA80j0AwK1HETzSPQD/O3RZFvd0zyAAgFdTFc5+MAwV9QsLGSIiotphUWNGQggcvlgAAAj2dpbaPxndA5+M7gGd3gCd3gBnlfw/A+/wS0REZDwWNWZ08Y+b0vvItj6V9jvYKeFgxyuAREREpsAzqhn998Ctm+S5N3GAexMHK2dDRERk21jUmNGiracAAN5NVVbOhIiIyPaxqLGAZ3u3snYKRERENo9FjZkU3NRJ70fUcBdgIiIiMg0WNWZy7NKtVU8tPJvAi5efiIiIzI5FjZkc/rOoCWnhbuVMiIiIGgcWNWZy5M/703QL9LBuIkRERI0EixozOfLnSE3XQMs9Z4qIiKgxY1FjBtl5xcjKK4adUoGQFh7WToeIiKhRYFFjBh9v+R0A0FRlx5vuERERWQiLGjM4fkULAOjGScJEREQWU6eiZunSpQgODoaTkxMiIiKQlpZWbeyxY8cQExOD4OBgKBQKLFq0qFJMQkICevbsCVdXV/j6+mLEiBE4efKkLOahhx6CQqGQvV566aW6pG92N3V6AMDLA9tZORMiIqLGw+iiZt26dYiNjcWsWbNw4MABdO/eHVFRUcjNza0yvri4GG3atEFiYiL8/f2rjNmxYwcmT56MPXv2YMuWLdDpdBgyZAiKiopkcRMnTsSVK1ek17x584xN3+wKbupw4XoxAE4SJiIisiSjn9K9cOFCTJw4EePHjwcALF++HJs2bcKKFSswc+bMSvE9e/ZEz549AaDK/QCQlJQk2161ahV8fX2Rnp6OAQMGSO3Ozs7VFkb1xYk/Lz0FejSBhzNvukdERGQpRo3UlJWVIT09HWq1+vYBlEqo1WqkpqaaLKmCglvLob28vGTtq1evho+PD7p27Yq4uDgUFxeb7DtN5dy1W6NL7f1crJwJERFR42LUSM21a9eg1+vh5+cna/fz80NmZqZJEjIYDJg2bRr69u2Lrl27Su3PPPMMWrVqhYCAABw+fBgzZszAyZMn8d1331V5nNLSUpSWlkrbWq3WJPndy/nrt4qaYO+mFvk+IiIiusXoy0/mNnnyZBw9ehS7du2StU+aNEl6361bNzRv3hyDBw/GmTNn0LZt20rHSUhIwJw5c8ye790uXLs1etTK29ni301ERNSYGXX5ycfHB3Z2dsjJyZG15+TkmGSuy5QpU7Bx40Zs374dLVq0qDE2IiICAHD69Okq98fFxaGgoEB6ZWdn33d+tSGN1PhwpIaIiMiSjCpqVCoVwsLCkJycLLUZDAYkJycjMjKyzkkIITBlyhR8//332LZtG1q3bn3Pz2RkZAAAmjdvXuV+R0dHuLm5yV7mJoTg5SciIiIrMfryU2xsLMaNG4fw8HD06tULixYtQlFRkbQaauzYsQgMDERCQgKAW5OLjx8/Lr2/dOkSMjIy4OLignbtbt3HZfLkyVizZg1++OEHuLq6QqPRAADc3d3RpEkTnDlzBmvWrMGwYcPg7e2Nw4cPY/r06RgwYABCQkJM0hGmcO1GGUp0BigUt1Y/ERERkeUYXdSMHDkSV69eRXx8PDQaDUJDQ5GUlCRNHs7KyoJSeXsA6PLly+jRo4e0vWDBAixYsAADBw5ESkoKAGDZsmUAbt1g704rV67E888/D5VKha1bt0oFVFBQEGJiYvDOO+8Ym75Z5ReXAQDcmzhAZc+bNRMREVmSQgghrJ2EJWi1Wri7u6OgoMBsl6L2n8/Dk8tTEeztjJQ3BpnlO4iIiBoTY87fHE4wofxiHQDAnTfdIyIisjgWNSaUf/NWUePBJ3MTERFZHIsaE7pzTg0RERFZFosaEyqoGKlxZlFDRERkaSxqTEj7Z1Hj5sSihoiIyNJY1JjQTZ0eANBEZWflTIiIiBofFjUmVKIzAACcHFjUEBERWRqLGhMq+XOkxsmB3UpERGRpPPuaUEn5nyM19hypISIisjQWNSZ0e6SGRQ0REZGlsagxoVJefiIiIrIann1NiBOFiYiIrIdFjQmVlHOkhoiIyFp49jWhijk1jpwoTEREZHEsakzo9uUndisREZGl8exrQhypISIish4WNSYihEBpOScKExERWQuLGhOpKGgAwJGXn4iIiCyOZ18TKTcI6b3Kjt1KRERkaTz7mojujpEaBxY1REREFsezr4noDLeKGoUCsFMqrJwNERFR48OixkTK9bcuPzko2aVERETWwDOwiej0t0ZqHOw4SkNERGQNLGpMRPfnSI0959MQERFZBc/AJnJ7pIZdSkREZA08A5uINKeGl5+IiIisgkWNiVSsfrJnUUNERGQVLGpMpOI+Nbz8REREZB08A5tIxR2FuaSbiIjIOngGNpGKicK8/ERERGQdLGpMRCdNFGaXEhERWUOdzsBLly5FcHAwnJycEBERgbS0tGpjjx07hpiYGAQHB0OhUGDRokV1OmZJSQkmT54Mb29vuLi4ICYmBjk5OXVJ3yzKefM9IiIiqzK6qFm3bh1iY2Mxa9YsHDhwAN27d0dUVBRyc3OrjC8uLkabNm2QmJgIf3//Oh9z+vTp+N///of169djx44duHz5Mp544glj0zebMt6nhoiIyKqMPgMvXLgQEydOxPjx49G5c2csX74czs7OWLFiRZXxPXv2xPz58zFq1Cg4OjrW6ZgFBQX48ssvsXDhQjz88MMICwvDypUrsXv3buzZs8fYn2AW5byjMBERkVUZdQYuKytDeno61Gr17QMolVCr1UhNTa1TArU5Znp6OnQ6nSymY8eOaNmyZZ2/19TK/7xPjQOf0E1ERGQV9sYEX7t2DXq9Hn5+frJ2Pz8/ZGZm1imB2hxTo9FApVLBw8OjUoxGo6nyuKWlpSgtLZW2tVptnfKrrTJOFCYiIrIqmz0DJyQkwN3dXXoFBQWZ9fvKuaSbiIjIqowqanx8fGBnZ1dp1VFOTk61k4BNcUx/f3+UlZUhPz+/1t8bFxeHgoIC6ZWdnV2n/GqrnCM1REREVmXUGVilUiEsLAzJyclSm8FgQHJyMiIjI+uUQG2OGRYWBgcHB1nMyZMnkZWVVe33Ojo6ws3NTfYypzIu6SYiIrIqo+bUAEBsbCzGjRuH8PBw9OrVC4sWLUJRURHGjx8PABg7diwCAwORkJAA4NZE4OPHj0vvL126hIyMDLi4uKBdu3a1Oqa7uzsmTJiA2NhYeHl5wc3NDVOnTkVkZCR69+5tko64X1z9REREZF1GFzUjR47E1atXER8fD41Gg9DQUCQlJUkTfbOysqC84/lHly9fRo8ePaTtBQsWYMGCBRg4cCBSUlJqdUwA+Pjjj6FUKhETE4PS0lJERUXh008/revvNrmKxyRw9RMREZF1KIQQwtpJWIJWq4W7uzsKCgrMcikq4acT+GzHWbzQrzXe+Wtnkx+fiIioMTLm/M1rJSbCy09ERETWxTOwiVRcflJxojAREZFVsKgxER1HaoiIiKyKZ2AT4c33iIiIrItFjYncvvzELiUiIrIGnoFNRGf48/ITl3QTERFZBYsaE9GVV1x+YpcSERFZA8/AJlL+50gNLz8RERFZB8/AJqLjRGEiIiKrYlFjItJjEjhSQ0REZBU8A5tIxR2F+ZRuIiIi62BRYyLS5Sclu5SIiMgaeAY2kYo7CjvYs0uJiIisgWdgEyk3/DmnhvepISIisgoWNSbCZz8RERFZF8/AJnJ79RNHaoiIiKyBRY2J3F79xC4lIiKyBp6BTYT3qSEiIrIunoFNhHcUJiIisi4WNSYiLenmfWqIiIisgmdgE5GWdNtzpIaIiMgaWNSYgBDi9pJujtQQERFZBc/AJlBuENJ7LukmIiKyDhY1JlCxnBvg6iciIiJr4RnYBHR/zqcBuPqJiIjIWljUmICu/HZRw9VPRERE1sEzsAlUzKmxUyqg5AMtiYiIrIJFjQmU/TlSY8+ChoiIyGpY1JhAxUiNipOEiYiIrIZnYRMo5yMSiIiIrI5FjQmUSUUNu5OIiMha6nQWXrp0KYKDg+Hk5ISIiAikpaXVGL9+/Xp07NgRTk5O6NatGzZv3izbr1AoqnzNnz9figkODq60PzExsS7pm1zFfWp4+YmIiMh6jD4Lr1u3DrGxsZg1axYOHDiA7t27IyoqCrm5uVXG7969G6NHj8aECRNw8OBBjBgxAiNGjMDRo0elmCtXrsheK1asgEKhQExMjOxY7733nixu6tSpxqZvFhXPfeLlJyIiIusxuqhZuHAhJk6ciPHjx6Nz585Yvnw5nJ2dsWLFiirj//nPfyI6OhpvvPEGOnXqhLlz5+LBBx/EkiVLpBh/f3/Z64cffsCgQYPQpk0b2bFcXV1lcU2bNjU2fbMoK6947hOLGiIiImsxqqgpKytDeno61Gr17QMolVCr1UhNTa3yM6mpqbJ4AIiKiqo2PicnB5s2bcKECRMq7UtMTIS3tzd69OiB+fPno7y83Jj0zUZ6QjcvPxEREVmNvTHB165dg16vh5+fn6zdz88PmZmZVX5Go9FUGa/RaKqM/+qrr+Dq6oonnnhC1v7KK6/gwQcfhJeXF3bv3o24uDhcuXIFCxcurPI4paWlKC0tlba1Wu09f19d6fQsaoiIiKzNqKLGElasWIExY8bAyclJ1h4bGyu9DwkJgUqlwosvvoiEhAQ4OjpWOk5CQgLmzJlj9nwBQPfnRGE+oZuIiMh6jBpa8PHxgZ2dHXJycmTtOTk58Pf3r/Iz/v7+tY7/9ddfcfLkSbzwwgv3zCUiIgLl5eU4f/58lfvj4uJQUFAgvbKzs+95zLqqWP3EJd1ERETWY9RZWKVSISwsDMnJyVKbwWBAcnIyIiMjq/xMZGSkLB4AtmzZUmX8l19+ibCwMHTv3v2euWRkZECpVMLX17fK/Y6OjnBzc5O9zOX25SeO1BAREVmL0ZefYmNjMW7cOISHh6NXr15YtGgRioqKMH78eADA2LFjERgYiISEBADAq6++ioEDB+Kjjz7C8OHDsXbtWuzfvx+ff/657LharRbr16/HRx99VOk7U1NTsXfvXgwaNAiurq5ITU3F9OnT8eyzz8LT07Muv9ukOKeGiIjI+owuakaOHImrV68iPj4eGo0GoaGhSEpKkiYDZ2VlQam8fXLv06cP1qxZg3feeQdvvfUW2rdvjw0bNqBr166y465duxZCCIwePbrSdzo6OmLt2rWYPXs2SktL0bp1a0yfPl02z8aaKubU2CtZ1BAREVmLQgghrJ2EJWi1Wri7u6OgoMDkl6L+nXoe8T8cw9Cu/lj2bJhJj01ERNSYGXP+5tCCCdxe/cTuJCIishaehU1Ax6d0ExERWR2LGhMo/7Oo4QMtiYiIrIdnYROQJgpzpIaIiMhqWNSYgHT5iaufiIiIrIZnYRMoN9waqVHZszuJiIishWdhEygrrxip4eUnIiIia2FRYwLlhorVT+xOIiIia+FZ2AQqHmip4kRhIiIiq2FRYwJleo7UEBERWRvPwiZQLj37iSM1RERE1sKixgQq5tRw9RMREZH18CxsAmXlfEo3ERGRtfEsbAIVIzUOnChMRERkNSxqTKDijsJ8SjcREZH18CxsAnz2ExERkfWxqDGBco7UEBERWR3PwiZQMVLDOTVERETWw6LGBPiUbiIiIuvjWdgEKp7SzctPRERE1sOzsAncXv3Ey09ERETWwqLGBMr1HKkhIiKyNp6FTeD2Ay05UkNERGQtLGpMgEu6iYiIrI9nYRPg5SciIiLr41nYBKTLT0pefiIiIrIWFjUmwCXdRERE1sez8H0yGAT0Bt5RmIiIyNpY1NwnncEgvbfnSA0REZHV8Cx8nyomCQOAikUNERGR1fAsfJ8q7iYM8D41RERE1lSnombp0qUIDg6Gk5MTIiIikJaWVmP8+vXr0bFjRzg5OaFbt27YvHmzbP/zzz8PhUIhe0VHR8ti8vLyMGbMGLi5ucHDwwMTJkzAjRs36pK+SenuGKnh6iciIiLrMbqoWbduHWJjYzFr1iwcOHAA3bt3R1RUFHJzc6uM3717N0aPHo0JEybg4MGDGDFiBEaMGIGjR4/K4qKjo3HlyhXp9c0338j2jxkzBseOHcOWLVuwceNG7Ny5E5MmTTI2fZMrN9x+7pNCwaKGiIjIWhRCCHHvsNsiIiLQs2dPLFmyBABgMBgQFBSEqVOnYubMmZXiR44ciaKiImzcuFFq6927N0JDQ7F8+XIAt0Zq8vPzsWHDhiq/88SJE+jcuTP27duH8PBwAEBSUhKGDRuGixcvIiAg4J55a7VauLu7o6CgAG5ubsb85BplXS/GgPnb0cTBDifmRt/7A0RERFRrxpy/jRqpKSsrQ3p6OtRq9e0DKJVQq9VITU2t8jOpqamyeACIioqqFJ+SkgJfX1906NABL7/8Mq5fvy47hoeHh1TQAIBarYZSqcTevXuN+QkmV7H6ifNpiIiIrMvemOBr165Br9fDz89P1u7n54fMzMwqP6PRaKqM12g00nZ0dDSeeOIJtG7dGmfOnMFbb72FoUOHIjU1FXZ2dtBoNPD19ZUnbm8PLy8v2XHuVFpaitLSUmlbq9Ua81NrrWKiMFc+ERERWZdRRY25jBo1SnrfrVs3hISEoG3btkhJScHgwYPrdMyEhATMmTPHVClWq2JJN0dqiIiIrMuo4QUfHx/Y2dkhJydH1p6TkwN/f/8qP+Pv729UPAC0adMGPj4+OH36tHSMuycil5eXIy8vr9rjxMXFoaCgQHplZ2ff8/fVhU567hNHaoiIiKzJqDOxSqVCWFgYkpOTpTaDwYDk5GRERkZW+ZnIyEhZPABs2bKl2ngAuHjxIq5fv47mzZtLx8jPz0d6eroUs23bNhgMBkRERFR5DEdHR7i5ucle5lCxpFtlz6KGiIjImow+E8fGxuKLL77AV199hRMnTuDll19GUVERxo8fDwAYO3Ys4uLipPhXX30VSUlJ+Oijj5CZmYnZs2dj//79mDJlCgDgxo0beOONN7Bnzx6cP38eycnJeOyxx9CuXTtERUUBADp16oTo6GhMnDgRaWlp+O233zBlyhSMGjWqViufzKmcT+gmIiKqF4yeUzNy5EhcvXoV8fHx0Gg0CA0NRVJSkjQZOCsrC8o7LsX06dMHa9aswTvvvIO33noL7du3x4YNG9C1a1cAgJ2dHQ4fPoyvvvoK+fn5CAgIwJAhQzB37lw4OjpKx1m9ejWmTJmCwYMHQ6lUIiYmBosXL77f33/fdHxCNxERUb1g9H1qGipz3afm7NUb+P7gJXg3VeH5vq1NdlwiIiIy7vxdL1Y/NWRtmrngtSEdrJ0GERFRo8drJkRERGQTWNQQERGRTWBRQ0RERDaBRQ0RERHZBBY1REREZBNY1BAREZFNYFFDRERENoFFDREREdkEFjVERERkE1jUEBERkU1gUUNEREQ2gUUNERER2QQWNURERGQTGs1TuoUQAG49wpyIiIgahorzdsV5vCaNpqgpLCwEAAQFBVk5EyIiIjJWYWEh3N3da4xRiNqUPjbAYDDg8uXLcHV1hUKhMOmxtVotgoKCkJ2dDTc3N5Me29awr2qPfVV77KvaY1/VHvuq9szZV0IIFBYWIiAgAEplzbNmGs1IjVKpRIsWLcz6HW5ubvyDX0vsq9pjX9Ue+6r22Fe1x76qPXP11b1GaCpwojARERHZBBY1REREZBNY1JiAo6MjZs2aBUdHR2unUu+xr2qPfVV77KvaY1/VHvuq9upLXzWaicJERERk2zhSQ0RERDaBRQ0RERHZBBY1REREZBNY1BAREZFNYFFzn5YuXYrg4GA4OTkhIiICaWlp1k7JrBISEtCzZ0+4urrC19cXI0aMwMmTJ2UxJSUlmDx5Mry9veHi4oKYmBjk5OTIYrKysjB8+HA4OzvD19cXb7zxBsrLy2UxKSkpePDBB+Ho6Ih27dph1apV5v55ZpWYmAiFQoFp06ZJbeyr2y5duoRnn30W3t7eaNKkCbp164b9+/dL+4UQiI+PR/PmzdGkSROo1WqcOnVKdoy8vDyMGTMGbm5u8PDwwIQJE3Djxg1ZzOHDh9G/f384OTkhKCgI8+bNs8jvMxW9Xo93330XrVu3RpMmTdC2bVvMnTtX9lycxtxXO3fuxCOPPIKAgAAoFAps2LBBtt+SfbN+/Xp07NgRTk5O6NatGzZv3mzy33s/auornU6HGTNmoFu3bmjatCkCAgIwduxYXL58WXaMetdXgups7dq1QqVSiRUrVohjx46JiRMnCg8PD5GTk2Pt1MwmKipKrFy5Uhw9elRkZGSIYcOGiZYtW4obN25IMS+99JIICgoSycnJYv/+/aJ3796iT58+0v7y8nLRtWtXoVarxcGDB8XmzZuFj4+PiIuLk2LOnj0rnJ2dRWxsrDh+/Lj45JNPhJ2dnUhKSrLo7zWVtLQ0ERwcLEJCQsSrr74qtbOvbsnLyxOtWrUSzz//vNi7d684e/as+Pnnn8Xp06elmMTEROHu7i42bNggDh06JB599FHRunVrcfPmTSkmOjpadO/eXezZs0f8+uuvol27dmL06NHS/oKCAuHn5yfGjBkjjh49Kr755hvRpEkT8dlnn1n0996P999/X3h7e4uNGzeKc+fOifXr1wsXFxfxz3/+U4ppzH21efNm8fbbb4vvvvtOABDff/+9bL+l+ua3334TdnZ2Yt68eeL48ePinXfeEQ4ODuLIkSNm74Paqqmv8vPzhVqtFuvWrROZmZkiNTVV9OrVS4SFhcmOUd/6ikXNfejVq5eYPHmytK3X60VAQIBISEiwYlaWlZubKwCIHTt2CCFu/UVwcHAQ69evl2JOnDghAIjU1FQhxK2/SEqlUmg0Gilm2bJlws3NTZSWlgohhHjzzTdFly5dZN81cuRIERUVZe6fZHKFhYWiffv2YsuWLWLgwIFSUcO+um3GjBmiX79+1e43GAzC399fzJ8/X2rLz88Xjo6O4ptvvhFCCHH8+HEBQOzbt0+K+emnn4RCoRCXLl0SQgjx6aefCk9PT6nvKr67Q4cOpv5JZjN8+HDxt7/9Tdb2xBNPiDFjxggh2Fd3uvtEbcm+efrpp8Xw4cNl+URERIgXX3zRpL/RVKoqAO+WlpYmAIgLFy4IIepnX/HyUx2VlZUhPT0darVaalMqlVCr1UhNTbViZpZVUFAAAPDy8gIApKenQ6fTyfqlY8eOaNmypdQvqamp6NatG/z8/KSYqKgoaLVaHDt2TIq58xgVMQ2xbydPnozhw4dX+j3sq9t+/PFHhIeH46mnnoKvry969OiBL774Qtp/7tw5aDQa2e90d3dHRESErK88PDwQHh4uxajVaiiVSuzdu1eKGTBgAFQqlRQTFRWFkydP4o8//jD3zzSJPn36IDk5Gb///jsA4NChQ9i1axeGDh0KgH1VE0v2jS38vbxbQUEBFAoFPDw8ANTPvmJRU0fXrl2DXq+XnWwAwM/PDxqNxkpZWZbBYMC0adPQt29fdO3aFQCg0WigUqmkP/QV7uwXjUZTZb9V7KspRqvV4ubNm+b4OWaxdu1aHDhwAAkJCZX2sa9uO3v2LJYtW4b27dvj559/xssvv4xXXnkFX331FYDbv7Wmv28ajQa+vr6y/fb29vDy8jKqP+u7mTNnYtSoUejYsSMcHBzQo0cPTJs2DWPGjAHAvqqJJfumupiG2nclJSWYMWMGRo8eLT2wsj72VaN5SjeZ3uTJk3H06FHs2rXL2qnUS9nZ2Xj11VexZcsWODk5WTudes1gMCA8PBwffPABAKBHjx44evQoli9fjnHjxlk5u/rl22+/xerVq7FmzRp06dIFGRkZmDZtGgICAthXZBY6nQ5PP/00hBBYtmyZtdOpEUdq6sjHxwd2dnaVVqrk5OTA39/fSllZzpQpU7Bx40Zs374dLVq0kNr9/f1RVlaG/Px8Wfyd/eLv719lv1XsqynGzc0NTZo0MfXPMYv09HTk5ubiwQcfhL29Pezt7bFjxw4sXrwY9vb28PPzY1/9qXnz5ujcubOsrVOnTsjKygJw+7fW9PfN398fubm5sv3l5eXIy8szqj/ruzfeeEMarenWrRuee+45TJ8+XRoNZF9Vz5J9U11MQ+u7ioLmwoUL2LJlizRKA9TPvmJRU0cqlQphYWFITk6W2gwGA5KTkxEZGWnFzMxLCIEpU6bg+++/x7Zt29C6dWvZ/rCwMDg4OMj65eTJk8jKypL6JTIyEkeOHJH9Zaj4y1JxYouMjJQdoyKmIfXt4MGDceTIEWRkZEiv8PBwjBkzRnrPvrqlb9++lW4N8Pvvv6NVq1YAgNatW8Pf31/2O7VaLfbu3Svrq/z8fKSnp0sx27Ztg8FgQEREhBSzc+dO6HQ6KWbLli3o0KEDPD09zfb7TKm4uBhKpfyfbjs7OxgMBgDsq5pYsm9s4e9lRUFz6tQpbN26Fd7e3rL99bKvjJ5aTJK1a9cKR0dHsWrVKnH8+HExadIk4eHhIVupYmtefvll4e7uLlJSUsSVK1ekV3FxsRTz0ksviZYtW4pt27aJ/fv3i8jISBEZGSntr1imPGTIEJGRkSGSkpJEs2bNqlym/MYbb4gTJ06IpUuXNrhlylW5c/WTEOyrCmlpacLe3l68//774tSpU2L16tXC2dlZfP3111JMYmKi8PDwED/88IM4fPiweOyxx6pcitujRw+xd+9esWvXLtG+fXvZ8tL8/Hzh5+cnnnvuOXH06FGxdu1a4ezsXO+XKd9p3LhxIjAwUFrS/d133wkfHx/x5ptvSjGNua8KCwvFwYMHxcGDBwUAsXDhQnHw4EFpxY6l+ua3334T9vb2YsGCBeLEiRNi1qxZ9W5Jd019VVZWJh599FHRokULkZGRIfv3/s6VTPWtr1jU3KdPPvlEtGzZUqhUKtGrVy+xZ88ea6dkVgCqfK1cuVKKuXnzpvj73/8uPD09hbOzs3j88cfFlStXZMc5f/68GDp0qGjSpInw8fERr732mtDpdLKY7du3i9DQUKFSqUSbNm1k39FQ3V3UsK9u+9///ie6du0qHB0dRceOHcXnn38u228wGMS7774r/Pz8hKOjoxg8eLA4efKkLOb69eti9OjRwsXFRbi5uYnx48eLwsJCWcyhQ4dEv379hKOjowgMDBSJiYlm/22mpNVqxauvvipatmwpnJycRJs2bcTbb78tO9E05r7avn17lf9GjRs3Tghh2b759ttvxQMPPCBUKpXo0qWL2LRpk9l+d13U1Ffnzp2r9t/77du3S8eob32lEOKO21ASERERNVCcU0NEREQ2gUUNERER2QQWNURERGQTWNQQERGRTWBRQ0RERDaBRQ0RERHZBBY1REREZBNY1BAREZFNYFFDRERENoFFDREREdkEFjVERERkE1jUEBERkU34f/gi2qwYb5JBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.convolve(corrs, [1]*100, \"valid\")/100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63fd3441-09e9-4e16-8e6a-e16db26ca980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbcd9279e10>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.convolve(losses, [1]*100, \"valid\")/100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24489d70-70ca-4c08-b896-14a393e906a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(opt_r.state_dict(), \"small_hiera_1016.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2187d-f3c1-4bd6-805d-75a87a1fb126",
   "metadata": {},
   "source": [
    "# Another 200 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc8d99-bfc5-4e63-9d57-c63d55f83b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2493495497672485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:28,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24698720524257822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:55,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2548009030297455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:23,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25241333779929065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "331it [01:32,  3.40it/s]"
     ]
    }
   ],
   "source": [
    "for train_loop in range(200):\n",
    "    for i, (k, b) in tqdm(enumerate(train_dl)):\n",
    "        videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        #with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        #    out = opt_r(videos, k);\n",
    "        #    loss = criteria(out.transpose(1,2), responses)\n",
    "        out = opt_r(videos, k);\n",
    "        loss = criteria(out.transpose(1,2), responses)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(opt_r.parameters(), max_norm=1.0, norm_type=2)\n",
    "        opt.step()\n",
    "\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        with warmup_scheduler.dampening():\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "        if i % 10 ==0:\n",
    "            r2 = responses.to(torch.float32).cpu().numpy().flatten()\n",
    "            r1 = out.transpose(1,2).detach().cpu().to(torch.float32).numpy().flatten()\n",
    "            corrs.append(np.corrcoef(r1,r2)[0,1].item())\n",
    "            lrs.append(opt.param_groups[0]['lr'])\n",
    "        if i % 100 ==0:\n",
    "            print(np.corrcoef(r1,r2)[0,1].item())\n",
    "    for k, v in train_dl.loaders.items():\n",
    "        v.dataset.shuffle_valid_screen_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b09f9-4acd-4180-b008-d856b559fe17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d789f-ab26-4d35-a9a6-e4b73286100b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fbe2d9-03de-416d-865b-8c2d21900c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ec2eacb-7523-42de-96a7-bbe67463972d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"_amp_foreach_non_finite_check_and_unscale_cuda\" not implemented for 'BFloat16'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m criteria(out\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m), responses)\n\u001b[1;32m      7\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     10\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:424\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m OptState\u001b[38;5;241m.\u001b[39mREADY:\n\u001b[0;32m--> 424\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_inf_per_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_scale_async()\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:680\u001b[0m, in \u001b[0;36mGradScaler._check_inf_per_device\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    675\u001b[0m dummy_inv_scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((), \u001b[38;5;241m1.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    676\u001b[0m found_inf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((), \u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_per_optimizer_states[\u001b[38;5;28mid\u001b[39m(optimizer)][\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 680\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unscale_grads_\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_inv_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_per_optimizer_states[\u001b[38;5;28mid\u001b[39m(optimizer)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:279\u001b[0m, in \u001b[0;36mGradScaler._unscale_grads_\u001b[0;34m(self, optimizer, inv_scale, found_inf, allow_fp16)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m device, per_dtype_grads \u001b[38;5;129;01min\u001b[39;00m per_device_and_dtype_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m grads \u001b[38;5;129;01min\u001b[39;00m per_dtype_grads\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 279\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_amp_foreach_non_finite_check_and_unscale_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                \u001b[49m\u001b[43mper_device_found_inf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                \u001b[49m\u001b[43mper_device_inv_scale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m per_device_found_inf\u001b[38;5;241m.\u001b[39m_per_device_tensors\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"_amp_foreach_non_finite_check_and_unscale_cuda\" not implemented for 'BFloat16'"
     ]
    }
   ],
   "source": [
    "losses, corrs = [], []\n",
    "for _ in tqdm(range(200)):\n",
    "    \n",
    "    videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "    responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "    with autocast(\"cuda\", )\n",
    "        out = opt_r.generate(videos, k);\n",
    "    loss = criteria(out.transpose(1,2), responses)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(opt)\n",
    "    scaler.update()\n",
    "    opt.zero_grad()\n",
    "    losses.append(loss.item())\n",
    "    neuron=0\n",
    "    r2 = responses.to(torch.float32).cpu().numpy().flatten()\n",
    "    r1 = out.transpose(1,2).detach().cpu().to(torch.float32).numpy().flatten()\n",
    "    corrs.append(np.corrcoef(r1,r2)[0,1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44391934-bac0-43c1-8746-7be9c1ba82b2",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff07b24a-c41d-43ef-a810-228683ecd536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f90b4d9c490>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6PUlEQVR4nO3deXxU9b3/8ffMJDPZFwhJIAQCgqKyBFlitLjUKLVeq7a2SK1QXHptxWub2lupLWjtvbFX6w9bqVattbVVqG1dapV7bVTUyiKBsAoiW9iSECB7MpPMfH9/JBkIJJCBZM5k5vV8POaRmXPOnHzmgMzb73ZsxhgjAAAAi9itLgAAAEQ2wggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFJRVhfQEz6fT/v371diYqJsNpvV5QAAgB4wxqiurk5DhgyR3d59+0e/CCP79+9Xdna21WUAAIDTsGfPHg0dOrTb/f0ijCQmJkpq+zBJSUkWVwMAAHqitrZW2dnZ/u/x7vSLMNLRNZOUlEQYAQCgnznVEAsGsAIAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgqX5xozwAAILF6zNq9fnU6jVq9Rm1en3t24x8xsgYyWeMfO0/Tftz70n2e30d207c7/OdeC7//vZz9mS/Mabb856w/4TzSrd9boSyB8RZcs0JIwCAXuP1GbV4ffJ4277MW7y+9kfbl3pL+7ZW3zHPvcZ/fKvPJ0+rzx8CPP73tZ/juPd13t7VvrZzdWzvqM/bvs17bOjwtR1rjNVX0Rpfyh1CGAEAnBljjJpavGryeNXU4lVzi1fNLb4Tth193rbP3eqVp7Xti7vtZ1s46LytLRgcv63F65P7mG2+MP0id9htstsku83W/twmW/vrju229ufd7+94bZP9mPPZbfK/9+j+o8+7+j2OU+zvqKPzeTt+T9f7M5JiLLu+hBEAsJAxRo0er2qaWvyPuuZWNXpaVe9uVYO7VQ1ub9tPz9Hn9e5WNXqOPm9wt6qxxRty/1fvsNsUZbfJ6bArymFTlMN+9LndpmiHXdHtr9ue2xRltx993v4z2n7cMe3vi7bbFB1l7+Jcba/bzmXr9Dsc9rbzOew2/7mi7DZFOWxH9x3zOx3t4QF9hzACAL3E0+rTkUaPqurdOlTv0aGGtp+1xwSN6mOed2xv8fZ+gnBF2RXrdCgmytH2M9qh2Oi2bbHRHa/bfsZE2/1f5M6otrDgjDoaCE7cdvxxbV/yro79UUcDBF/i6AnCCACchNdndKjerYpatypqm1VR16yKWrcOtQeOww0eVbWHjpqmltP+PdEOm5Jjo5UUG63EmGgluByKd0Yp3hWleJej7Wf76wSXQ3HOKCW4ohTndLRvi1Jc+3tiox2EAPQrhBEAEcsYo5qmFu090qT91U3aV330577qZpXXNOlgnTugcRAOu00D4p0aGO/UwASnUuPaHsmx0UcfcdGdXqfERSs22iGbjQCByEQYARDWaptbtLuqUXuPNGrvkaZjfrY9b/B4T3kOu00alOhSRlKM0hNjlJ7kUlqCS2kJTg2Md2lggtP/PDk2mlYJIECEEQD9ns9ntK+6SZ9V1uvTijptq6zXzqoG7apq0KEGzynfPzDeqazUWA1Jjm37mRKrrJRYDU6OUWZyjNISXHIQMIA+QxgB0K+4W7365ECd1u+t1vq9Nfq0ok6fVdar8SQtHGkJTmUPiNPQ1DgNTY1tf7Q9H5Icq1inI4ifAMDxCCMAQlp5TbNW7jyk1buOaP3eam0+UNvl7JNoh00j0xI0OiNBo9MTdVZ6vHIGxmv4wDglxkRbUDmAniKMAAgptc0tendLpVbsOKQVOw5rZ1XDCccMiHdq/NBkjR+aovMGJ2pUeqJyBsYpysHttoD+iDACwHK7DzXo7+v2a+XOw1q547A8Xp9/n90mnT8kWVNHDFBudopys1M0NDWWmSdAGCGMAAg6r89ow74alZYd0Wvr9mttWXWn/aPSE3T5OYN04ciBmpwzQMmxdLMA4YwwAiBoqhs9eu7DnXpzY7k+q6z3b7fbpItHpenK8zJ04ciBOjsj0cIqAQTbaYWRRYsW6ZFHHlF5ebkmTJigX/3qV5o6deop37d48WLNnDlT1113nV599dXT+dUA+qH3Pz2oFTsO6a9r9qqi1i1Jinc6NG5osq48L1PXThis9ETrbtIFwFoBh5ElS5aosLBQTz31lPLy8rRw4UJNnz5dW7duVXp6erfv27Vrl+69915NmzbtjAoG0H+8VrpPz3+0q1M3zIi0eN0xbaSuGT+Y7hcAkiSbMYHd4zEvL09TpkzRE088IUny+XzKzs7W3Xffrfvuu6/L93i9Xl1yySW69dZb9cEHH6i6ujqglpHa2lolJyerpqZGSUlJgZQLIMhavD59cqBWy7Ye1C/e/lRS2xLpV4/N1KVnD9K1E4YoJpp1PYBI0NPv74BaRjwej0pKSjRv3jz/NrvdroKCAi1fvrzb9/30pz9Venq6brvtNn3wwQeB/EoA/YTXZ/Ra6T49/f4ObSmv82+/YWKW/uOK0RqRFm9hdQBCWUBhpKqqSl6vVxkZGZ22Z2RkaMuWLV2+58MPP9Rvf/tblZaW9vj3uN1uud1u/+va2tpAygRggZ8v3aKn39/hf52R5NId00bq1otHcK8WACfVp7Np6urqdMstt+iZZ55RWlpaj99XVFSkBx98sA8rA9Ab3K1e/fiVjVq+45D2HmmSJH3h/EzN++IYDR9ISwiAngkojKSlpcnhcKiioqLT9oqKCmVmZp5w/Pbt27Vr1y5de+21/m0+X9tiRlFRUdq6davOOuusE943b948FRYW+l/X1tYqOzs7kFIBBMFzH+7SyyV7/a+vzx2ihTdNtLAiAP1RQGHE6XRq0qRJKi4u1vXXXy+pLVwUFxdr7ty5Jxw/ZswYbdiwodO2H//4x6qrq9Pjjz/ebcBwuVxyuVyBlAYgiGoaW/TgG5v0tzX7/Nu+eVGO7r/mXAurAtBfBdxNU1hYqNmzZ2vy5MmaOnWqFi5cqIaGBs2ZM0eSNGvWLGVlZamoqEgxMTEaO3Zsp/enpKRI0gnbAfQfd724Rh9+ViVJumbcYP1y5kQ5GBcC4DQFHEZmzJihgwcPav78+SovL1dubq6WLl3qH9RaVlYmu52bVQGhpsHdqjc3HJAzyq7rcrNO6xyLV5Xpv/7xiercrZKkv9yZr8k5A3qzTAARKOB1RqzAOiPAmSn+pEL3v7JR5bXNkqS37pmmcwcH9t/Spv01uuaXH/pfjx+arNfnfq5X6wQQXvpknREA/cvhBo8e/PsmvVa6v9P21bsOBxRGjjR4tOC1TZ22TaFFBEAvIYwAYcgYozfWH9ADr2/SoQaP7Dbp9mkjZZP0m/d3aG1ZtW7J79m5SvdU6/pF/5IkRTts+vrUYfrX9kOac3FOn9UPILIQRoAwU+9u1U9e3ahX1rbNdDknI1E/v3G8crNT9N7WyrYwsqf6lOdxt3pVuGSd3tx4wL9tdn6Ofvxv5/VV6QAiFGEECCMb99Vo7otrtOtQo+w2ae7nR2vu5aPkjGobVJ6bnSJJ2lnVoHp3qxJcJ/4T4Gn1qdHTqo+2H9I/NhwNIrPyh+tHX2TqLoDeRxgBwoAxRi+s2K2fvfGJPF6fhiTH6PGZE08Y15ES51SU3aZWn1Fdc0uXYWTWcyu1Ysdh/dv4wZ22f3HcYJZ1B9AnCCNAP9fi9emB1zfpTyvLJElXnZeh/7lxvFLinF0eH+t0qK65VY0eb5f7V+w4LEl6Y/2BTtsDnX0DAD1FGAH6sZqmFs19cY0+2FYlm02ad/UY3TFtpGy27lsw4trDSJPHqzc3HNC4rGRlD4iT1NbC0p3k2Oherx8AJMII0G+VHWrUrb//WJ9V1is22qFfzpyoK8/LOOX7YqMdkqR3t1TqF29/qkvPHqTf3zpV/7upXL9+97NOx6YlOHX12MH63Oie3+gSAAJFGAH6oZLdh3XHH0p0uMGjzKQYPTt7ssZmJffovbHOtv/sN+6vkSRV1rklSf/+QskJx47LStZD13PrBgB9izAC9DOvle7TD/6yXp5Wn8ZmJenZWVOUmRzT4/fHOdtaRnYfapQkuVu6HjsiSWMYJwIgCAgjQD9hjNHCf27T48XbJLUNVF14U67inIH9Z9zRTbPrUIMkyd3qk9fX9ViRMZmJZ1AxAPQMYQToB5pbvPrPv6zX6+valnX/90tG6odfGHNaU21j21tGmlt8/nOXHW7s8tjhA+NPs2IA6DnCCBDiqurd+tYfVmtNWbWi7Db97PqxumnqsNM+X0c3TYdDDR5d/uh7Jxx346ShGt/DcSgAcCYII0AI21ZRpznPf6y9R5qUFBOlp74xSReNOrOZLR3dNCfz+THpevSrE87o9wBATxFGgBC1eX+tvvHblTrc4NHwgXF67ptTdNaghDM+b6zz1GEkMYZ/GgAED//iACFo2acH9e0/lqjR49X4ocl6fs5UDYjvekXVQB3fTdMVwgiAYLJbXQCAzlbuOKRv/WG1Gj1eXXTWQL1wW16vBRGp+26a84ccncYb6AwdADgThBEghPzrsyrd9vvVcrf69Pkx6fr9rVN7fRn22G6CxsxjBsV2N9UXAPoC//sDhIjXSvfpe0tK5TNS3ogB+vXNFyja0fv/v9BdN82xXTOEEQDBRMsIEAL+ublChX9eJ5+RvnxBln5/61TF9GDWy+noLowc233T6vP1ye8GgK7QMgJYbPn2Q/rOi2vk9RndMDFLj9444bQWM+up7kLOseNEpuQM6LPfDwDHI4wAFvpg20H9+wsl8rT6dOV5GXrkxvF9GkSkk7SMOO16797LVLqnWteOH9KnNQDAsQgjgEWWbjygu19aqxav0bTRafrVzImK6oMxIsfrvpsmSjlp8cpJYwl4AMHFmBHAAjsO1ut7S9apxWt0zfjBenb25D4bI3K8Y39PatzRmTo9WX8EAPoCYQQIsmWfHtSNTy1XU4tX+SMH6pc3TZQrKnhB4NixIcOOuREeYQSAVeimAYKobYzIajW3+DQ6PUG/+NoEOfp4jMjx0hNdinc6lJboUqLr6D8BPVkmHgD6AmEECJKlGw/ozj+ukSRdds4g/eaWSUFtEekQ74rS24WXKibaobkvrvFv78kN9ACgLxBGgCCorG3Wgtc3SZK+PDFL/3XDOEuCSIchKbGSJJ85urhZMAbPAkBXCCNAHzLG6Hf/2qXH3v5U9e5WDR8Yp//+8rigDVY9FdY2AxAKCCNAH3q8eJsW/nObJGnC0GQ98tUJIRNEpM4tIwBgFcII0Ef+tHK3P4jcd/UYfWvayD5f0CxQRBEAoYAwAvSyyrpmvbWhXA/8vW2MyH98fpTuvPQsi6vqGjfEAxAKCCNALzpU79YNiz7SvuomSdLnRqXpe1eebXFV3TN00wAIAQyfB3rJ9oP1+upvlvuDSGy0Q/dfc65sttDqmjkWDSMAQgEtI0AvOFjn1qzfrtK+6iZlJsXo2dmTlZUSq9R4p9WlndSMKdnasK9Gk4enWl0KgAhGGAF6wTMf7NC+6iaNSIvXy3fmKy3BZXVJPfL1qcM0JjNR5w5OsroUABGMMAKcpheW79LuQ41asfOQNu6rlST98Avn9JsgIkl2u02TcwZYXQaACEcYAU7DpxV1+slrm07Yftk56RZUAwD9G2EECMCyTw9q+fZDiok+cez3VycNDakFzQCgvyCMAD3U6vVp9nOrOm0rvPJsfeuSkdpzuFHZA+IsqgwA+jfCCNAD7396ULOOCyI2W9tslJhoh0ZnJFpUGQD0f6wzAvTAb97ffsK2z41KU0ZSjAXVAEB4IYwAxzHGaMnHZfr7uv0yxqjV69PHu46ccNy1E4ZYUB0AhB+6aYBjGGP08Ftb9Jv3d0iS3li/X9++bJQ8rT4lxkSpdP5VWvxxmT4tr9MNE7MsrhYAwgNhBGjX5PHq3pfX6R8bDvi3/e+mCi3ffkiSNHl4qhx2m27OG25ViQAQlggjgKSK2mbd/vvV2rCvRtEOm3563VhJ0ry/bVBtc6skadzQFAsrBIDwRRhBxNu0v0a3/361DtQ0KzUuWk/PmqwpOQO0s6qh03E5A5m6CwB9gTCCiPb25grds3itGj1enTUoXs99c4qGD4yXJA1NjZXDbpO3/da2HdsBAL2LMIKI5PUZ/eqdbXq8eJuMaZumu+jmC5QcG+0/Jtph16AEl8prmyVJw2kZAYA+QRhBxKmsa9bdL67Vyp2HJUk35w3TA186X9GOE2e6O+w2//OB8c6g1QgAkYQwgoiybk+1/v2FEpXXNive6dB/3TBO1/dwiq7NZjv1QQCAgLHoGSKCMUZ/Xr1HX/3NcpXXNmtUeoL+fvfnThlErh6bKUnKHhAbjDIBICLRMoKwV93o0f2vbPSvH1Jwbob+34wJSoyJPsU7pcKrzlZmcoymn5/Z12UCQMQijCCsfbDtoO59eZ0qat2Kstv0vSvP1rcvPUt2e8+6XOKcUbp92sg+rhIAIhthBGGpucWrny/dot/9a5ckaeSgeC2ckavxLFwGACGHMIKws3Ffjb63pFTbKuslSbdcOFw/+uK5inU6LK4MANAVwgjCRqvXp9+8v0P/7+1P1eozGpTo0v98ZbwuH5NudWkAgJMgjCAs7Kpq0PdfXqeS3Ucktc2C+a8bxmkAa4MAQMgjjKBfM8boTyvL9F//+ERNLV4luqL04HXn64aJWawLAgD9BGEE/VZ5TbP+86/r9f6nByVJ+SMH6pGvjtfQVJZtB4D+hDCCfsfnM3rp4zI9/OYW1blb5Yqy64dfGKNvXpTT4ym7AIDQQRhBv7LjYL3u+9sGrWq/r8yE7BT94qvjNSo90eLKAACnizCCfqHF69PT7+/Q48Xb5Gn1KTbaoR9MP0ezL8rpdDM7AED/QxhByNtSXqt7X16njftqJUnTRqfpv28Yp+wBjA0BgHBAGEHIavH69Jtl2/V48Ta1eI2SYqK04Nrz9eULmCkDAOGEMIKQ9GlFnQr/XOpvDSk4N13/fcM4pSfFWFwZAKC3EUYQUowxemHFbv3sH5/I0+pTUkyUHvgS64YAQDizn86bFi1apJycHMXExCgvL0+rVq3q9ti//e1vmjx5slJSUhQfH6/c3Fy98MILp10wwteherdu//1qzX9tkzytPl12ziD9s/BSffmCoQQRAAhjAbeMLFmyRIWFhXrqqaeUl5enhQsXavr06dq6davS00+8B8iAAQN0//33a8yYMXI6nXrjjTc0Z84cpaena/r06b3yIdD/rdxxSHe/tFaVdW45HXbN+2LbuiGEEAAIfzZjjAnkDXl5eZoyZYqeeOIJSZLP51N2drbuvvtu3XfffT06xwUXXKBrrrlGDz30UI+Or62tVXJysmpqapSUlBRIuQhxxhj9/qNd+tk/PlGrz2h0eoJ+OXOizh3MnzMA9Hc9/f4OqJvG4/GopKREBQUFR09gt6ugoEDLly8/5fuNMSouLtbWrVt1ySWXdHuc2+1WbW1tpwfCT3OLV99/eZ0e+PtmtfqMvjRhiF6bezFBBAAiTEDdNFVVVfJ6vcrIyOi0PSMjQ1u2bOn2fTU1NcrKypLb7ZbD4dCvf/1rXXnlld0eX1RUpAcffDCQ0tDP7D3SqDv/WKKN+2rlsNs07+oxuu1zI+iWAYAIFJTZNImJiSotLVV9fb2Ki4tVWFiokSNH6rLLLuvy+Hnz5qmwsND/ura2VtnZ2cEoFUHw0fYq3fWnNTrS2KIB8U498fWJuuisNKvLAgBYJKAwkpaWJofDoYqKik7bKyoqlJmZ2e377Ha7Ro0aJUnKzc3VJ598oqKiom7DiMvlksvlCqQ09BOvle7TvS+vU4vXaFxWsp66ZZKyUmKtLgsAYKGAxow4nU5NmjRJxcXF/m0+n0/FxcXKz8/v8Xl8Pp/cbncgvxph4NkPduiexaVq8RpdM26wXr4znyACAAi8m6awsFCzZ8/W5MmTNXXqVC1cuFANDQ2aM2eOJGnWrFnKyspSUVGRpLbxH5MnT9ZZZ50lt9utN998Uy+88IKefPLJ3v0kCFk+n9HDS7fo6fd3SJK+eVGO5v/bebJzgzsAgE4jjMyYMUMHDx7U/PnzVV5ertzcXC1dutQ/qLWsrEx2+9EGl4aGBn3nO9/R3r17FRsbqzFjxuiPf/yjZsyY0XufAiHL0+rTf/5lnV4t3S9J+uEXxujOS0cyUBUA4BfwOiNWYJ2R/qne3apv/7FEH2yrksNu08+/Ml43ThpqdVkAgCDp6fc396ZBnzhY59ac51dp475axUY79OtvXKDLzzlxhV4AAAgj6HX7q5v09WdWaNehRg2Id+q5b05RbnaK1WUBAEIUYQS9au+RRs18ZoX2HG7S0NRYvXBbnkakxVtdFgAghBFG0Gv2HG7UTU+v0L7qJg0fGKcX77iQqbsAgFMijKBXlB1qaxHZV92kEWnxevGOPA1OJogAAE6NMIIztquqQTOfWaEDNc0aOSheL91xoTKSYqwuCwDQTxBGcEZ2VTXopqdXqLy2WaPSE/Ti7XlKJ4gAAAJAGMFp23ukUV9/pi2InJ2RoD/dfqEGJXJPIQBAYAK6Nw3QobK2Wd94dqX2t3fNEEQAAKeLMIKAHW7w6OZnV2rXoUYNTY3Vn27PI4gAAE4bYQQBqWlq0S2/XaltlfXKSHLpxdsvZNYMAOCMEEbQY80tXt32/MfatL9WA+Od+tPtF2rYwDirywIA9HOEEfSIz2f0vSWlWr37iBJjovSH26ZqVHqC1WUBAMIAYQQ9UvTWJ3prY7miHTY9fctknT8k2eqSAABhgjCCU/rD8l165oOdkqRHbpyg/LMGWlwRACCcEEZwUv/cXKEHXt8kSbr3qrN1/cQsiysCAIQbwgi6tX5vte5+aa18RrppSrbuunyU1SUBAMIQYQRd2nO4Ubc+v1pNLV5dcvYgPXT9WNlsNqvLAgCEIcIITlDT2KI5z3+sqnq3xmQmatHXJyrawV8VAEDf4BsGnXhaffr3P67WZ5X1ykyK0e/mTFFiTLTVZQEAwhhhBJ389I1NWrHjsBJcUfrdnCmsrgoA6HOEEfgt+bhMf1xRJptN+uXMXJ07OMnqkgAAEYAwAknSmrIj+smrbVN4CwvO1ufHZFhcEQAgUhBGoMq6Zn37jyXyeH266rwMpvACAIKKMBLhvD6juS+uVUWtW6PSE/TYjFzZ7UzhBQAED2Ekwi169zOt2nlY8U6Hnr5lkhJcUVaXBACIMISRCFay+7AeL94mSXro+rEaOYi78AIAgo8wEqFqmlr0Hy+VyuszumFilr58wVCrSwIARCjCSIT66d83a191k4YNiNNPrzvf6nIAABGMMBKB3ttaqb+u2SubTfp/M3JZYRUAYCnCSISpd7fq/lc2SpLmXDRCk4anWlwRACDSEUYizM/f2qJ91U3KHhCre6efbXU5AAAQRiLJmrIjemHFbknSw18erzgn03gBANYjjEQIn8/op3/fLEn6ygVDdfGoNIsrAgCgDWEkQry2bp9K91Qr3unQD79wjtXlAADgRxiJAI2eVv38ra2SpO9cPkrpSTEWVwQAwFGEkQjw1LIdKq9t1tDUWN32uRFWlwMAQCeEkTBXWdesp9/fLkn60RfPVUy0w+KKAADojDAS5n797nY1t/iUm52iq8dmWl0OAAAnIIyEsX3VTXpxZZkk6QfTz5HNZrO4IgAATkQYCWO/Kt4mj9enC0cO0EVnDbS6HAAAukQYCVM7qxr0csleSdK9V9EqAgAIXYSRMPWrd7bJ6zO67JxBmpwzwOpyAADoFmEkDJXXNOv10v2SpHuuGG1xNQAAnBxhJAw9/9EutfqMpuSkauIw7soLAAhthJEw0+Bu1Ysr226Gd/u0kRZXAwDAqRFGwsyfV+9RbXOrcgbGqeDcDKvLAQDglAgjYcTrM3ruXzslSbd9boQcdmbQAABCH2EkjPzvpnLtOdyklLho3Tgp2+pyAADoEcJIGHnmgx2SpFsuHK5YJ/egAQD0D4SRMFGy+7DWllXL6bDrlvzhVpcDAECPEUbCxDPvt40VuX7iEKUnxlhcDQAAPUcYCQO7DzXofzeXS2I6LwCg/yGMhIHnPtwpY6RLzx6kszMSrS4HAICAEEb6uepGj/68uu2GeHfQKgIA6IcII/3cn1aWqanFqzGZibp41ECrywEAIGCEkX7M0+rT7z/aJamtVcRmY5EzAED/Qxjpx15ft1+VdW5lJLl07YQhVpcDAMBpIYz0U8YYPdu+yNnsi3LkjOKPEgDQP/EN1k99+FmVtpTXKc7p0M1TWeQMANB/EUb6qd9+2LbI2dcmZys5LtriagAAOH2EkX5o96EGvbf1oCRpzsU51hYDAMAZIoz0Qy+uLJPUtsjZ8IHxFlcDAMCZIYz0M80tXv159R5J0jcuZKwIAKD/I4z0M29uOKAjjS0akhyjz49Jt7ocAADOGGGkn3ll7T5J0k1Th8lhZ5EzAED/RxjpRw7Vu/XR9kOSpOtyWeQMABAeTiuMLFq0SDk5OYqJiVFeXp5WrVrV7bHPPPOMpk2bptTUVKWmpqqgoOCkx6N7/7e5Ql6f0disJAauAgDCRsBhZMmSJSosLNSCBQu0Zs0aTZgwQdOnT1dlZWWXx7/33nuaOXOm3n33XS1fvlzZ2dm66qqrtG/fvjMuPtK8t7XtGk8/L9PiSgAA6D02Y4wJ5A15eXmaMmWKnnjiCUmSz+dTdna27r77bt13332nfL/X61VqaqqeeOIJzZo1q0e/s7a2VsnJyaqpqVFSUlIg5YaNVq9PEx96W3XNrXr1rouVm51idUkAAJxUT7+/A2oZ8Xg8KikpUUFBwdET2O0qKCjQ8uXLe3SOxsZGtbS0aMCAAd0e43a7VVtb2+kR6dbvq1Fdc6uSYqI0LivZ6nIAAOg1AYWRqqoqeb1eZWRkdNqekZGh8vLyHp3jhz/8oYYMGdIp0ByvqKhIycnJ/kd2dnYgZYalFTvaBq7mnzWQWTQAgLAS1Nk0Dz/8sBYvXqxXXnlFMTEx3R43b9481dTU+B979uwJYpWhqWTXEUnSlJzuW5QAAOiPogI5OC0tTQ6HQxUVFZ22V1RUKDPz5IMqH330UT388MP65z//qfHjx5/0WJfLJZfLFUhpYc0Yo5KytjAyaXiqxdUAANC7AmoZcTqdmjRpkoqLi/3bfD6fiouLlZ+f3+37/ud//kcPPfSQli5dqsmTJ59+tRFq+8EGVTe2yBVl1/lDGC8CAAgvAbWMSFJhYaFmz56tyZMna+rUqVq4cKEaGho0Z84cSdKsWbOUlZWloqIiSdLPf/5zzZ8/Xy+++KJycnL8Y0sSEhKUkJDQix8lfJXuqZYkjR+aLGcU69QBAMJLwGFkxowZOnjwoObPn6/y8nLl5uZq6dKl/kGtZWVlstuPfmE++eST8ng8uvHGGzudZ8GCBXrggQfOrPoIsWFvtSRp/NAUS+sAAKAvBLzOiBUifZ2RG379L60tq9bjN+Xqutwsq8sBAKBH+mSdEQRfi9enzfvb1llhfREAQDgijIS4bRX1crf6lOiKUg73owEAhCHCSIjbuK9GkjQ2K1l2FjsDAIQhwkiIW7+vWlLbTBoAAMIRYSTEbdjb1jIyjjACAAhThJEQ5mn16ZMDdZIYvAoACF+EkRD2aUWdPF6fkmKiNGxAnNXlAADQJwgjIWxD++DV8UNTZLMxeBUAEJ4IIyFsPeNFAAARgDASwjZ0zKRhvAgAIIwRRkJUc4tXW8vbBq+OJYwAAMIYYSREfXKgVi1eo4HxTg1NjbW6HAAA+gxhJESt21MtSZqQzeBVAEB4I4yEqHXtg1cnDE2xthAAAPoYYSREHW0ZYbwIACC8EUZCUE1ji3ZUNUiiZQQAEP4IIyGo4+Z4wwfGKTXeaW0xAAD0McJICFrPeBEAQAQhjISg0vbxIuNZeRUAEAEIIyHo2Gm9AACEO8JIiCmvaVZlnVsOu01jh9AyAgAIf4SRELNub7UkaXR6gmKdDmuLAQAgCAgjIcbfRcPgVQBAhCCMhJiOmTTjWewMABAhCCMhxBij9e3dNLSMAAAiBWEkhOw61Kja5lY5o+w6JzPR6nIAAAgKwkgI6WgVOW9wkqId/NEAACID33gh5OjKq4wXAQBEDsJICNlaXidJOm9IksWVAAAQPISREPJZZb0kaVR6gsWVAAAQPISREFHvblV5bbMkadQgBq8CACIHYSREbG9vFUlLcCk5LtriagAACB7CSIg42kUTb3ElAAAEF2EkROysapAknTWI8SIAgMhCGAkRFe3jRYakxFpcCQAAwUUYCREH692SpEEJLosrAQAguAgjIaKqI4wkEkYAAJGFMBIiDta1hZE0WkYAABGGMBICfD6jqnqPJFpGAACRhzASAqqbWuT1GUnSwASnxdUAABBchJEQ0NFFkxoXzd16AQARh2++ENARRuiiAQBEIsJICOiYScPgVQBAJCKMhICOMDKQMAIAiECEkRBQ726VJCXFRFlcCQAAwUcYCQH1zW1hJIEwAgCIQISRENDRMpLoIowAACIPYSQE1LWHkQTCCAAgAhFGQsDRbppoiysBACD4CCMhoJ6WEQBABCOMhAB/ywhhBAAQgQgjIcDfMsJsGgBABCKMhAC6aQAAkYwwYjFjzNGpvbSMAAAiEGHEYs0tPnl9RhItIwCAyEQYsVidu0WSZLNJcU6HxdUAABB8hBGLHTuTxmazWVwNAADBRxixWIPbK4ml4AEAkYswYrGObpp4wggAIEIRRizGHXsBAJGOb0CLNHm8stmk2uaOab3clwYAEJkIIxZo9fp0ySPvyhjpW5eMkCSlxhFGAACRiTBigUMNHh2sc0uSPquslyQlxxJGAACRiTEjFmj0eP3Ptx9skCSlEEYAABGKMGKBjkGrkvRpRZ0kKTnOaVU5AABYijBigY570UhSXXswoWUEABCpTiuMLFq0SDk5OYqJiVFeXp5WrVrV7bGbNm3SV77yFeXk5Mhms2nhwoWnW2vYODaMdEhhACsAIEIFHEaWLFmiwsJCLViwQGvWrNGECRM0ffp0VVZWdnl8Y2OjRo4cqYcffliZmZlnXHA4qG9f6OxYhBEAQKQKOIw89thjuuOOOzRnzhydd955euqppxQXF6fnnnuuy+OnTJmiRx55RDfddJNcLtcZFxwOjh0z0iE5ljEjAIDIFFAY8Xg8KikpUUFBwdET2O0qKCjQ8uXLe724cFXv9p6wjZYRAECkCmidkaqqKnm9XmVkZHTanpGRoS1btvRaUW63W2632/+6tra2184dCrrqpmGdEQBApArJ2TRFRUVKTk72P7Kzs60uqVd11U0T7QjJPwoAAPpcQN+AaWlpcjgcqqio6LS9oqKiVwenzps3TzU1Nf7Hnj17eu3coaCui9k0AABEqoDCiNPp1KRJk1RcXOzf5vP5VFxcrPz8/F4ryuVyKSkpqdMjnHS0jNwxbYQyk2I0K3+4xRUBAGCdgO9NU1hYqNmzZ2vy5MmaOnWqFi5cqIaGBs2ZM0eSNGvWLGVlZamoqEhS26DXzZs3+5/v27dPpaWlSkhI0KhRo3rxo/QfDZ62MDI2K1nzrj5XdrvN4ooAALBOwGFkxowZOnjwoObPn6/y8nLl5uZq6dKl/kGtZWVlstuPNrjs379fEydO9L9+9NFH9eijj+rSSy/Ve++9d+afoB/qaBlJcEURRAAAEe+07to7d+5czZ07t8t9xweMnJwcGWNO59eErY4xI/EubpoMAABTOCxwbMsIAACRjjBigY570xBGAAAgjASdMUZNLW0rsMa5HBZXAwCA9QgjQeZu9aljCE2ck5YRAAAII0HW6Dl6X5rYaFpGAAAgjARZY/saI84ouxxM6wUAgDASbM0d40WctIoAACARRoKuo5smji4aAAAkEUaCriOMxNAyAgCAJMJI0DXRTQMAQCeEkSBr8nfTMK0XAACJMBJ0dNMAANAZYSTI/N00DGAFAEASYSTomtrXGWHMCAAAbQgjQUY3DQAAnRFGgoxuGgAAOiOMBJl/Ng0tIwAASCKMBF1HN00sd+wFAEASYSToOrppYqO59AAASISRoGj1+rR+b7W8PnNMNw0tIwAASBLfiEHw4N8364UVu/Wdy85SY/vU3ljGjAAAIImWkaB4YcVuSdKv39uuphafJCmW2TQAAEgijAQdi54BANAZYSTIGtztY0Zc9JABACARRoKupqlFkpQcG21xJQAAhAbCSBDYbUef17vbumlSCCMAAEgijARFTBeDVZMIIwAASCKMBMXxYSQxJkqOY5tLAACIYISRIIiJ6nyZGS8CAMBRhJEgcB3XMpISRxgBAKADYSQIXLSMAADQLcJIEPiM6fQ6JdZpUSUAAIQewkgQtHg7hxFm0gAAcBRhJAg8rb5Or+mmAQDgKMJIELR4O4cRBrACAHAUYSQIPF5aRgAA6A5hJAhajuumyUyKsagSAABCD7eODYKOAazfuHCYcgbGa9roNIsrAgAgdBBG+pgxxt9Nc88VZ2tQosviigAACC100/SxVt/Rab1OB5cbAIDj8e3Yx46dSRMdxc3xAAA4HmGkj7W0Hm0ZiaZlBACAE/Dt2MeOndYbZadlBACA4xFG+lhHN43TYZfNRhgBAOB4hJE+1hFGoh0EEQAAukIY6WP+lpEoLjUAAF3hG7KPuVs7Wka41AAAdIVvyD7WsfoqYQQAgK7xDdnH6KYBAODk+IbsYy2tDGAFAOBkCCN9zONlzAgAACfDN2QfY8wIAAAnxzdkHzt20TMAAHAiviH7mH/RM26SBwBAl6KsLiBcfVZZp9Q4pzysMwIAwEnxDdkHPqusU8Fj7+vLT37kHzNCNw0AAF3jG7IX7DhYr2fe36HmFq8k6S8l+yRJuw81HtNNw6UGAKArdNP0goLHlslnpDp3qwqvPFvbKur8+zoCCi0jAAB0jW/IXuBr64nR6l2H1dziVfGWSv++I40tklj0DACA7hBGepEzyq4vPfFhp237q5skSYkx0VaUBABAyCOMnIHDDR4ZY/yvW7w+fVpR3+mYPUcaJUmpcYQRAAC6wpiR09Di9emj7Yc0+7lVujlvmH97TVNbl0y806EBCU7tOdykPYfbWkZS4pyW1AoAQKgjjATocINHBY8t0+EGjyTpTyvL/Puq6tq2DUp0Kc4ZJalJVfVuSVIqYQQAgC4RRgL015K9/iByvPLaZkltYcRm6zxglW4aAAC6RhiR9KNXNmjfkSY99rUJindFKSbaccIxxhjd+/J6/XXN3lOeb1CiS+4WX6dtyYQRAAC6FPFhpLnFqxfbu1om/eyfys1O0at3XXzCcdWNLT0KIpI0KMHlHz/SgW4aAAC6FvFhZG/7bJcOpXuq5Wn1yXnciqmVde4en3NQokveY2bZSIQRAAC6c1pTexctWqScnBzFxMQoLy9Pq1atOunxL7/8ssaMGaOYmBiNGzdOb7755mkV2xfKDjeesO1ATdMJ2yrrmnt8zkGJLiW4jnbLuKLsinWe2PUDAABOI4wsWbJEhYWFWrBggdasWaMJEyZo+vTpqqys7PL4jz76SDNnztRtt92mtWvX6vrrr9f111+vjRs3nnHxvaHs0IlhZNehRi3deEBvrN+vO18o0V9L9mrB65t6fM60BJcSY442OtEqAgBA92zGHNefcAp5eXmaMmWKnnjiCUmSz+dTdna27r77bt13330nHD9jxgw1NDTojTfe8G+78MILlZubq6eeeqpHv7O2tlbJycmqqalRUlJSIOWe0kNvbNZvP9zZadtZg+K1/WDDaZ/z9bkXq3RPtea/1hZgxmQmaul3LzmjOgEA6G96+v0dUMuIx+NRSUmJCgoKjp7AbldBQYGWL1/e5XuWL1/e6XhJmj59erfHS5Lb7VZtbW2nR1/pqpvmTIKIJI0clNCpZSSFmTQAAHQroDBSVVUlr9erjIyMTtszMjJUXl7e5XvKy8sDOl6SioqKlJyc7H9kZ2cHUmaPGGP0v5vK9fbmii7322zSNeMHB3xeh92mBFdUpzEjF52Vdtp1AgAQ7kLy3jTz5s1TTU2N/7Fnz55e/x0er08PvbFZUtuA06vHZmpg/NGxHXd/frR+OH1MwOcdNiBOkjQlJ1XnD0nSbZ8bobsuH9U7RQMAEIYCmtqblpYmh8OhiorOrQkVFRXKzMzs8j2ZmZkBHS9JLpdLLpcrkNIC5opy6L6rx2jLgTp969KRSoqJ1s6qBhU8tkxjMhN11+VnKcp+6qwW7bDpF1/L1X+8tFaSNDQ1VlLbvWj+8R/T+vQzAAAQDgJqGXE6nZo0aZKKi4v923w+n4qLi5Wfn9/le/Lz8zsdL0lvv/12t8cH07+NH6J7p5+jpJi2LpURafH64D8v11+/fZFcUQ457LZTnEHa+tDV+tKEIf7XV48NvGsHAIBIFvCiZ4WFhZo9e7YmT56sqVOnauHChWpoaNCcOXMkSbNmzVJWVpaKiookSffcc48uvfRS/eIXv9A111yjxYsXa/Xq1Xr66ad795P0kiEpsZ1eP/a1CXppVZm+V3C23t9WpaeWbe+0394eWN66Z5pW7z6im6b0/vgWAADCWcBhZMaMGTp48KDmz5+v8vJy5ebmaunSpf5BqmVlZbIf071x0UUX6cUXX9SPf/xj/ehHP9Lo0aP16quvauzYsb33KfrQly8Yqi9fMFSS5DXmhDDS4dzBSTp3cO9OOwYAIBIEvM6IFfpynZFAHG7w6IKH3u60bdfD11hUDQAAoa1P1hmJdAPinfrgPy/XvVedbXUpAACEjYi/UV6gsgfE6duXjVJqvFN5IwZaXQ4AAP0eYeQ0OOw23Zw33OoyAAAIC3TTAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAAGApwggAALBUv7hrrzFGklRbW2txJQAAoKc6vrc7vse70y/CSF1dnSQpOzvb4koAAECg6urqlJyc3O1+mzlVXAkBPp9P+/fvV2Jiomw2W6+dt7a2VtnZ2dqzZ4+SkpJ67bw4Edc6OLjOwcF1Dh6udXD01XU2xqiurk5DhgyR3d79yJB+0TJit9s1dOjQPjt/UlISf8mDhGsdHFzn4OA6Bw/XOjj64jqfrEWkAwNYAQCApQgjAADAUhEdRlwulxYsWCCXy2V1KWGPax0cXOfg4DoHD9c6OKy+zv1iACsAAAhfEd0yAgAArEcYAQAAliKMAAAASxFGAACApSI6jCxatEg5OTmKiYlRXl6eVq1aZXVJ/cr777+va6+9VkOGDJHNZtOrr77aab8xRvPnz9fgwYMVGxurgoICbdu2rdMxhw8f1s0336ykpCSlpKTotttuU319fRA/RegrKirSlClTlJiYqPT0dF1//fXaunVrp2Oam5t11113aeDAgUpISNBXvvIVVVRUdDqmrKxM11xzjeLi4pSenq4f/OAHam1tDeZHCWlPPvmkxo8f71/0KT8/X2+99ZZ/P9e4bzz88MOy2Wz67ne/69/Gte4dDzzwgGw2W6fHmDFj/PtD6jqbCLV48WLjdDrNc889ZzZt2mTuuOMOk5KSYioqKqwurd948803zf3332/+9re/GUnmlVde6bT/4YcfNsnJyebVV18169atM1/60pfMiBEjTFNTk/+YL3zhC2bChAlmxYoV5oMPPjCjRo0yM2fODPInCW3Tp083v/vd78zGjRtNaWmp+eIXv2iGDRtm6uvr/cfceeedJjs72xQXF5vVq1ebCy+80Fx00UX+/a2trWbs2LGmoKDArF271rz55psmLS3NzJs3z4qPFJJef/11849//MN8+umnZuvWreZHP/qRiY6ONhs3bjTGcI37wqpVq0xOTo4ZP368ueeee/zbuda9Y8GCBeb88883Bw4c8D8OHjzo3x9K1zliw8jUqVPNXXfd5X/t9XrNkCFDTFFRkYVV9V/HhxGfz2cyMzPNI4884t9WXV1tXC6Xeemll4wxxmzevNlIMh9//LH/mLfeesvYbDazb9++oNXe31RWVhpJZtmyZcaYtusaHR1tXn75Zf8xn3zyiZFkli9fboxpC452u92Ul5f7j3nyySdNUlKScbvdwf0A/Uhqaqp59tlnucZ9oK6uzowePdq8/fbb5tJLL/WHEa5171mwYIGZMGFCl/tC7TpHZDeNx+NRSUmJCgoK/NvsdrsKCgq0fPlyCysLHzt37lR5eXmna5ycnKy8vDz/NV6+fLlSUlI0efJk/zEFBQWy2+1auXJl0GvuL2pqaiRJAwYMkCSVlJSopaWl07UeM2aMhg0b1ulajxs3ThkZGf5jpk+frtraWm3atCmI1fcPXq9XixcvVkNDg/Lz87nGfeCuu+7SNddc0+maSvx97m3btm3TkCFDNHLkSN18880qKyuTFHrXuV/cKK+3VVVVyev1drrAkpSRkaEtW7ZYVFV4KS8vl6Qur3HHvvLycqWnp3faHxUVpQEDBviPQWc+n0/f/e53dfHFF2vs2LGS2q6j0+lUSkpKp2OPv9Zd/Vl07EObDRs2KD8/X83NzUpISNArr7yi8847T6WlpVzjXrR48WKtWbNGH3/88Qn7+Pvce/Ly8vT888/rnHPO0YEDB/Tggw9q2rRp2rhxY8hd54gMI0B/ddddd2njxo368MMPrS4lLJ1zzjkqLS1VTU2N/vKXv2j27NlatmyZ1WWFlT179uiee+7R22+/rZiYGKvLCWtXX321//n48eOVl5en4cOH689//rNiY2MtrOxEEdlNk5aWJofDccKo4YqKCmVmZlpUVXjpuI4nu8aZmZmqrKzstL+1tVWHDx/mz6ELc+fO1RtvvKF3331XQ4cO9W/PzMyUx+NRdXV1p+OPv9Zd/Vl07EMbp9OpUaNGadKkSSoqKtKECRP0+OOPc417UUlJiSorK3XBBRcoKipKUVFRWrZsmX75y18qKipKGRkZXOs+kpKSorPPPlufffZZyP2djsgw4nQ6NWnSJBUXF/u3+Xw+FRcXKz8/38LKwseIESOUmZnZ6RrX1tZq5cqV/mucn5+v6upqlZSU+I9555135PP5lJeXF/SaQ5UxRnPnztUrr7yid955RyNGjOi0f9KkSYqOju50rbdu3aqysrJO13rDhg2dwt/bb7+tpKQknXfeecH5IP2Qz+eT2+3mGveiK664Qhs2bFBpaan/MXnyZN18883+51zrvlFfX6/t27dr8ODBofd3uleHw/YjixcvNi6Xyzz//PNm8+bN5lvf+pZJSUnpNGoYJ1dXV2fWrl1r1q5daySZxx57zKxdu9bs3r3bGNM2tTclJcW89tprZv369ea6667rcmrvxIkTzcqVK82HH35oRo8ezdTe43z72982ycnJ5r333us0Ra+xsdF/zJ133mmGDRtm3nnnHbN69WqTn59v8vPz/fs7puhdddVVprS01CxdutQMGjSIqZDHuO+++8yyZcvMzp07zfr16819991nbDab+b//+z9jDNe4Lx07m8YYrnVv+f73v2/ee+89s3PnTvOvf/3LFBQUmLS0NFNZWWmMCa3rHLFhxBhjfvWrX5lhw4YZp9Nppk6dalasWGF1Sf3Ku+++aySd8Jg9e7Yxpm16709+8hOTkZFhXC6XueKKK8zWrVs7nePQoUNm5syZJiEhwSQlJZk5c+aYuro6Cz5N6OrqGksyv/vd7/zHNDU1me985zsmNTXVxMXFmRtuuMEcOHCg03l27dplrr76ahMbG2vS0tLM97//fdPS0hLkTxO6br31VjN8+HDjdDrNoEGDzBVXXOEPIsZwjfvS8WGEa907ZsyYYQYPHmycTqfJysoyM2bMMJ999pl/fyhdZ5sxxvRuWwsAAEDPReSYEQAAEDoIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACw1P8Hn1dqJEHbfMYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d4ea016-d12a-4fcd-9b35-81a157166e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f90b4d312d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124e5cd-5eb2-4718-a0a9-5d45128c317f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78361a-662b-47de-8ee7-eacd577ee96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64601119-8837-4a64-9036-064adc7065b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cda224b-faf3-4e89-9c82-aa638e31ca52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab8283e-d71d-4f0b-bb67-db0eb478ad24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471bb43b-ebf0-43eb-8d6b-8f7e616a663b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff347aee-fac8-41d6-8fde-6b38a53f4215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:14,  2.00s/it]/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:168: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "8it [00:22,  4.01s/it]W1015 15:32:29.407000 20839 torch/_dynamo/convert_frame.py:844] [0/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W1015 15:32:29.407000 20839 torch/_dynamo/convert_frame.py:844] [0/8]    function: 'forward' (/tmp/ipykernel_20839/2467812288.py:21)\n",
      "W1015 15:32:29.407000 20839 torch/_dynamo/convert_frame.py:844] [0/8]    last reason: 0/0: L['key'] == '29513-3-5'                                     \n",
      "W1015 15:32:29.407000 20839 torch/_dynamo/convert_frame.py:844] [0/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1015 15:32:29.407000 20839 torch/_dynamo/convert_frame.py:844] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "201it [00:31,  6.41it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (k, b) in tqdm(enumerate(train_dl)):\n",
    "        videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        out = opt_r(videos, k);\n",
    "        if i > 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e1c3779-b837-475e-9d67-e26ce56ea9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:09, 22.31it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (k, b) in tqdm(enumerate(train_dl)):\n",
    "        videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        out = opt_r(videos, k);\n",
    "        if i > 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1eb81e6a-b579-4ab9-96a3-e4e6fb2b15f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:08, 22.55it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (k, b) in tqdm(enumerate(train_dl)):\n",
    "        videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        out = opt_r(videos, k);\n",
    "        if i > 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d992fe01-9ca9-4097-a802-4bf60fbce37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:03, 52.64it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (k, b) in tqdm(enumerate(train_dl)):\n",
    "        videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        out = tiny_hiera(videos,);\n",
    "        if i > 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff72357-9d7a-4e56-8a8d-eabb88263228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdeb56b-d76c-48d5-983d-2245d1b467a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd4e86-6739-4bf5-ab83-053a18631079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a4d90-75d8-4ca1-a2f6-3fde8152e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b7f1a27b-1df3-4a74-a94a-43e2aaefdf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0eb97efa-8654-4a37-b491-ee51ff2efa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "59a56fca-6b0e-4d0b-bb74-41f8b48a86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_r.to(torch.bfloat16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "58ef0935-b86f-4a73-9dca-f29c60d60e39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with autocast(device_type='cuda', dtype=torch.float16):\n",
    "    out = opt_r(videos, k);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a054172-3da7-4838-9409-11dd426025cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7495, 16])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6090ec79-583a-4ca8-8ce6-264f46256c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criteria(out.transpose(1,2), responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "792b4898-72fe-49dd-baa8-84068ca448bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "264de30b-6ea6-465f-892d-0808e330ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e7cf70a-ac27-4fb9-b7d7-429ace2c3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "daf67086-e6fb-4cb3-8770-328736ee7cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "31b8d7dd-39e0-4463-b722-196da471198b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 16, 144, 256])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bef727c6-06aa-4ad6-9a91-a00fab2655ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_r = opt_r.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "91a7ad8a-4f9b-4c57-b11f-ab8fd84971b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = opt_r(videos, k);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8914da-83f9-4dc3-9aa5-711aa94c36e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = opt_r(videos, k);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9a5c4-c157-4f22-a330-7a56435d8eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f2d7a-bdc8-4c12-bcb7-15f48fdfbfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41be22c-7f65-4907-8d8e-5a36aba6360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58% 576/1000 [01:24<01:01,  6.84it/s]"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    #with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "    videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "    responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "    out = opt_r(videos, k);\n",
    "    loss = criteria(out.transpose(1,2), responses)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "71a97bb8-839b-49c5-9c01-13127532b30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd899a9900>]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8edc7-a81f-4044-9ddf-c5b109a9b688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c78d388b-5176-47ad-b537-a92c06e4c8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7495, 16])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "051479be-66d8-4088-a405-0b5c6b18b0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 7495])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8e1b9ea-df97-46c8-946c-8fcdde8409df",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron=66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475e66c-66f4-41e9-b687-8cb605efc6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d75c7d30-8a3b-4240-9071-f52b2c163e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "650e21fa-b1a1-4a01-9e50-7f93b1ac5629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12096827660364878"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69cad70d-a399-4f2e-aaca-b890f0648836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7495, 16])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ee422-8240-4925-8b7d-1144e4ff4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_no, (data_key, data) in tqdm(enumerate(LongCycler(dataloaders[\"train\"])), total=n_iterations,\n",
    "                                       desc=\"Epoch {}\".format(epoch)):\n",
    "\n",
    "    loss = full_objective(model, dataloaders[\"train\"], data_key, *data)\n",
    "    # loss = torch.sum(loss)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff1834-6ada-4ebc-936a-a314d222b79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4739486e-f0ad-4501-9927-85ea0a3b78ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7671, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b2b13-87d6-47be-9938-a454e2896eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1b607-1a4c-4223-9e9b-2d8a8427f462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd30e9-388b-4fd0-be31-98b68c6f93a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f0fc1-a125-409b-8d97-0420c3da97a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b011c-8572-42d2-9ecd-4c71bf25087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.readout[\"29513-3-5\"].bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1954b39b-f65a-4954-b415-43f21857cf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87468ce7-5242-4ab2-a310-e2f26b43e36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a34bec-74f0-4349-b191-40b7e665d458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "32b5e139-d56c-4366-83be-a7a065a7f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_out = rearrange(full_out, 'b (n t) c -> b t n c', n=7671, t=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd79f992-43ee-4268-92a3-cd727c7ba70d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 7671, 384])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "730901f6-c80e-41be-9a95-ce95328d22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = r.readout[\"29513-3-5\"].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41b43b9b-f9a5-4809-b34b-85eba1245051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7671, 256, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f614dad-0f86-4b4f-b5cc-89fefd033dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7671, 16])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"btni, njr->bnt\", full_out, w, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b7cc2-45a0-48bd-8d27-811df5878b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "28439883-dfc8-438e-b164-abb78eff32e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7671, 256])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2724a50b-6553-47d1-a132-bba6d964d817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(960416, device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(full_out).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7cd778-7919-46f1-8388-341fa4aa3d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8f415-295c-4512-9d4c-b537c3a6378c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d3ebaa9-f588-4324-9487-33a77dbf040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:00<00:00, 110.38it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        r(videos, \"29513-3-5\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e05df6e-defc-4198-8ea4-a5a793b50dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:00<00:00, 110.43it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        r(videos, \"29513-3-5\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3eb8ec7f-6f52-44db-867e-91c0304f4805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:00<00:00, 103.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    r(videos, \"29513-3-5\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42e5eb-ebc6-4fb2-b630-22f5980a774b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88598f07-6e6b-47c1-b0d3-f93ddea04c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11410205-9a03-4048-99cb-9d58173ab628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29513-3-5.query torch.Size([1, 8, 7671, 32]) 1963776\n",
      "29513-3-5.weight torch.Size([7671, 256, 1]) 1963776\n",
      "29513-3-5.bias torch.Size([1, 7671, 1]) 7671\n",
      "29514-2-9.query torch.Size([1, 8, 7495, 32]) 1918720\n",
      "29514-2-9.weight torch.Size([7495, 256, 1]) 1918720\n",
      "29514-2-9.bias torch.Size([1, 7495, 1]) 7495\n",
      "29755-2-8.query torch.Size([1, 8, 8122, 32]) 2079232\n",
      "29755-2-8.weight torch.Size([8122, 256, 1]) 2079232\n",
      "29755-2-8.bias torch.Size([1, 8122, 1]) 8122\n",
      "29647-19-8.query torch.Size([1, 8, 8202, 32]) 2099712\n",
      "29647-19-8.weight torch.Size([8202, 256, 1]) 2099712\n",
      "29647-19-8.bias torch.Size([1, 8202, 1]) 8202\n",
      "29156-11-10.query torch.Size([1, 8, 7440, 32]) 1904640\n",
      "29156-11-10.weight torch.Size([7440, 256, 1]) 1904640\n",
      "29156-11-10.bias torch.Size([1, 7440, 1]) 7440\n",
      "29623-4-9.query torch.Size([1, 8, 7908, 32]) 2024448\n",
      "29623-4-9.weight torch.Size([7908, 256, 1]) 2024448\n",
      "29623-4-9.bias torch.Size([1, 7908, 1]) 7908\n",
      "29515-10-12.query torch.Size([1, 8, 7863, 32]) 2012928\n",
      "29515-10-12.weight torch.Size([7863, 256, 1]) 2012928\n",
      "29515-10-12.bias torch.Size([1, 7863, 1]) 7863\n",
      "29234-6-9.query torch.Size([1, 8, 8285, 32]) 2120960\n",
      "29234-6-9.weight torch.Size([8285, 256, 1]) 2120960\n",
      "29234-6-9.bias torch.Size([1, 8285, 1]) 8285\n",
      "29712-5-9.query torch.Size([1, 8, 7939, 32]) 2032384\n",
      "29712-5-9.weight torch.Size([7939, 256, 1]) 2032384\n",
      "29712-5-9.bias torch.Size([1, 7939, 1]) 7939\n",
      "29228-2-10.query torch.Size([1, 8, 7928, 32]) 2029568\n",
      "29228-2-10.weight torch.Size([7928, 256, 1]) 2029568\n",
      "29228-2-10.bias torch.Size([1, 7928, 1]) 7928\n",
      "40451589\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "n_params=0\n",
    "for n, p in r.readout.named_parameters():\n",
    "    print(n, p.shape, torch.numel(p))\n",
    "    n_params += torch.numel(p)\n",
    "print(n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69805ee3-9932-46a7-8a6e-71e09ecfb971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97b3716a-dcb4-4f59-9fb2-ce060acb9d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7671, 256])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d67e8158-fd8f-4812-a3ae-4f1076150ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1917.75"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30684/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c464c95-6965-4bef-92c0-fdf084266bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "30684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3c75278-22ff-4795-9ce9-9de3a76cabd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 18, 16, 384])\n",
      "torch.Size([8, 1152, 256])\n",
      "torch.Size([8, 1152, 256])\n",
      "torch.Size([32, 8, 7671, 32])\n",
      "torch.Size([8, 8, 1152, 32])\n",
      "torch.Size([8, 8, 1152, 32])\n"
     ]
    }
   ],
   "source": [
    "with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(100)):\n",
    "            r(videos, \"29513-3-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "757dc737-3a8c-4f11-923e-52b37d38e000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:00<00:00, 110.38it/s]\n"
     ]
    }
   ],
   "source": [
    "with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(100)):\n",
    "            r(videos, \"29513-3-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2333e7d-a367-48fd-9c46-4e94e9ce3136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13d327-b63d-4534-a41a-58a5b6fd15d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a1575ae-ac41-491f-aeb5-3089581ed116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1000/1000 [00:21<00:00, 46.31it/s]\n"
     ]
    }
   ],
   "source": [
    "example_in = torch.ones(32,1,16,144, 144).to(\"cuda\", torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(1000)):\n",
    "        tiny_hiera(example_in);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9782b0e-9fc1-4e47-be2d-e6d9b80107cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904d3a60-7f69-4759-84e9-f04f591e9f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24*32*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc68e4-a2b8-4190-8fe9-2fc15601766a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fdf496-5164-4387-9cb8-1b8706f0eaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e8cd4-343c-4220-9365-0b41f21d154b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7791f421-0ddf-4872-8228-365f09cdcc23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:17, 17.03it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (k, b) in tqdm(enumerate(dl)):\n",
    "        video_tensor = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        _ = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        _ = b[\"eye_tracker\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        _ = b[\"treadmill\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        #tiny_hiera(video_tensor);\n",
    "        if i >300:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0873f3a-b561-4885-bf37-5c07462e0e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:22, 13.28it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (k, b) in tqdm(enumerate(dl)):\n",
    "        video_tensor = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        _ = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        _ = b[\"eye_tracker\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        _ = b[\"treadmill\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        tiny_hiera(video_tensor);\n",
    "        if i >300:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c70a44e0-0bb0-4f5a-84f4-dd7eab9dc657",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4891336\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "n_params=0\n",
    "for n, p in tiny_hiera.named_parameters():\n",
    "    #print(n, p.shape, torch.numel(p))\n",
    "    n_params += torch.numel(p)\n",
    "print(n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb454824-3492-4ded-8eb6-77c74ca42cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ee11e-e469-410c-b358-4ebdc1086100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37cdb19-af10-42ac-9af0-80fc6862fd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840860ce-5afc-4379-b1be-c853424a413d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4949dfc8-d00e-4f89-8729-2f245239a6c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import hiera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feedd47-466e-4c5a-bd4f-8a1ad2e2e202",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210e397-652a-4770-8e19-e0c3b0ee5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hiera import Hiera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a37c6c0-9ec4-40f1-8527-381f0b71b9f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'hiera' from '/usr/local/lib/python3.10/dist-packages/hiera/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382e17f-546f-47f9-93a9-3214fd67bcaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26bed1f-9c54-4de1-a65e-5a615bf61972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from hiera import Hiera\n",
    "model = Hiera.from_pretrained(\"facebook/hiera_base_224.mae_in1k_ft_in1k\")  # mae pt then in1k ft'd model\n",
    "model = Hiera.from_pretrained(\"facebook/hiera_base_224.mae_in1k\") # just mae pt, no ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37209baa-3aff-4eb1-92a6-e117abb34fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Hiera.from_pretrained(\"facebook/hiera_tiny_224.mae_in1k\") # just mae pt, no ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010fb0e4-d425-4a13-8456-a88622880b57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from hiera import Hiera\n",
    "my_tiny_hiera = Hiera(embed_dim=96, num_heads=1, stages=(1, 2, 7, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f451901-3d01-4a01-b134-46654a1cfa80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_cut_hiera = Hiera(input_size=(16,144, 144),\n",
    "                     num_heads=1, \n",
    "                     stages=(1, 2, 2), \n",
    "                     q_pool=1, \n",
    "                     in_chans=1,\n",
    "                     q_stride=(1, 2, 2),\n",
    "                     mask_unit_size=(1, 8, 8),\n",
    "                     patch_kernel=(3, 7, 7),\n",
    "                     patch_stride=(2, 4, 4),\n",
    "                     patch_padding=(1, 3, 3),\n",
    "                     sep_pos_embed=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9b6a5b-6648-42bc-b093-ad7c2528064e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_cut_hiera.eval().cuda().to(torch.bfloat16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abb1ddd-e36c-452b-aa88-bb15938a39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0a93ad-c07a-49b0-8498-5d57c25d16a2",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19% 193/1000 [00:15<01:06, 12.07it/s]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f167ca8b370>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_in = torch.ones(32,1,16,144, 144).to(\"cuda\", torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(1000)):\n",
    "        my_cut_hiera(example_in);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3a6b2-6212-43f0-89dc-909780e70fc5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ab672-a59f-4c8d-9b26-e084e8d2b697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b86d3440-8eff-4a51-88f0-25d3be8494ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = my_cut_hiera(torch.ones(1,1,16,144,144).cuda(), return_intermediates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090e6a5-e668-447a-8f16-5fd29662626c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e4d2677e-484c-48ab-bfb4-2c0f2dfcabd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 18, 18, 192])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out[1])[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11413059-5f2e-40b7-8809-a9a5481208dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a48d8104-8117-4e10-8aa4-bcb717c655dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 384])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cut_hiera.head.projection.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e963e852-3142-4b5f-88ce-54294d8b5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2295ed8-d9c8-4e32-a25d-602719f32b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(19.595917942265423)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef858d6-774b-483e-8fa2-f8342e5d53f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "206e2f6b-50e0-46d0-8e62-230237a1a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hiera/hiera.py\u001b[0m(413)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    411 \u001b[0;31m            \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    412 \u001b[0;31m        )\n",
      "\u001b[0m\u001b[0;32m--> 413 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pos_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    414 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    415 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  x.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3888, 96])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.get_pos_embed().shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10368, 96])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7c076-adb5-462a-9b76-4100f3ff8fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f13cdd8-29d4-4d05-a85b-66a86c1694e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(8,8, figsize=(10,10))\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(my_cut_hiera.patch_embed.proj.weight.data[i,0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756c62cc-6e32-467b-9506-cdbf2796f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8acce321-4647-4ec7-9cab-d423f476909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248295/1124240724.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  some_weights = torch.load(\"mae_hiera_tiny_224.pth\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Hiera:\n\tsize mismatch for pos_embed: copying a param with shape torch.Size([1, 3136, 96]) from checkpoint, the shape in current model is torch.Size([1, 2304, 96]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m some_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae_hiera_tiny_224.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmy_cut_hiera\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_state\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Hiera:\n\tsize mismatch for pos_embed: copying a param with shape torch.Size([1, 3136, 96]) from checkpoint, the shape in current model is torch.Size([1, 2304, 96])."
     ]
    }
   ],
   "source": [
    "some_weights = torch.load(\"mae_hiera_tiny_224.pth\")\n",
    "my_cut_hiera.load_state_dict(some_weights[\"model_state\"], strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9da569-f7a3-41f8-abeb-22226158b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(8,12, figsize=(12,8))\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(my_cut_hiera.patch_embed.proj.weight.data[i,2].cpu().numpy(), cmap=\"hot\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a37f4-479b-44ba-80bb-cb2d48119d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b724b-c346-41f4-9504-4a0216743d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7e894-aee1-4fc9-963b-af2e948423b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f94e0-92a1-4733-8580-df3bcf1d37bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab7c3d-6f57-46b2-8070-98e362b1d3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0033efb-3787-424c-878c-cca29424386b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef45710-e406-4b68-9914-481a4bd56f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27910216\n"
     ]
    }
   ],
   "source": [
    "n_params=0\n",
    "for n, p in my_tiny_hiera.named_parameters():\n",
    "    #print(n, p.shape, torch.numel(p))\n",
    "    n_params += torch.numel(p)\n",
    "print(n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f35e368-dd3a-470e-a177-ea52473612a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27910216\n"
     ]
    }
   ],
   "source": [
    "n_params=0\n",
    "for n, p in model.named_parameters():\n",
    "    print#(n, p.shape, torch.numel(p))\n",
    "    n_params += torch.numel(p)\n",
    "print(n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d477298e-4de0-41a9-bb5b-f8f534438049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4987336\n"
     ]
    }
   ],
   "source": [
    "n_params=0\n",
    "for n, p in my_cut_hiera.named_parameters():\n",
    "    #print(n, p.shape, torch.numel(p))\n",
    "    n_params += torch.numel(p)\n",
    "print(n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47ad59e-5750-48f9-bfcd-0252998608a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cut_hiera.to(\"cuda\", torch.bfloat16);\n",
    "my_tiny_hiera.to(\"cuda\", torch.bfloat16);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add1fcf1-797f-420a-b3c0-51347f4f7409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0373b257-44c3-477f-ba72-87566f1711f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:16<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        my_cut_hiera(torch.ones(500,3,256,144).to(\"cuda\", torch.bfloat16));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "515a6386-99ec-41b2-a578-56cf7c19f07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:22<00:00,  4.48it/s]\n"
     ]
    }
   ],
   "source": [
    "example = torch.ones(500,3,224,224).to(\"cuda\", torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        out = my_tiny_hiera(example, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e09605-e069-4d8b-a267-be2ddf74d2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "941ab106-2976-46a2-91ed-c5d07b74ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tiny_hiera = torch.compile(my_tiny_hiera,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b973bcb3-331f-4c98-94d0-182001e2dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tiny_hiera.to(\"cuda\", torch.bfloat16);\n",
    "example = torch.ones(500,3,224,224).to(\"cuda\", torch.bfloat16)\n",
    "out = my_tiny_hiera(example, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "318ec312-e56c-43f7-a265-f706c40dfc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c65b1277-6c1f-4532-9290-8e42811c7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:13<00:00,  7.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# default\n",
    "example = torch.ones(500,3,224,224).to(\"cuda\", torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        out = my_tiny_hiera(example, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f50b20c4-e650-4fd8-8725-e6105c32ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:13<00:00,  7.64it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "# default\n",
    "example = torch.ones(500,3,224,224).to(\"cuda\", torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        out = my_tiny_hiera(example, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8ec05-7811-49d9-a2dd-46d8e7403c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c0ff115-df33-42c8-a297-67795dcc604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a1ded79-cd3a-4d09-948b-e3afc04c79a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:13<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "example = torch.ones(500,3,224,224).to(\"cuda\", torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e6c14d5-cf08-461b-b605-30de9bb85c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:13<00:00,  7.65it/s]\n"
     ]
    }
   ],
   "source": [
    "example = torch.ones(500,3,224,224).to(\"cuda\", torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        out = my_tiny_hiera(example, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29814e9e-1137-4cc9-92d8-d8069930b691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:13<00:00,  7.65it/s]\n"
     ]
    }
   ],
   "source": [
    "with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(100)):\n",
    "            out = my_tiny_hiera(example, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "759d6a5c-fa3e-4a23-a358-ab0c2bbc7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:22<00:00,  4.46it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        out = my_tiny_hiera(example, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f54d74f-d6dd-4ffd-a40f-40792e437ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:22<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cuda.enable_flash_sdp(True)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        out = my_tiny_hiera(example, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d728102-8005-46d8-a8e8-473f1720da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "009febcc-ad8b-419f-9d75-0a9bc4f1c21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df59d000-6713-4300-ba59-33fd3e8dfeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0.dev20240913+cu121'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb39bfb-6963-40ac-8ea2-3105abfdc212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hiera/hiera.py\u001b[0m(100)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     98 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scaled_dot_product_attention\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     99 \u001b[0;31m            \u001b[0;31m# Note: the original paper did *not* use SDPA, it's a free boost!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 100 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m            \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  k.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 49, 64, 96])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88df5a44-b286-449c-ae9e-6a65fe021ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No available kernel. Aborting execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[0;32m----> 7\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mmy_tiny_hiera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hiera/hiera.py:423\u001b[0m, in \u001b[0;36mHiera.forward\u001b[0;34m(self, x, mask, return_intermediates)\u001b[0m\n\u001b[1;32m    418\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[mask[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mtile(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_size, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])]\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    419\u001b[0m         x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m--> 423\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_intermediates \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_ends:\n\u001b[1;32m    426\u001b[0m         intermediates\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreroll(x, i, mask\u001b[38;5;241m=\u001b[39mmask))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hiera/hiera.py:147\u001b[0m, in \u001b[0;36mHieraBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_out:\n\u001b[1;32m    146\u001b[0m     x \u001b[38;5;241m=\u001b[39m do_pool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x_norm), stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn\u001b[38;5;241m.\u001b[39mq_stride)\n\u001b[0;32m--> 147\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_norm\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# MLP\u001b[39;00m\n\u001b[1;32m    150\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hiera/hiera.py:100\u001b[0m, in \u001b[0;36mMaskUnitAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m     q \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         q\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads, num_windows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_stride, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(F, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaled_dot_product_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Note: the original paper did *not* use SDPA, it's a free boost!\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     attn \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No available kernel. Aborting execution."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "from torch.nn.attention import SDPBackend, sdpa_kernel\n",
    "with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(100)):\n",
    "            out = my_tiny_hiera(torch.ones(10,3,224,224).to(\"cuda\", torch.bfloat16), );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e48b6d-1b38-4c45-80bd-149c8986af73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.308281344"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*8*3*224*224*2 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ab91e-a8e4-4343-994f-a057c7a7321c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a445668-d639-46b2-b02b-2e4798b91636",
   "metadata": {},
   "outputs": [],
   "source": [
    "! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7054ac-3833-42a0-ba2f-efac8c6d168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "checkpoint = \"./checkpoints/sam2.1_hiera_large.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
