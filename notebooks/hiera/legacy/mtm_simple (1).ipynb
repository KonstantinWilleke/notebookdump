{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import warnings\n",
    "from random_word import RandomWords\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import random\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "# Disable warnings for low Pearson correlation\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    category=UserWarning,\n",
    "    message=\"The variance of predictions or target \"\n",
    "            \"is close to zero. This can cause instability\"\n",
    "            \" in Pearson correlationcoefficient, leading\"\n",
    "            \" to wrong results.\")\n",
    "\n",
    "# Set random seed (before model initialization)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Enable TensorFloat32 tensor cores for float32 matrix multiplication\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from `torchmetrics.PearsonCorrCoef <https://github.com/Lightning-AI/torchmetrics/blob/master/src/torchmetrics/regression/pearson.py>`__.\n",
    "\"\"\"\n",
    "from typing import Optional, Union, Any, Tuple\n",
    "from jaxtyping import Float, Float64, Int, Int64, Bool\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "from torchmetrics import Metric\n",
    "from torchmetrics.regression.pearson import _final_aggregation as _pearson_corrcoef_final_aggregation\n",
    "from torchmetrics.functional.regression.pearson import _pearson_corrcoef_compute\n",
    "from torchmetrics.utilities.plot import _PLOT_OUT_TYPE\n",
    "\n",
    "\n",
    "def safe_divide(numerator: torch.Tensor, denominator: torch.Tensor):\n",
    "    return torch.where(denominator != 0, numerator / denominator, torch.tensor(0.0))\n",
    "\n",
    "\n",
    "def _pearson_corrcoef_update(\n",
    "    preds: Float64[torch.Tensor, \"n_samples n_neurons\"],\n",
    "    target: Float64[torch.Tensor, \"n_samples n_neurons\"],\n",
    "    mask: Bool[torch.Tensor, \"n_samples n_neurons\"],\n",
    "    mean_x: Float64[torch.Tensor, \"n_neurons\"],\n",
    "    mean_y: Float64[torch.Tensor, \"n_neurons\"],\n",
    "    var_x: Float64[torch.Tensor, \"n_neurons\"],\n",
    "    var_y: Float64[torch.Tensor, \"n_neurons\"],\n",
    "    corr_xy: Float64[torch.Tensor, \"n_neurons\"],\n",
    "    n_total: Int64[torch.Tensor, \"n_neurons\"],\n",
    ") -> Tuple[\n",
    "    Float64[torch.Tensor, \"n_neurons\"],\n",
    "    Float64[torch.Tensor, \"n_neurons\"],\n",
    "    Float64[torch.Tensor, \"n_neurons\"],\n",
    "    Float64[torch.Tensor, \"n_neurons\"],\n",
    "    Float64[torch.Tensor, \"n_neurons\"],\n",
    "    Int64[torch.Tensor, \"n_neurons\"]\n",
    "]:\n",
    "    \"\"\"Update and returns variables required to compute Pearson Correlation Coefficient,\n",
    "        for subset of population neurons\n",
    "\n",
    "    Args:\n",
    "        preds: estimated scores\n",
    "        target: ground truth scores\n",
    "        mask: binary mask indicating which samples to include in update\n",
    "        mean_x: current mean estimate of x tensor\n",
    "        mean_y: current mean estimate of y tensor\n",
    "        var_x: current variance estimate of x tensor\n",
    "        var_y: current variance estimate of y tensor\n",
    "        corr_xy: current covariance estimate between x and y tensor\n",
    "        n_total: current number of observed observations\n",
    "    \n",
    "    NOTE: Adapted (for population and masking) from :func:`torchmetrics.functional.regression.pearson._pearson_corrcoef_update`\n",
    "    \"\"\"\n",
    "    # Count obs\n",
    "    num_obs = mask.sum(0)\n",
    "    # Running mean updaes\n",
    "    mx_new = safe_divide(n_total * mean_x + (preds * mask).sum(0), n_total + num_obs)\n",
    "    my_new = safe_divide(n_total * mean_y + (target * mask).sum(0), n_total + num_obs)\n",
    "    # Update obs counts\n",
    "    n_total += num_obs\n",
    "    # Running variance updates\n",
    "    var_x += ((preds - mx_new) * (preds - mean_x) * mask).sum(0)\n",
    "    var_y += ((target - my_new) * (target - mean_y) * mask).sum(0)\n",
    "    corr_xy += ((preds - mx_new) * (target - my_new) * mask).sum(0)\n",
    "\n",
    "    return mx_new, my_new, var_x, var_y, corr_xy, n_total\n",
    "\n",
    "\n",
    "class MaskedPopulationPearsonCorrCoef(Metric):\n",
    "    is_differentiable: bool = True\n",
    "    higher_is_better: Optional[bool] = True\n",
    "    full_state_update: bool = True\n",
    "    plot_lower_bound: float = -1.0\n",
    "    plot_upper_bound: float = 1.0\n",
    "\n",
    "    mean_x: Float64[torch.Tensor, \"population_size\"]\n",
    "    mean_y: Float64[torch.Tensor, \"population_size\"]\n",
    "    var_x: Float64[torch.Tensor, \"population_size\"]\n",
    "    var_y: Float64[torch.Tensor, \"population_size\"]\n",
    "    corr_xy: Float64[torch.Tensor, \"population_size\"]\n",
    "    n_total: Int64[torch.Tensor, \"population_size\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        population_size: int,\n",
    "        masked: Optional[bool] = None,\n",
    "        # override default with `False` to enable plotting distribution\n",
    "        compute_with_cache: bool = False,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(compute_with_cache=compute_with_cache, **kwargs)\n",
    "        # Initialize states\n",
    "        self.add_state(\"mean_x\", default=torch.zeros(population_size, dtype=torch.float64), dist_reduce_fx=None)\n",
    "        self.add_state(\"mean_y\", default=torch.zeros(population_size, dtype=torch.float64), dist_reduce_fx=None)\n",
    "        self.add_state(\"var_x\", default=torch.zeros(population_size, dtype=torch.float64), dist_reduce_fx=None)\n",
    "        self.add_state(\"var_y\", default=torch.zeros(population_size, dtype=torch.float64), dist_reduce_fx=None)\n",
    "        self.add_state(\"corr_xy\", default=torch.zeros(population_size, dtype=torch.float64), dist_reduce_fx=None)\n",
    "        self.add_state(\"n_total\", default=torch.zeros(population_size, dtype=torch.int64), dist_reduce_fx=None)\n",
    "        # Masking behavior\n",
    "        self.ignore_mask = (masked is None)\n",
    "        self.invert_mask = (masked == True)\n",
    "\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        preds: Float[torch.Tensor, \"batch n_neurons n_samples\"],\n",
    "        target: Float[torch.Tensor, \"batch n_neurons n_samples\"],\n",
    "        neurons: Int[torch.Tensor, \"batch n_neurons\"],\n",
    "        mask: Float[torch.Tensor, \"batch n_neurons n_samples\"],\n",
    "    ) -> None:\n",
    "        # Invert mask if metric is inverted\n",
    "        mask = torch.ones_like(mask) if self.ignore_mask else mask.logical_not() if self.invert_mask else mask\n",
    "        # Increase precision of inputs to avoid overflow\n",
    "        preds, target = preds.to(torch.float64), target.to(torch.float64)\n",
    "        # Iterate over samples in batch (NOTE: batches might use overlapping neurons so can't parallelize)\n",
    "        for preds_block, target_block, neurons_block, mask_block in zip(preds, target, neurons, mask):\n",
    "            # Calculate new state values for neurons in block\n",
    "            mean_x, mean_y, var_x, var_y, corr_xy, n_total = _pearson_corrcoef_update(\n",
    "                preds_block.T, target_block.T, mask_block.T,\n",
    "                self.mean_x[neurons_block],\n",
    "                self.mean_y[neurons_block],\n",
    "                self.var_x[neurons_block],\n",
    "                self.var_y[neurons_block],\n",
    "                self.corr_xy[neurons_block],\n",
    "                self.n_total[neurons_block],\n",
    "            )\n",
    "            # Update population state values for subset of neurons\n",
    "            self.mean_x.scatter_(dim=0, index=neurons_block, src=mean_x)\n",
    "            self.mean_y.scatter_(dim=0, index=neurons_block, src=mean_y)\n",
    "            self.var_x.scatter_(dim=0, index=neurons_block, src=var_x)\n",
    "            self.var_y.scatter_(dim=0, index=neurons_block, src=var_y)\n",
    "            self.corr_xy.scatter_(dim=0, index=neurons_block, src=corr_xy)\n",
    "            self.n_total.scatter_(dim=0, index=neurons_block, src=n_total)\n",
    "\n",
    "    def compute(\n",
    "        self,\n",
    "        reduce: bool = True,\n",
    "        observed_only: bool = False,\n",
    "        nonnan: bool = False,\n",
    "    ) -> Union[float, Float[torch.Tensor, \"selected_length\"]]:\n",
    "        var_x, var_y, corr_xy, n_total = self.var_x, self.var_y, self.corr_xy, self.n_total\n",
    "        # Multiple devices, need further reduction\n",
    "        if self.mean_x.ndim > 1:\n",
    "            _, _, var_x, var_y, corr_xy, n_total = _pearson_corrcoef_final_aggregation(\n",
    "                self.mean_x, self.mean_y, self.var_x, self.var_y, self.corr_xy, self.n_total\n",
    "            )\n",
    "        # Compute Pearson Correlation Coefficient for entire population\n",
    "        ret = _pearson_corrcoef_compute(var_x, var_y, corr_xy, n_total)\n",
    "        # Initialize selection of valid neurons\n",
    "        selection = torch.ones_like(ret, dtype=torch.bool)\n",
    "        # Ignore neurons with NAN\n",
    "        if nonnan or reduce:\n",
    "            selection = torch.logical_and(selection, ~ret.isnan())\n",
    "        # Ignore neurons unseen in dataset (i.e. `n_total` updates is zero)\n",
    "        if observed_only or reduce:\n",
    "            selection = torch.logical_and(selection, (n_total > 0))\n",
    "        # Select neurons with mask\n",
    "        ret = ret[selection]\n",
    "        if not reduce:\n",
    "            return ret\n",
    "        # If reduction specified, take average weighted by number of\n",
    "        #  observations in the dataset\n",
    "        valid_n_total = n_total[selection].float()\n",
    "        weights = valid_n_total / valid_n_total.sum()\n",
    "        return torch.sum(weights * ret)\n",
    "    \n",
    "    def forward(self, *args: Any, **kwargs: Any) -> Any:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def plot(self, val: Any, ax: Any,) -> _PLOT_OUT_TYPE:\n",
    "        \"\"\"\n",
    "        Plot's distribution of Pearson Correlation Coefficient values \n",
    "         across neurons in population\n",
    "\n",
    "        TODO: Handle plotting pre-computed values (i.e. `val`)\n",
    "        \"\"\"\n",
    "        # Compute unreduced metric value for population, and prepare for plotting\n",
    "        val = self.compute(\n",
    "            reduce=False, observed_only=True, nonnan=True\n",
    "        ).detach().cpu()\n",
    "        #   Create figure\n",
    "        fig = go.Figure()\n",
    "        #   Create violin plot\n",
    "        fig.add_trace(go.Violin(\n",
    "            y=val, \n",
    "            box_visible=True, \n",
    "            meanline_visible=True, \n",
    "            line_color='blue', \n",
    "            name='Distribution'\n",
    "        ))\n",
    "        # Add lines at metric bounds and annotate optimal bound\n",
    "        fig.add_shape(\n",
    "            type='line', \n",
    "            x0=0, x1=1, \n",
    "            y0=self.plot_lower_bound, \n",
    "            y1=self.plot_lower_bound, \n",
    "            xref='paper', yref='y', \n",
    "            line=dict(dash='dash', color='black',)\n",
    "        )\n",
    "        fig.add_shape(\n",
    "            type='line', \n",
    "            x0=0, x1=1, \n",
    "            y0=self.plot_upper_bound, \n",
    "            y1=self.plot_upper_bound, \n",
    "            xref='paper', \n",
    "            yref='y', \n",
    "            line=dict(dash='dash', color='black')\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=0.2, \n",
    "            y=self.plot_upper_bound + .1, \n",
    "            text=\"Optimal \\n value\", \n",
    "            showarrow=False, \n",
    "            xanchor='center', \n",
    "            yanchor='middle'\n",
    "        )\n",
    "        # Calculate y-axis range\n",
    "        pad = 0.1 * (self.plot_upper_bound - self.plot_lower_bound)\n",
    "        yaxis_range = [self.plot_lower_bound - pad, self.plot_upper_bound + pad]\n",
    "        # Update plot layout\n",
    "        fig.update_layout(\n",
    "            title=f'Population Distribution of Pearson Correlation Coefficient for '\n",
    "            f'{\"All\" if self.ignore_mask else \"Masked\" if self.invert_mask else \"Unmasked\"} Samples',\n",
    "            yaxis_title='Pearson Correlation Coefficient', \n",
    "            yaxis=dict(showgrid=True, range=yaxis_range), \n",
    "            xaxis=dict(showgrid=True), \n",
    "            width=1000, height=1000\n",
    "        )\n",
    "        return fig, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup dataloader and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from foundation_models.modeling import build_model\n",
    "from foundation_models.modeling.mtm import MTMPerceiverArgs\n",
    "from foundation_models.datasets.masked_neuro import MaskedNeuroDataset, MaskedNeuroDatapoint, MaskedNeuroSampler, MaskedNeuroSampler, SubsetSequentialSampler\n",
    "\n",
    "model_args = MTMPerceiverArgs(\n",
    "    neural_population_size=8000,\n",
    "    num_sessions=1,\n",
    "    num_samples_per_token=4,\n",
    "    dim_embedding=128,\n",
    "    num_latent_groups=32,\n",
    "    latent_group_size=8,\n",
    "    partial_rot=True,\n",
    "    context_window_len_s=4.1,\n",
    "    temporal_precision_s=1.e-3,\n",
    "    num_heads=8,\n",
    "    dim_head=32,\n",
    "    num_blocks=1,\n",
    "    num_self_attends_per_block=2,\n",
    "    ffn_hidden_mult=1,\n",
    "    ffn_multiple_of=128,\n",
    "    reconstruct_masked_only=False,\n",
    "    init_std=0.02,\n",
    "    depth_init=False\n",
    ")\n",
    "\n",
    "model = build_model(model_args)\n",
    "\n",
    "dataset = MaskedNeuroDataset(\n",
    "    data_root=\"/mnt/scratch09/foundational_model_data\",\n",
    "    session=\"0\",\n",
    "    num_samples_per_block=32,\n",
    "    train_indice_step=4,\n",
    "    validation_fraction=0.2,\n",
    ")\n",
    "dataset.setup()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    sampler=MaskedNeuroSampler(dataset.train_indices),\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    sampler=SubsetSequentialSampler(dataset.validation_indices),\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "def transfer_batch_to_device(\n",
    "    batch: MaskedNeuroDatapoint,\n",
    "    device: Union[str, torch.device] = \"cuda\",\n",
    "):\n",
    "    return MaskedNeuroDatapoint(*(x.to(device) for x in batch))\n",
    "\n",
    "log_dir = Path('logs') / 'mtm_simple'\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metric\n",
    "train_xcorr = MaskedPopulationPearsonCorrCoef(\n",
    "    population_size=model_args.neural_population_size,\n",
    "    masked=None,\n",
    ")\n",
    "# Move metric to GPU\n",
    "train_xcorr.to('cuda')\n",
    "# Move model to GPU\n",
    "model.to('cuda')\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "# Compile model\n",
    "compiled_model = torch.compile(model, fullgraph=False, dynamic=True)\n",
    "# Configure Optimization\n",
    "optimizer = optim.Adam(model.parameters(), lr=1.e-3)\n",
    "# Configure Logger\n",
    "r = RandomWords()\n",
    "# Name of general project. TODO: Change to your own!\n",
    "project_name = 'foundation_models'\n",
    "run_name = f'{r.get_random_word()}-{r.get_random_word()}-{datetime.now(timezone.utc).strftime(\"%y%m%d%H%M\")}' \n",
    "log_dir = log_dir / project_name / run_name\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f'TensorBoard logging training to {log_dir} ...')\n",
    "writer = SummaryWriter(log_dir)\n",
    "# Training loop\n",
    "epoch_loss, epoch_xcorr = 0., -1.\n",
    "epoch_progress = tqdm(range(100), desc=f\"Training MTM Model\")\n",
    "for epoch in epoch_progress:\n",
    "    # Initialize the running loss\n",
    "    running_loss = 0.0\n",
    "    # Reset metric\n",
    "    train_xcorr.reset()\n",
    "    # Epoch loop\n",
    "    for i,batch in enumerate(train_dataloader):\n",
    "        # Move data to GPU \n",
    "        batch = transfer_batch_to_device(batch, 'cuda')\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        loss, logits = compiled_model(\n",
    "            batch.responses,\n",
    "            batch.timestamps,\n",
    "            batch.neurons,\n",
    "            batch.mask,\n",
    "            batch.session,\n",
    "        ) \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()  \n",
    "        # Update loss tracker\n",
    "        running_loss += loss.item() * batch.responses.size(0)\n",
    "        # Update metric states\n",
    "        train_xcorr.update(logits, batch.responses, batch.neurons, batch.mask)\n",
    "        # Update tqdm description with epoch loss\n",
    "        epoch_progress.set_postfix(batch=f'{i+1}/{len(train_dataloader)}', loss=epoch_loss, masked_xcorr=epoch_xcorr)\n",
    "\n",
    "    # Caluclate average loss across epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader.sampler)\n",
    "    # Caluclate per-neuron correlation over course of the \n",
    "    #  epoch, and average over the population\n",
    "    epoch_xcorr = train_xcorr.compute()\n",
    "    # Log the loss and correlation to TensorBoard\n",
    "    writer.add_scalar('train/loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('train/masked_xcorr', epoch_xcorr, epoch)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "# Cleanup Tensorboard\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Expects you just ran training above. Use Lightning if you want to load checkpoints etc...\n",
    "# Initialize metric\n",
    "val_xcorr = MaskedPopulationPearsonCorrCoef(\n",
    "    population_size=dataset.num_neurons,\n",
    "    masked=None,\n",
    ")\n",
    "# Move metric to GPU\n",
    "val_xcorr.to('cuda')\n",
    "# Move model to GPU\n",
    "model.to('cuda')\n",
    "# Set the model to eval mode\n",
    "model.eval()\n",
    "# Compile model\n",
    "compiled_model = torch.compile(model, fullgraph=False, dynamic=True)\n",
    "# Initialize the running loss\n",
    "validation_loss = 0.0\n",
    "# Reset metric\n",
    "val_xcorr.reset()\n",
    "# Re-open Logger\n",
    "print(f'TensorBoard logging validation to {log_dir} ...')\n",
    "writer = SummaryWriter(f'{log_dir}')\n",
    "# Disable gradient tracking\n",
    "with torch.no_grad():\n",
    "    # Validation loop\n",
    "    batch_progress = tqdm(val_dataloader, desc=f\"Validation Loop\")\n",
    "    for i, batch in enumerate(batch_progress):\n",
    "        # Move data to GPU \n",
    "        batch = transfer_batch_to_device(batch, 'cuda')\n",
    "        # Forward pass\n",
    "        loss, logits = compiled_model(\n",
    "            batch.responses,\n",
    "            batch.timestamps,\n",
    "            batch.neurons,\n",
    "            batch.mask,\n",
    "            batch.session,\n",
    "        )\n",
    "        # Update loss tracker\n",
    "        validation_loss += loss.item() * batch.responses.size(0)\n",
    "        # Update metric states\n",
    "        val_xcorr.update(logits, batch.responses, batch.neurons, batch.mask)\n",
    "        # Update tqdm description with epoch loss\n",
    "        batch_progress.set_postfix(loss=loss.item())\n",
    "# Caluclate average loss across epoch\n",
    "epoch_loss = validation_loss / len(val_dataloader.dataset)\n",
    "# Caluclate per-neuron correlation over course of the \n",
    "#  epoch, and average over the population\n",
    "epoch_xcorr = val_xcorr.compute()\n",
    "# Log the loss and correlation to TensorBoard\n",
    "writer.add_scalar('validation/loss', epoch_loss, 0)\n",
    "writer.add_scalar('validation/masked_xcorr', epoch_xcorr, 0)\n",
    "# Let 'em know!\n",
    "print(f\"Validation complete: Loss = {epoch_loss} | Masked XCorr = {epoch_xcorr}\")\n",
    "# Cleanup Tensorboard\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
