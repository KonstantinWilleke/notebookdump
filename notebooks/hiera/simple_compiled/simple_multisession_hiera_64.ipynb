{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0e49e-3752-42b6-bfe4-2e7d03bc7752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of torch.overrides failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/overrides.py\", line 1754, in <module>\n",
      "    has_torch_function = _add_docstr(\n",
      "RuntimeError: function '_has_torch_function' already has a docstring\n",
      "]\n",
      "[autoreload of torch._tensor failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 80, in <module>\n",
      "    class Tensor(torch._C.TensorBase):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 725, in Tensor\n",
      "    detach = _C._add_docstr(\n",
      "RuntimeError: method 'detach' already has a docstring\n",
      "]\n",
      "[autoreload of torch.storage failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to _LegacyStorageMeta object\n",
      "]\n",
      "[autoreload of torch.serialization failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to _SerializationLocal object\n",
      "]\n",
      "[autoreload of torch.cuda.amp.autocast_mode failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/autocast_mode.py\", line 12, in <module>\n",
      "    class autocast(torch.amp.autocast_mode.autocast):\n",
      "AttributeError: module 'torch.amp' has no attribute 'autocast_mode'\n",
      "]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:858: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[autoreload of torch.sparse failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/sparse/__init__.py\", line 44, in <module>\n",
      "    addmm = _add_docstr(\n",
      "RuntimeError: function '_sparse_addmm' already has a docstring\n",
      "]\n",
      "[autoreload of torch.nn.parameter failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to _ParameterMeta object\n",
      "]\n",
      "/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py:423: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py:376: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(a, typ) and isinstance(b, typ)\n",
      "[autoreload of torch.distributed.distributed_c10d failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to _WorldMeta object\n",
      "]\n",
      "[autoreload of torch.distributed.device_mesh failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/extensions/autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to _MeshEnv object\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b327b-4b4d-4ed9-9918-818e5825c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import scaled_dot_product_attention\n",
    "from torch.nn.attention import SDPBackend, sdpa_kernel\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "from torch.optim import AdamW, Adam\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "from experanto.datasets import ChunkDataset, SimpleChunkedDataset\n",
    "from experanto.utils import LongCycler, MultiEpochsDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ecf779-64e2-4c53-930c-4bc96109fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional packages\n",
    "# pip install hiera-transformer\n",
    "# pip install -U pytorch_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f5a3f-8720-4222-a63c-b3605b61c5e7",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8aa514-908e-4e00-af7a-06830084b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_size = [72, 128]\n",
    "chunk_size = 8\n",
    "dim_head = 128\n",
    "num_heads = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a43689-cdb6-4443-a57d-0a227fb65d45",
   "metadata": {},
   "source": [
    "### get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edb2a0-b392-40be-9e1a-054aacb4593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experanto.dataloaders import get_multisession_dataloader\n",
    "\n",
    "from experanto.configs import DEFAULT_CONFIG as cfg\n",
    "paths = ['dynamic29513-3-5-Video-full',\n",
    "         'dynamic29514-2-9-Video-full',\n",
    "         'dynamic29755-2-8-Video-full',\n",
    "         'dynamic29647-19-8-Video-full',\n",
    "         'dynamic29156-11-10-Video-full',\n",
    "         'dynamic29623-4-9-Video-full',\n",
    "         'dynamic29515-10-12-Video-full',\n",
    "         'dynamic29234-6-9-Video-full',\n",
    "         'dynamic29712-5-9-Video-full',\n",
    "         'dynamic29228-2-10-Video-full'\n",
    "        ]\n",
    "full_paths = [path.join(\"/data/mouse_polly/\", f) for f in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f1c64c-31a4-4391-85ef-6f35d7085c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset.global_chunk_size = 8\n",
    "cfg.dataset.global_sampling_rate = 8\n",
    "cfg.dataset.modality_config.screen.sample_stride = 8\n",
    "cfg.dataset.modality_config.screen.include_blanks=True\n",
    "cfg.dataset.modality_config.screen.valid_condition = {\"tier\": \"train\"}\n",
    "cfg.dataset.modality_config.screen.transforms.Resize.size = video_size\n",
    "\n",
    "cfg.dataloader.num_workers=4\n",
    "cfg.dataloader.prefetch_factor=1\n",
    "cfg.dataloader.batch_size=64\n",
    "cfg.dataloader.pin_memory=True\n",
    "cfg.dataloader.shuffle=True\n",
    "\n",
    "train_dl = get_multisession_dataloader(full_paths, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14b18d-346d-48c4-b12e-e7b8e0f28820",
   "metadata": {},
   "source": [
    "### get Hiera backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0b8f9-b374-479f-b166-801bf9d22851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hiera-transformer\n",
    "from hiera import Hiera\n",
    "tiny_hiera = Hiera(input_size=(chunk_size, video_size[0], video_size[1]),\n",
    "                     num_heads=1,\n",
    "                     embed_dim=128,\n",
    "                     stages=(2, 2), # 4 transformer layers \n",
    "                     q_pool=1, \n",
    "                     in_chans=1,\n",
    "                     q_stride=(1, 2, 2),\n",
    "                     mask_unit_size=(1, 8, 8),\n",
    "                     patch_kernel=(3, 8, 8),\n",
    "                     patch_stride=(2, 4, 4),\n",
    "                     patch_padding=(1, 3, 3),\n",
    "                     sep_pos_embed=True,)\n",
    "\n",
    "tiny_hiera = tiny_hiera.cuda().to(torch.bfloat16);\n",
    "example_input = torch.ones(8,1,8,72,128).to(\"cuda\", torch.bfloat16)\n",
    "out = tiny_hiera(example_input, return_intermediates=True);\n",
    "hiera_output = out[-1][-1]\n",
    "hiera_output.shape # (b, t, h, w, c): (8, 4, 9, 16, 192)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e892e-0e01-4fda-bec9-13179f415692",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce1ed2-9c69-43e0-91c9-a35fc2e4b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MouseHieraSmall(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 dls,\n",
    "                 chunk_size,\n",
    "                 dim=192,\n",
    "                 dim_head=32,\n",
    "                 num_heads=4):\n",
    "        super().__init__()\n",
    "        self.backbone=backbone\n",
    "        self.num_heads=num_heads\n",
    "        self.dim_head=dim_head\n",
    "        self.wk = nn.Linear(dim, dim_head * num_heads, bias=False)\n",
    "        self.wv = nn.Linear(dim, dim_head * num_heads, bias=False)\n",
    "        self.neuron_proj = nn.Linear(dim_head * num_heads, chunk_size, bias=False)\n",
    "        self.readout = nn.ModuleDict()\n",
    "        self.activation = nn.Softplus(beta=0.5) # probably a much better activation than ELU+1\n",
    "        for k, v in dls.loaders.items():\n",
    "            n_neurons = next(iter(v))[\"responses\"].shape[-1]\n",
    "            self.readout[k] = IndexedLinearReadout(n_neurons, \n",
    "                                                   in_features=dim_head*num_heads,\n",
    "                                                   dim_head=dim_head, \n",
    "                                                   num_heads=num_heads, \n",
    "                                                  )\n",
    "            \n",
    "    def forward(self, x, key):\n",
    "        x = self.backbone(x, return_intermediates=True)[1][-1]\n",
    "        b, t, h, w, d = x.shape\n",
    "        x = x.view(b, -1, d) # (B, t*h*w, D)\n",
    "        k, v = self.wk(x), self.wv(x)\n",
    "        q = self.readout[key].query\n",
    "        n = q.shape[2] # number of neurons\n",
    "        q = q.repeat(b, 1, 1, 1) # repeat query for number of batches\n",
    "        k = k.view(b, -1, self.num_heads, self.dim_head).transpose(1, 2) # (B, H, S, D)\n",
    "        v = v.view(b, -1, self.num_heads, self.dim_head).transpose(1, 2) # (B, H, S, D)\n",
    "        # remove if kernel is not available\n",
    "        with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n",
    "            o = F.scaled_dot_product_attention(q, k, v)\n",
    "            \n",
    "        # (B, H, S, D) -> (B, N, D), with N = num_neurons\n",
    "        o = o.transpose(1,2).contiguous().view(b, -1, self.num_heads * self.dim_head)\n",
    "        o = self.neuron_proj(o) # (B, N, D) -> (B, N, t)\n",
    "        o = o + self.readout[key].bias\n",
    "        o = self.activation(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528566e8-29c1-46a1-b4b3-2fea3b64da88",
   "metadata": {},
   "source": [
    "# Readout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a6270-174c-42d7-8f19-2591ca4ddb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexedLinearReadout(nn.Module):\n",
    "    \"\"\"\n",
    "    Readout module for MTM models with selectable weights based on \n",
    "    input IDs. Based on :class:`torch.nn.Linear`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        unique_ids: int,\n",
    "        in_features: int = 384,\n",
    "        dim_head=32,\n",
    "        num_heads=4,\n",
    "        bias: bool = True,\n",
    "        device=\"cuda\",\n",
    "        dtype=torch.float32,\n",
    "        init_std: float = 0.02,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        self.unique_ids = unique_ids\n",
    "        self.in_features = in_features\n",
    "        self.init_std = init_std\n",
    "        self.query = nn.Parameter(\n",
    "            torch.empty(1, num_heads, unique_ids, dim_head, **factory_kwargs)\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(\n",
    "                torch.empty(1, unique_ids, 1, **factory_kwargs)\n",
    "            )\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self, cutoff_factor: int = 3):\n",
    "        \"\"\"See `TorchTitan <https://github.com/pytorch/torchtitan/blob/40a10263c5b3468ffa53b3ac98d80c9267d68155/torchtitan/models/llama/model.py#L403>`__.\"\"\"\n",
    "        readout_std = self.in_features**-0.5\n",
    "        nn.init.trunc_normal_(\n",
    "            self.query,\n",
    "            mean=0.0,\n",
    "            std=readout_std,\n",
    "            a=-cutoff_factor * readout_std,\n",
    "            b=cutoff_factor * readout_std,\n",
    "        )\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dddde36-dfd5-44b3-8961-b67d970422a5",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512db87e-b274-4208-9579-0c36d322d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_dim = hiera_output[-1][-1].shape[-1]\n",
    "model = MouseHieraSmall(backbone=tiny_hiera, \n",
    "                        dls=train_dl, \n",
    "                        chunk_size=chunk_size,\n",
    "                        dim=backbone_dim, \n",
    "                        dim_head=dim_head,\n",
    "                        num_heads=num_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c370d-db23-4fa6-8cb6-a34f3d72ae6a",
   "metadata": {},
   "source": [
    "### performance boosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb7bef-0c85-4b4a-b072-dba2e947617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "torch._dynamo.config.cache_size_limit = 32\n",
    "model = torch.compile(model).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db1feb-d92b-426b-925e-5ae114465d83",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03e89e-23d5-4cbe-b96e-8ecb2cee2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pytorch_warmup\n",
    "import pytorch_warmup as warmup\n",
    "\n",
    "n_epochs = 5\n",
    "lr = 1.0e-3\n",
    "\n",
    "criteria = nn.PoissonNLLLoss(log_input=False, reduction='mean')\n",
    "opt = AdamW(model.parameters(), lr=lr, weight_decay=0.1,)\n",
    "warmup_scheduler = warmup.UntunedLinearWarmup(opt)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt,\n",
    "                                                          T_max=5e5, \n",
    "                                                          eta_min=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91982d-a5f5-4a86-86c8-c04280570032",
   "metadata": {},
   "source": [
    "# train - simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa59f4a-4b2c-40ec-a83b-ece17dddaee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:13,  9.51s/it]W1025 00:40:25.568000 42943 torch/_dynamo/convert_frame.py:844] [0/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W1025 00:40:25.568000 42943 torch/_dynamo/convert_frame.py:844] [0/8]    function: 'forward' (/tmp/ipykernel_42943/2099902904.py:24)\n",
      "W1025 00:40:25.568000 42943 torch/_dynamo/convert_frame.py:844] [0/8]    last reason: 0/0: L['key'] == '29513-3-5'                                     \n",
      "W1025 00:40:25.568000 42943 torch/_dynamo/convert_frame.py:844] [0/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1025 00:40:25.568000 42943 torch/_dynamo/convert_frame.py:844] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "2140it [02:28, 14.39it/s]\n",
      "2140it [01:14, 28.58it/s]\n",
      "2140it [01:14, 28.92it/s]\n",
      "2140it [01:13, 28.94it/s]\n",
      "2140it [01:12, 29.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# the first 10 batches are slow because torch is compiling the model for each new input shape\n",
    "\n",
    "for _ in range(n_epochs):\n",
    "    for i, (key, batch) in tqdm(enumerate(train_dl)):\n",
    "        videos = batch[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        responses = batch[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        out = model(videos, key);\n",
    "        loss = criteria(out.transpose(1,2), responses)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), gradient_clip_value,)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        with warmup_scheduler.dampening():\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "    # after each epoch, the times can be shuffled so there are new random starting points for all chunks\n",
    "    for dataloader in train_dl.loaders.values():\n",
    "        dataloader.dataset.shuffle_valid_screen_times()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ae39a6-7b18-4450-a528-f060d0bbc87d",
   "metadata": {},
   "source": [
    "# train messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f31bcf-dab8-45d1-82d3-fc16c723da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experanto.configs import DEFAULT_CONFIG as cfg\n",
    "cfg.dataset.global_chunk_size = 8\n",
    "cfg.dataset.global_sampling_rate = 8\n",
    "cfg.dataset.modality_config.screen.include_blanks=False\n",
    "cfg.dataset.modality_config.screen.sample_stride=8\n",
    "cfg.dataset.modality_config.screen.valid_condition = {\"tier\": \"oracle\"}\n",
    "cfg.dataset.modality_config.screen.transforms.Resize.size = video_size\n",
    "\n",
    "\n",
    "cfg.dataloader.num_workers=4\n",
    "cfg.dataloader.prefetch_factor=1\n",
    "cfg.dataloader.batch_size=32\n",
    "cfg.dataloader.pin_memory=True\n",
    "# the multiple dataloader is an iterator that returns a tuple of (key, batch)\n",
    "val_dl = get_multisession_dataloader(full_paths[3:4], cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410a49b-aa7f-4251-8e7f-1d68b88e1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step():\n",
    "    targets, predictions = [],[]\n",
    "    with torch.no_grad():\n",
    "        for i, (k, b) in tqdm(enumerate(val_dl)):\n",
    "            videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "            responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "            out = model(videos, k);\n",
    "            predictions.append(out.transpose(1,2).to(torch.float32).cpu().numpy())\n",
    "            targets.append(responses.to(torch.float32).cpu().numpy())\n",
    "    r1 = np.vstack(np.vstack(predictions))\n",
    "    r2 = np.vstack(np.vstack(targets))\n",
    "    cs = []\n",
    "    for n in range(7000):\n",
    "        c =  np.corrcoef(r1[...,n].flatten(), r2[...,n].flatten(), )[0,1]\n",
    "        cs.append(c)\n",
    "    val_corrs = np.stack(cs).mean()\n",
    "    return val_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82f1ad-b724-49d6-99c8-7c01d884bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 0\n",
    "max_objective = 0\n",
    "losses, corrs, lrs, val_corrs = [], [], [], []\n",
    "for train_loop in range(1000):\n",
    "    current_objective = val_step()\n",
    "    if train_loop > 20:\n",
    "        max_objective = np.max(np.array(val_corrs[:-1])[~np.isnan(val_corrs[:-1])])\n",
    "    if current_objective < max_objective:\n",
    "        patience += 1\n",
    "    else:\n",
    "        patience = 0\n",
    "    if patience >=50:\n",
    "        break\n",
    "    val_corrs.append(current_objective)\n",
    "    print(val_corrs)\n",
    "    for i, (k, b) in tqdm(enumerate(train_dl)):\n",
    "        videos = b[\"screen\"].to(\"cuda\", torch.bfloat16, non_blocking=True).permute(0,2,1,3,4)\n",
    "        responses = b[\"responses\"].to(\"cuda\", torch.bfloat16, non_blocking=True)\n",
    "        out = model(videos, k);\n",
    "        loss = criteria(out.transpose(1,2), responses)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type=2)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        with warmup_scheduler.dampening():\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "        if i % 10 ==0:\n",
    "            r2 = responses.to(torch.float32).cpu().numpy().flatten()\n",
    "            r1 = out.transpose(1,2).detach().cpu().to(torch.float32).numpy().flatten()\n",
    "            corrs.append(np.corrcoef(r1,r2)[0,1].item())\n",
    "            lrs.append(opt.param_groups[0]['lr'])\n",
    "        if i % 100 ==0:\n",
    "            print(np.corrcoef(r1,r2)[0,1].item())\n",
    "            print(opt.param_groups[0]['lr'])\n",
    "    for k, v in train_dl.loaders.items():\n",
    "        v.dataset.shuffle_valid_screen_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd02c5d-6610-4b51-853a-d2ca1129dca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfaee79-34d8-41ea-a5f7-6eb1ac9ff3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
